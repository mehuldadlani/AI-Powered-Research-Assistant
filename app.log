2025-04-04 11:45:00,800 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.222 seconds
2025-04-04 11:45:00,802 - root - INFO - Starting up the application...
2025-04-04 11:45:00,802 - root - INFO - Configuration validated successfully
2025-04-04 11:45:00,802 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 11:45:00,815 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 11:45:01,573 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 11:45:01,573 - root - INFO - RAG service initialized successfully
2025-04-04 11:45:01,573 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 11:45:01,573 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 11:45:01,573 - root - INFO - PaperSearchService initialized successfully
2025-04-04 11:45:01,581 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 11:46:02,691 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 11:46:12,589 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 11:46:12,590 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 11:46:12,590 - root - INFO - QnAService initialized successfully
2025-04-04 11:46:12,590 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 11:46:12,590 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 11:46:12,590 - root - INFO - AIService initialized successfully
2025-04-04 11:46:12,590 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 11:46:12,590 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 11:46:12,590 - root - INFO - PDFService initialized successfully
2025-04-04 11:46:12,590 - root - INFO - Services initialized and passed to routes
2025-04-04 11:46:12,591 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 71.788 seconds
2025-04-04 11:46:12,592 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=31, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 11:46:12,599 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 11:50:24,545 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 11:50:24,547 - root - INFO - Starting up the application...
2025-04-04 11:50:24,547 - root - INFO - Configuration validated successfully
2025-04-04 11:50:24,547 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 11:50:24,559 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 11:50:24,687 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 11:50:24,687 - root - INFO - RAG service initialized successfully
2025-04-04 11:50:24,687 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 11:50:24,687 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 11:50:24,687 - root - INFO - PaperSearchService initialized successfully
2025-04-04 11:50:24,693 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 11:50:35,915 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 11:50:37,824 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 11:50:37,825 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 11:50:37,825 - root - INFO - QnAService initialized successfully
2025-04-04 11:50:37,826 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 11:50:37,826 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 11:50:37,826 - root - INFO - AIService initialized successfully
2025-04-04 11:50:37,826 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 11:50:37,826 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 11:50:37,826 - root - INFO - PDFService initialized successfully
2025-04-04 11:50:37,826 - root - INFO - Services initialized and passed to routes
2025-04-04 11:50:37,836 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 13.288 seconds
2025-04-04 11:50:37,838 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=26, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 11:50:37,853 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 11:53:47,134 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 11:53:47,136 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=11, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 11:53:47,137 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 11:54:37,229 - src.api.routes - ERROR - Error answering question: 'NoneType' object has no attribute 'answer_question'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 104, in ask_question
    answer = await qna_service.answer_question(question)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'answer_question'
2025-04-04 11:57:55,735 - src.api.routes - ERROR - Error answering question: 'NoneType' object has no attribute 'answer_question'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 104, in ask_question
    answer = await qna_service.answer_question(question)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'answer_question'
2025-04-04 12:00:48,072 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.164 seconds
2025-04-04 12:00:48,073 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=10, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:00:48,074 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:00:53,990 - src.api.routes - ERROR - Error answering question: 'NoneType' object has no attribute 'answer_question'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 104, in ask_question
    answer = await qna_service.answer_question(question)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'answer_question'
2025-04-04 12:01:29,483 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 12:01:29,486 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=11, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:01:29,486 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:01:34,732 - src.api.routes - ERROR - Error answering question: 'NoneType' object has no attribute 'answer_question'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 104, in ask_question
    answer = await qna_service.answer_question(question)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'answer_question'
2025-04-04 12:28:09,900 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.156 seconds
2025-04-04 12:28:09,903 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=12, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:28:09,903 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:28:26,799 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.152 seconds
2025-04-04 12:28:26,801 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=13, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:28:26,801 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:28:37,338 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.158 seconds
2025-04-04 12:28:37,340 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=14, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:28:37,341 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:28:43,782 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.152 seconds
2025-04-04 12:28:43,784 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=15, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:28:43,785 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:28:47,506 - src.api.routes - ERROR - Error answering question: 'NoneType' object has no attribute 'answer_question'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 104, in ask_question
    answer = await qna_service.answer_question(question)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'answer_question'
2025-04-04 12:29:10,193 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.150 seconds
2025-04-04 12:29:10,195 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=16, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:29:10,196 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:29:27,084 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.151 seconds
2025-04-04 12:29:27,086 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=17, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:29:27,086 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:29:44,037 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.168 seconds
2025-04-04 12:29:44,039 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=18, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:29:44,039 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:27,475 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.160 seconds
2025-04-04 12:30:27,477 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=19, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:27,478 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:34,135 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.157 seconds
2025-04-04 12:30:34,137 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=20, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:34,138 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:39,979 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.155 seconds
2025-04-04 12:30:39,982 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=21, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:39,982 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:46,751 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.161 seconds
2025-04-04 12:30:46,753 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=22, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:46,753 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:52,505 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.162 seconds
2025-04-04 12:30:52,506 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=23, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:52,507 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:30:57,219 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.158 seconds
2025-04-04 12:30:57,220 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=24, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:30:57,221 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:31:03,076 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.203 seconds
2025-04-04 12:31:03,077 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=25, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:31:03,077 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:31:09,484 - src.api.routes - ERROR - Error answering question: QnAService is not initialized
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 110, in ask_question
    raise ValueError("QnAService is not initialized")
ValueError: QnAService is not initialized
2025-04-04 12:31:28,311 - src.api.routes - ERROR - Error answering question: QnAService is not initialized
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 110, in ask_question
    raise ValueError("QnAService is not initialized")
ValueError: QnAService is not initialized
2025-04-04 12:32:27,999 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.154 seconds
2025-04-04 12:32:28,001 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=10, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:32:28,002 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:36:54,556 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.157 seconds
2025-04-04 12:36:54,559 - root - INFO - Starting up the application...
2025-04-04 12:36:54,559 - root - INFO - Configuration validated successfully
2025-04-04 12:36:54,559 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:36:54,571 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:36:54,699 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:36:54,700 - root - INFO - RAG service initialized successfully
2025-04-04 12:36:54,700 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 12:36:54,714 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 404 Not Found"
2025-04-04 12:36:54,714 - src.services.crew_service - ERROR - Failed to initialize CrewAI service
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:36:54,715 - root - ERROR - Error during startup: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:36:54,716 - app - ERROR - Exception
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:36:54,716 - asyncio - WARNING - Executing <Task finished name='Task-3' coro=<Lifespan.handle_lifespan() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:42> exception=LifespanFailureError('Lifespan failure in startup. \'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)\'') created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 0.157 seconds
2025-04-04 12:36:54,717 - root - CRITICAL - Unhandled exception in main app: Lifespan failure in startup. 'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 365, in __call__
    await self.app.startup()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 113, in <module>
    app.run(debug=Config.DEBUG, host=Config.HOST, port=Config.PORT)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 878, in run
    loop.run_until_complete(asyncio.gather(*tasks))
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/__init__.py", line 44, in serve
    await worker_serve(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py", line 88, in worker_serve
    raise exception
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 55, in handle_lifespan
    await self.app(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 367, in __call__
    await send(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 119, in asgi_send
    raise LifespanFailureError("startup", message.get("message", ""))
hypercorn.utils.LifespanFailureError: Lifespan failure in startup. 'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)'
2025-04-04 12:37:15,273 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.159 seconds
2025-04-04 12:37:15,275 - root - INFO - Starting up the application...
2025-04-04 12:37:15,275 - root - INFO - Configuration validated successfully
2025-04-04 12:37:15,275 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:37:15,287 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:37:15,386 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:37:15,386 - root - INFO - RAG service initialized successfully
2025-04-04 12:37:15,386 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 12:37:15,388 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 404 Not Found"
2025-04-04 12:37:15,388 - src.services.crew_service - ERROR - Failed to initialize CrewAI service
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:37:15,390 - root - ERROR - Error during startup: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:37:15,391 - app - ERROR - Exception
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)
2025-04-04 12:37:15,391 - asyncio - WARNING - Executing <Task finished name='Task-3' coro=<Lifespan.handle_lifespan() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:42> exception=LifespanFailureError('Lifespan failure in startup. \'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)\'') created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 0.116 seconds
2025-04-04 12:37:15,392 - root - CRITICAL - Unhandled exception in main app: Lifespan failure in startup. 'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 19, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 333, in chat
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 178, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/_client.py", line 122, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 365, in __call__
    await self.app.startup()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(e)}")
RuntimeError: Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 113, in <module>
    app.run(debug=Config.DEBUG, host=Config.HOST, port=Config.PORT)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 878, in run
    loop.run_until_complete(asyncio.gather(*tasks))
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/__init__.py", line 44, in serve
    await worker_serve(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py", line 88, in worker_serve
    raise exception
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 55, in handle_lifespan
    await self.app(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 367, in __call__
    await send(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 119, in asgi_send
    raise LifespanFailureError("startup", message.get("message", ""))
hypercorn.utils.LifespanFailureError: Lifespan failure in startup. 'Failed to initialize CrewAI service: model "mistral" not found, try pulling it first (status code: 404)'
2025-04-04 12:43:01,818 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 12:43:01,819 - root - INFO - Starting up the application...
2025-04-04 12:43:01,819 - root - INFO - Configuration validated successfully
2025-04-04 12:43:01,819 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:43:01,831 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:43:01,942 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:43:01,942 - root - INFO - RAG service initialized successfully
2025-04-04 12:43:01,942 - root - ERROR - Error during startup: 'CrewAIService' object has no attribute 'initialize'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'
2025-04-04 12:43:01,943 - app - ERROR - Exception
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'
2025-04-04 12:43:01,943 - asyncio - WARNING - Executing <Task finished name='Task-3' coro=<Lifespan.handle_lifespan() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:42> exception=LifespanFailureError("Lifespan failure in startup. ''CrewAIService' object has no attribute 'initialize''") created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 0.124 seconds
2025-04-04 12:43:01,944 - root - CRITICAL - Unhandled exception in main app: Lifespan failure in startup. ''CrewAIService' object has no attribute 'initialize''
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 365, in __call__
    await self.app.startup()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 113, in <module>
    app.run(debug=Config.DEBUG, host=Config.HOST, port=Config.PORT)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 878, in run
    loop.run_until_complete(asyncio.gather(*tasks))
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/__init__.py", line 44, in serve
    await worker_serve(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py", line 88, in worker_serve
    raise exception
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 55, in handle_lifespan
    await self.app(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 367, in __call__
    await send(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 119, in asgi_send
    raise LifespanFailureError("startup", message.get("message", ""))
hypercorn.utils.LifespanFailureError: Lifespan failure in startup. ''CrewAIService' object has no attribute 'initialize''
2025-04-04 12:43:34,145 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.152 seconds
2025-04-04 12:43:34,147 - root - INFO - Starting up the application...
2025-04-04 12:43:34,147 - root - INFO - Configuration validated successfully
2025-04-04 12:43:34,147 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:43:34,159 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:43:34,243 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:43:34,243 - root - INFO - RAG service initialized successfully
2025-04-04 12:43:34,243 - root - ERROR - Error during startup: 'CrewAIService' object has no attribute 'initialize'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'
2025-04-04 12:43:34,244 - app - ERROR - Exception
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'
2025-04-04 12:43:34,245 - root - CRITICAL - Unhandled exception in main app: Lifespan failure in startup. ''CrewAIService' object has no attribute 'initialize''
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 365, in __call__
    await self.app.startup()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'initialize'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 113, in <module>
    app.run(debug=Config.DEBUG, host=Config.HOST, port=Config.PORT)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 878, in run
    loop.run_until_complete(asyncio.gather(*tasks))
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/__init__.py", line 44, in serve
    await worker_serve(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py", line 88, in worker_serve
    raise exception
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 55, in handle_lifespan
    await self.app(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 367, in __call__
    await send(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 119, in asgi_send
    raise LifespanFailureError("startup", message.get("message", ""))
hypercorn.utils.LifespanFailureError: Lifespan failure in startup. ''CrewAIService' object has no attribute 'initialize''
2025-04-04 12:45:07,207 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.154 seconds
2025-04-04 12:45:07,209 - root - INFO - Starting up the application...
2025-04-04 12:45:07,209 - root - INFO - Configuration validated successfully
2025-04-04 12:45:07,209 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:45:07,221 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:45:07,344 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:45:07,344 - root - INFO - RAG service initialized successfully
2025-04-04 12:45:07,344 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 12:46:14,202 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 12:46:14,225 - src.services.crew_service - WARNING - Failed to initialize CrewAI service: object ChatResponse can't be used in 'await' expression
2025-04-04 12:46:14,226 - src.services.crew_service - INFO - Attempting to pull the model: mistral
2025-04-04 12:46:16,720 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-04-04 12:46:16,729 - src.services.crew_service - ERROR - Failed to pull and initialize the model: object ProgressResponse can't be used in 'await' expression
2025-04-04 12:46:16,729 - root - ERROR - Error during startup: Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 17, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
TypeError: object ChatResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    await self.llm.pull(model=self.model)
TypeError: object ProgressResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 29, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(pull_error)}")
RuntimeError: Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression
2025-04-04 12:46:16,776 - app - ERROR - Exception
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 17, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
TypeError: object ChatResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    await self.llm.pull(model=self.model)
TypeError: object ProgressResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 29, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(pull_error)}")
RuntimeError: Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression
2025-04-04 12:46:16,783 - asyncio - WARNING - Executing <Task finished name='Task-3' coro=<Lifespan.handle_lifespan() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:42> exception=LifespanFailureError("Lifespan failure in startup. 'Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression'") created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 69.572 seconds
2025-04-04 12:46:16,788 - root - CRITICAL - Unhandled exception in main app: Lifespan failure in startup. 'Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 17, in initialize
    await self.llm.chat(model=self.model, messages=[{"role": "system", "content": "Test"}])
TypeError: object ChatResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 23, in initialize
    await self.llm.pull(model=self.model)
TypeError: object ProgressResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 365, in __call__
    await self.app.startup()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1768, in startup
    await self.ensure_async(func)()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 58, in startup
    await crew_service.initialize()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 29, in initialize
    raise RuntimeError(f"Failed to initialize CrewAI service: {str(pull_error)}")
RuntimeError: Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/app.py", line 113, in <module>
    app.run(debug=Config.DEBUG, host=Config.HOST, port=Config.PORT)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 878, in run
    loop.run_until_complete(asyncio.gather(*tasks))
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 691, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/__init__.py", line 44, in serve
    await worker_serve(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py", line 88, in worker_serve
    raise exception
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 55, in handle_lifespan
    await self.app(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 367, in __call__
    await send(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py", line 119, in asgi_send
    raise LifespanFailureError("startup", message.get("message", ""))
hypercorn.utils.LifespanFailureError: Lifespan failure in startup. 'Failed to initialize CrewAI service: object ProgressResponse can't be used in 'await' expression'
2025-04-04 12:49:03,188 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.156 seconds
2025-04-04 12:49:03,190 - root - INFO - Starting up the application...
2025-04-04 12:49:03,190 - root - INFO - Configuration validated successfully
2025-04-04 12:49:03,190 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:49:03,202 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:49:03,314 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:49:03,314 - root - INFO - RAG service initialized successfully
2025-04-04 12:49:03,314 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 12:49:39,703 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 12:49:39,713 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T07:19:39.688953Z' done=True done_reason='stop' total_duration=36372844250 load_duration=14204916 prompt_eval_count=2 prompt_eval_duration=3874873750 eval_count=640 eval_duration=32479875250 message=Message(role='assistant', content=' <style>\n   body{\n    font-family: Arial, Helvetica, sans-serif;\n\t}\n  table {\n    border-collapse: collapse;\n    width: 90%;\n    margin: 0 auto;\n  }\n  th, td {\n    text-align: left;\n    padding: 8px;\n  }\n  tr:nth-child(even) {\n    background-color: #f2f2f2\n  }\n</style>\n<h1>Invoice</h1>\n<table>\n  <tr>\n    <th>No. Invoice</th>\n    <td>INV/2023/001</td>\n  </tr>\n  <tr>\n    <th>Tanggal</th>\n    <td>30 Maret 2023</td>\n  </tr>\n  <tr>\n    <th>Nama Pembeli</th>\n    <td>John Doe</td>\n  </tr>\n  <tr>\n    <th>Alamat</th>\n    <td>Jl. Perkantoran No. 123, Kota Besar</td>\n  </tr>\n  <tr>\n    <th>Nomor Telepon</th>\n    <td>089674892345</td>\n  </tr>\n  <tr>\n    <th colspan="2">Rincian Pesanan</th>\n  </tr>\n  <tr>\n    <th>No. Item</th>\n    <th>Produk</th>\n    <th>Harga Satuan</th>\n    <th>Jumlah</th>\n    <th>Total</th>\n  </tr>\n  <?php $total = 0; ?>\n  @foreach ($cart as $item)\n  <tr>\n    <td>{{ $loop->iteration }}</td>\n    <td>{{ $item[\'name\'] }}</td>\n    <td>Rp {{ number_format($item[\'price\'], 0, \',\', \'.\') }}</td>\n    <td>{{ $item[\'qty\'] }}</td>\n    <td>Rp {{ number_format($item[\'totalPrice\'], 0, \',\', \'.\') }}</td>\n  </tr>\n  <?php $total += $item[\'totalPrice\']; ?>\n  @endforeach\n  <tr>\n    <th colspan="3"></th>\n    <th>Total</th>\n    <td>Rp {{ number_format($total, 0, \',\', \'.\') }}</td>\n  </tr>\n</table>', images=None, tool_calls=None)
2025-04-04 12:49:39,713 - root - INFO - CrewAIService initialized successfully
2025-04-04 12:49:39,714 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 12:49:39,714 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 12:49:39,714 - root - INFO - PaperSearchService initialized successfully
2025-04-04 12:49:39,744 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:49:51,351 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 12:49:59,444 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 12:49:59,445 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 12:49:59,445 - root - INFO - QnAService initialized successfully
2025-04-04 12:49:59,445 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 12:49:59,445 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 12:49:59,445 - root - INFO - AIService initialized successfully
2025-04-04 12:49:59,445 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 12:49:59,445 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 12:49:59,445 - root - INFO - PDFService initialized successfully
2025-04-04 12:49:59,445 - root - INFO - Services initialized and passed to routes
2025-04-04 12:49:59,447 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 56.257 seconds
2025-04-04 12:49:59,449 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=27, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:49:59,453 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:50:37,653 - src.services.qna_service - INFO - Querying collection for prompt: What is machine learning?
2025-04-04 12:50:38,980 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 1.321 seconds
2025-04-04 12:50:41,833 - httpx - INFO - HTTP Request: GET https://chroma-onnx-models.s3.amazonaws.com/all-MiniLM-L6-v2/onnx.tar.gz "HTTP/1.1 200 OK"
2025-04-04 12:51:12,780 - src.services.rag_service - INFO - Search completed for query: What is machine learning?
2025-04-04 12:51:12,781 - src.services.qna_service - ERROR - Error answering question: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 134, in answer_question
    logger.info(f"Query results received: {len(results['documents'])} documents")
                                               ~~~~~~~^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2025-04-04 12:51:12,782 - src.api.routes - ERROR - Error answering question: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 111, in ask_question
    answer = await qna_service.answer_question(question)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 134, in answer_question
    logger.info(f"Query results received: {len(results['documents'])} documents")
                                               ~~~~~~~^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2025-04-04 12:54:42,143 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 12:54:42,145 - root - INFO - Starting up the application...
2025-04-04 12:54:42,145 - root - INFO - Configuration validated successfully
2025-04-04 12:54:42,145 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 12:54:42,157 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:54:42,281 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 12:54:42,281 - root - INFO - RAG service initialized successfully
2025-04-04 12:54:42,281 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 12:56:29,687 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 12:56:29,738 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T07:26:29.603416Z' done=True done_reason='stop' total_duration=107316890333 load_duration=3570067666 prompt_eval_count=2 prompt_eval_duration=4747194625 eval_count=1722 eval_duration=98991090667 message=Message(role='assistant', content=" This site uses cookies. By continuing to browse this site, you are agreeing to our use of cookies.\n\n### What is a cookie?\n\nCookies are small pieces of data that the website sends to the user's device while they browse the web pages and which may then be sent back to the website on subsequent visits.\n\n### Why do we use cookies?\n\nWe use cookies for two main purposes:\n\n1. To improve the functionality of our website – cookies allow us to remember user preferences (such as language, font size), recognize you when you return to our site and personalize content accordingly, provide features such as video or social network sharing, measure traffic patterns, and generally improve your online experience.\n2. For statistical purposes and analyses, and in some cases for marketing and advertising purposes – we use cookies to collect information about how users interact with our website, which pages are visited most frequently, which links are clicked on, the number of visits to a particular page, whether you open an e-mail or click on links contained in it. Such data is aggregated and used by us for statistical analysis and reporting purposes. We use cookies to help us understand user preferences and improve the content and functionality of our website.\n\n### Types of Cookies\n\nWe may use the following types of cookies on our site:\n\n1. Strictly necessary cookies - these are cookies that are essential for the operation of a website, such as enabling users to log in securely or remember previous actions (e.g. filling out a form) when navigating through different pages on a site.\n2. Performance cookies - these cookies collect information about how visitors use a website, for instance which pages visitors go to most often and if they get error messages from web pages. These cookies do not collect information that identifies a visitor. All information these cookies collect is aggregated and therefore anonymous. It is only used to improve how the website works.\n3. Functionality cookies - these cookies allow the website to remember choices you make (such as your user name, language or region) and provide enhanced, more personal features. These cookies can also be used to remember changes you've made to text size, fonts and other parts of web pages that you can customize. They may also be used to provide services you have asked for such as watching a video or commenting on a blog. The information these cookies collect may be anonymized and they cannot track your browsing activity on other websites.\n4. Targeting/advertising cookies - these cookies are used to deliver adverts more relevant to you and your interests, limit the number of times you see an advertisement as well as help measure the effectiveness of the advertising campaign. They are usually placed by advertising networks with the website operator's permission. They remember that you have visited a website and this information may be shared with other organizations such as advertisers.\n5. Session Cookies - these cookies allow us to link your actions during a browser session. A browser session starts when you open the browser window and finishes when you close your browser window. Session cookies are created temporarily, they expire after you leave the site.\n6. Persistent Cookies - a persistent cookie is stored on a user's device in between browser sessions, which allows the preferences or actions of the user across a site (or in some cases across different websites) to be remembered. Persistent cookies may be used for a variety of purposes including remembering users' preferences and choices when using the site or targeting advertising.\n\n### Cookies on this Site\n\nThe following table provides more information about the specific cookies that are currently being used on this website:\n\n| Name             | Category  | Purpose                                                         | Expiry time   |\n|------------------|----------|---------------------------------------------------------------|--------------|\n| AWSELB          | Necessary | AWS Elastic Load Balancer Cookie                                | Session      |\n| JSESSIONID       | Functional | Secure Spring Web Application Framework session cookie    | Session     |\n| PHPSESSID        | Functional | Secure PHP session cookie                             | Session     |\n| _ga             | Statistical | Google Analytics                          2 years     |\n| _gid            | Statistical  | Google Analytics                           24 hours   |\n| __atuvs         | Advertising  | AddThis Social Media Sharing Widget  | 1 year    |\n| __atuvc         | Advertising  | AddThis Social Media Sharing Widget  | Session     |\n| _fbp             | Advertising  | Facebook Pixel                         3 months    |\n| _fbevents        | Advertising  | Facebook Pixel                           5 months   |\n| fr                | Functional | Hotjar User ID                                2 years |\n| _hjIncludedInSample | Statistical | Hotjar Session Recording (only for the visitors being sampled)       | Session    |\n| hjid             | Functional | Hotjar User ID                                30 minutes   |\n| hjs              | Functional  | Hotjar Tracking Script               1 year     |\n| nym             | Statistical  | NewRelic Browser Monitoring                        1 month   |\n| optanon          | Functional  | Cookie Consent                     13 months   |\n| sess_exp        | Functional  | Secure Spring Web Application Framework session cookie    | Session     |\n| TS              | Strictly necessary | Cloudflare Security              2 hours    |\n| _gae          | Statistical  | Google Analytics                          90 days   |\n| _gcl_au         | Statistical  | Google Ads Conversion Tracking       90 days     |\n| fr              | Functional  | Hotjar User ID                                2 years |\n| __stripe_mid    | Functional  | Stripe Checkout Session ID            3 months    |\n\n### Controlling Cookies\n\nYou have the right to choose whether or not to accept cookies and we have explained how you can exercise this right below. However, please note that if you choose to refuse cookies you may not be able to use the full functionality of our website.\n\n#### Browser Controls:\n\nMost browsers allow you to control cookies through their settings. To find out more about cookies, including how to see what cookies have been set and how to manage and delete them, visit www.allaboutcookies.org or www.youronlinechoices.eu.\n\nTo opt out of being tracked by Google Analytics across all websites, visit tools.google.com/dlpage/gaoptout.\n\n#### User preferences:\n\nIf you have an account on this site, you can choose to manage your cookie settings at any time by visiting the Cookie Consent Tool in your user account. Once you've visited the tool, the website will remember your preferences for the duration of your browser session or you may opt-out again by deleting your cookies (see below).\n\n#### Delete cookies:\n\nIf you want to delete all cookies that are already on your computer, please refer to the instructions for your file management software to locate the file or directory that stores cookies. Please note that if you choose to delete cookies, any settings and preferences controlled by those cookies, including advertising customization, will be lost and may need to be recreated.\n\n### Contact Us:\n\nIf you have any questions about our use of cookies, please email us at [webmaster@bios.pt](mailto:webmaster@bios.pt) or contact us by mail at the following address:\n\nBIO-ImageOceanS - Bioimaging and Oceanography of the Portuguese Sea\nInstituto Português do Mar e da Atmosfera (IPMA), Edifício IPMA, Cais do Sodré, 91\n1200-375 Lisboa, Portugal.", images=None, tool_calls=None)
2025-04-04 12:56:29,743 - root - INFO - CrewAIService initialized successfully
2025-04-04 12:56:29,753 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 12:56:29,753 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 12:56:29,753 - root - INFO - PaperSearchService initialized successfully
2025-04-04 12:56:30,001 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 12:56:34,984 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 12:56:35,689 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 12:56:35,689 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 12:56:35,690 - root - INFO - QnAService initialized successfully
2025-04-04 12:56:35,690 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 12:56:35,690 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 12:56:35,690 - root - INFO - AIService initialized successfully
2025-04-04 12:56:35,691 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 12:56:35,691 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 12:56:35,691 - root - INFO - PDFService initialized successfully
2025-04-04 12:56:35,691 - root - INFO - Services initialized and passed to routes
2025-04-04 12:56:35,695 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 113.549 seconds
2025-04-04 12:56:35,697 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=27, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 12:56:35,718 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 12:57:10,167 - src.services.qna_service - INFO - Querying collection for prompt: What is machine learning?
2025-04-04 12:57:11,336 - src.services.rag_service - INFO - Search completed for query: What is machine learning?
2025-04-04 12:57:11,336 - src.services.qna_service - INFO - Query results received: 0 documents
2025-04-04 12:57:11,336 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 12:57:11,338 - src.services.qna_service - ERROR - Error re-ranking with cross encoders: list index out of range
2025-04-04 12:57:11,338 - src.services.qna_service - ERROR - Error answering question: list index out of range
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 386, in predict
    if isinstance(sentences[0], str):  # Cast an individual pair to a list with length 1
                  ~~~~~~~~~^^^
IndexError: list index out of range
2025-04-04 12:57:11,343 - src.api.routes - ERROR - Error answering question: list index out of range
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 111, in ask_question
    answer = await qna_service.answer_question(question)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 386, in predict
    if isinstance(sentences[0], str):  # Cast an individual pair to a list with length 1
                  ~~~~~~~~~^^^
IndexError: list index out of range
2025-04-04 13:08:33,343 - hypercorn.error - ERROR - Error in ASGI Framework
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/task_group.py", line 27, in _handle
    await app(scope, receive, send, sync_spawn, call_soon)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 60, in __call__
    raise_task_exceptions(done)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py", line 186, in raise_task_exceptions
    raise task.exception()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 110, in handle_request
    response = await _handle_exception(self.app, error)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 408, in _handle_exception
    raise error
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 108, in handle_request
    response = await self.app.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1468, in handle_request
    return await self.handle_exception(error)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1464, in handle_request
    return await self.full_dispatch_request(request_context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1502, in full_dispatch_request
    result = await self.handle_user_exception(error)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1059, in handle_user_exception
    raise error
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1500, in full_dispatch_request
    result = await self.dispatch_request(request_context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1597, in dispatch_request
    return await self.ensure_async(handler)(**request_.view_args)  # type: ignore[return-value]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 59, in upload_file
    if 'file' not in request.files:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'coroutine' is not iterable
2025-04-04 13:12:11,315 - hypercorn.error - ERROR - Error in ASGI Framework
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/task_group.py", line 27, in _handle
    await app(scope, receive, send, sync_spawn, call_soon)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/app_wrappers.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1735, in __call__
    await self.asgi_app(scope, receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1761, in asgi_app
    await asgi_handler(receive, send)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 60, in __call__
    raise_task_exceptions(done)
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py", line 186, in raise_task_exceptions
    raise task.exception()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 110, in handle_request
    response = await _handle_exception(self.app, error)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 408, in _handle_exception
    raise error
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py", line 108, in handle_request
    response = await self.app.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1468, in handle_request
    return await self.handle_exception(error)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1464, in handle_request
    return await self.full_dispatch_request(request_context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1502, in full_dispatch_request
    result = await self.handle_user_exception(error)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1059, in handle_user_exception
    raise error
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1500, in full_dispatch_request
    result = await self.dispatch_request(request_context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py", line 1597, in dispatch_request
    return await self.ensure_async(handler)(**request_.view_args)  # type: ignore[return-value]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 59, in upload_file
    if 'file' not in request.files:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'coroutine' is not iterable
2025-04-04 13:14:20,256 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.156 seconds
2025-04-04 13:14:20,258 - root - INFO - Starting up the application...
2025-04-04 13:14:20,258 - root - INFO - Configuration validated successfully
2025-04-04 13:14:20,258 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:14:20,270 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:14:20,403 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:14:20,403 - root - INFO - RAG service initialized successfully
2025-04-04 13:14:20,403 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:14:54,648 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 13:14:54,738 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T07:44:54.534279Z' done=True done_reason='stop' total_duration=34123163958 load_duration=4082908333 prompt_eval_count=2 prompt_eval_duration=11053956000 eval_count=334 eval_duration=18973533833 message=Message(role='assistant', content=' * [Docker](#docker)\n      + [Docker Compose](#docker-compose)\n          - [Docker Compose: Configurar Servicios en Docker](#docker-compose-configurar-servicios-en-docker)\n          - [Docker Compose: Probar el Servicio](#docker-compose-probar-el-servicio)\n      + [Docker Swarm](#docker-swarm)\n      + [Docker Machine](#docker-machine)\n\n## Docker\n\n### Docker Compose\n\n#### Docker Compose: Configurar Servicios en Docker\n\n- Crea el archivo `docker-compose.yml` con la siguiente estructura:\n\n```bash\nversion: \'3\'\nservices:\n  app:\n    image: my_app:1.0\n    container_name: my_app\n    ports:\n      - "8000:8000"\n    volumes:\n      - ./src:/app\n```\n\n- Ejecuta el comando `docker-compose up` para subir la imagen, crear el contenedor y montar los volúmenes.\n\n#### Docker Compose: Probar el Servicio\n\n- Accede a la aplicación en http://localhost:8000\n\n## Docker Swarm\n\n## Docker Machine', images=None, tool_calls=None)
2025-04-04 13:14:54,743 - root - INFO - CrewAIService initialized successfully
2025-04-04 13:14:54,751 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 13:14:54,751 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 13:14:54,751 - root - INFO - PaperSearchService initialized successfully
2025-04-04 13:14:54,880 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:15:05,559 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 13:15:06,460 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 13:15:06,460 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 13:15:06,460 - root - INFO - QnAService initialized successfully
2025-04-04 13:15:06,460 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 13:15:06,460 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 13:15:06,460 - root - INFO - AIService initialized successfully
2025-04-04 13:15:06,460 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 13:15:06,460 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 13:15:06,460 - root - INFO - PDFService initialized successfully
2025-04-04 13:15:06,460 - root - INFO - Services initialized and passed to routes
2025-04-04 13:15:06,463 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 46.204 seconds
2025-04-04 13:15:06,464 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=36, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 13:15:06,481 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 13:15:12,600 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.164 seconds
2025-04-04 13:15:12,602 - root - INFO - Starting up the application...
2025-04-04 13:15:12,602 - root - INFO - Configuration validated successfully
2025-04-04 13:15:12,602 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:15:12,614 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:15:12,722 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:15:12,722 - root - INFO - RAG service initialized successfully
2025-04-04 13:15:12,722 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:17:27,277 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 13:17:27,329 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T07:47:27.222208Z' done=True done_reason='stop' total_duration=134486707333 load_duration=16751208 prompt_eval_count=2 prompt_eval_duration=2394200667 eval_count=2348 eval_duration=132069967875 message=Message(role='assistant', content="1. The Solemnity of the Most Holy Trinity (B)\n\nThe liturgical celebration of the Blessed Trinity is a solemnity of the highest order in our Christian faith because it celebrates God’s most intimate and mysterious self-revelation: that God is one single divine nature subsisting in three Persons. The Catechism teaches us that “The most basic statement about man…is that he is called to be a son ‘in the image of God,’ after him who is 'love' (cf. 1 Jn 4:8, 16).” As adopted children of God we are also invited to live and experience communion in our families, friendships, communities and Church, mirroring the eternal life shared by the three divine Persons of the Blessed Trinity.\n\nOur Catholic faith teaches us that there is only one God but that this one God exists eternally in three persons: the Father, Son (God the Word or Second Person) and the Holy Spirit (the Third Person). There are no distinctions among these divine Persons as to their divinity, dignity, power, omnipresence, etc., but there is a distinct interplay of roles. This mystery has baffled many philosophers and theologians throughout the centuries and yet it remains at the heart of our Christian faith.\n\nToday’s Gospel passage (Jn 3:16-18) highlights God as Love. In this love relationship, the Father sends his only Son into the world to redeem mankind from sin. We are invited to believe in the One who was sent and we will have eternal life. The life of the Trinity is a communion of love, a community of love, sharing all things equally and eternally in perfect unity. This perfect unity and harmony is called perichoresis (from the Greek words peri meaning around or through, and chorein meaning dance).\n\nThe word “Trinity” comes from the Latin trinitas (threeness) and the Greek trias (tripod or three-legged support). The concept of one God existing in three persons has been debated among Christians since the earliest years after Christ. In 381 AD, the Council of Constantinople, under Emperor Theodosius, adopted a statement on the Holy Trinity, the Nicene Creed. This creed was further clarified by the First Vatican Council (1870) which taught that “the Father is God, the Son is God, and the Holy Spirit is God; and yet there are not three gods but one God.”\n\nThe doctrine of the Blessed Trinity is a mystery beyond our grasp because we cannot fully understand how one God exists in three persons. We can, however, see and experience reflections of this truth in the family life and in our community life. As children of God, we are called to reflect the love relationship of the Father, Son and Holy Spirit.\n\nIn the family, we experience a love relationship that mirrors the inner life of the Trinity. The father is the head but he is not alone. There is a mother who nurtures and loves her children with all her heart. They are one family, sharing in the same home, the same food, the same values and the same hopes and dreams for their future.\n\nSimilarly, we experience this communion of love in our Church community and as Catholics. We worship together at Mass but we also share in the common life, sharing meals, working side by side on projects and participating in various activities for spiritual growth, formation and fellowship. As members of God’s family, we are united as one community of faith, sharing the same faith, hope and love for our Lord Jesus Christ and his Church.\n\nThe Blessed Trinity is a mystery that transcends human reason. Yet, the life of the Trinity becomes a model for our own lives as members of God’s family: in marriage, in family, in community and in the Church. This eternal communion of love inspires us to be self-giving and to seek unity with others. We are called to reflect this divine love in all aspects of our human relationships, sharing, serving and loving one another as the Father, Son and Holy Spirit share their divine life together.\n\nLet us ask the Lord for an increase of faith so that we may experience more fully the communion of love in our lives and in our Church community. Let us also pray for families, especially those who are experiencing difficulties. May they rediscover and cherish the love that the Trinity has poured into their lives.\n\nFather Federico Lombardi, SJ (courtesy of Jesuit Curia press office)\n\n2. Pope Francis’s Introductory Remarks at the General Audience:\n\nDear Brothers and Sisters, Good morning!\n\nAt this time of year, we celebrate a great mystery: the Most Holy Trinity. On Sunday, in fact, we will commemorate this solemnity and, as is tradition, we will recite together the Creed, our Profession of Faith. It is important to remember what faith we have received, and to know it well, because without it we cannot truly live and experience life.\n\nThe doctrine of the Blessed Trinity — one God in three persons: the Father, the Son and the Holy Spirit — is a mystery that transcends human reason. Yet, the life of the Trinity becomes a model for our own lives as members of God’s family: in marriage, in family, in community and in the Church. This eternal communion of love inspires us to be self-giving and to seek unity with others.\n\nWe are called to reflect this divine love in all aspects of our human relationships, sharing, serving and loving one another as the Father, Son and Holy Spirit share their divine life together. Let us ask the Lord for an increase of faith so that we may experience more fully the communion of love in our lives and in our Church community.\n\nIn the name of the Father, and of the Son, and of the Holy Spirit! Amen.\n\n3. Pope Francis’s Homily at the Mass for the Solemnity of the Most Holy Trinity (11 June 2017)\n\nVatican City – In his homily during today’s Mass in Saint Peter’s Basilica, Pope Francis reflected on the “mystery of faith” that is the Holy Trinity. He said we can only understand this mystery by looking at it from the perspective of love and communion between persons. The Pope noted how our families, our communities, and even our Church community are all called to mirror the eternal relationship of love in the Blessed Trinity.\n\nThe family is a school of love, the pope said, where we learn “to give ourselves, to live in peace, to seek the common good, to care for others.” This is because the home is a place where the Father, Mother and children are united by the bonds of love and are called to share their lives with one another.\n\nThe Church community, too, must be characterized by love, he added, noting that our communion with Christ and each other strengthens us for our mission in the world. In this way, we “grow in unity, as a family, so that we can go out together to announce the Gospel, which is the good news of salvation.”\n\nAt the end of his homily, Pope Francis prayed: “Father, may we live with love and commitment in our families, among friends and in the Church community. May we be bearers of peace, witnesses of fraternity, teachers of mercy. Amen!”\n\n— — —\n\nOn this solemnity of the Most Holy Trinity, I would like to offer some thoughts on this mystery that is the foundation of our faith. The mystery of the Blessed Trinity is something that exceeds human reason; we can only understand it by looking at it from the perspective of love and communion between persons.\n\nOur families, our communities and even our Church community are all called to mirror the eternal relationship of love in the Blessed Trinity. This means living with the capacity to give ourselves, to live in peace, to seek the common good, to care for others, to serve one another and to be open to God’s action in our lives as we journey together.\n\nWe have a duty to build bridges of love, rather than walls of enmity. We must not allow our lives to become like a house that is closed up and locked; we are called to live with open doors, so that others may come in, find shelter from the storm and feel welcomed. May our homes be schools of love, where this mystery is lived out and learned!\n\nThe family is a school of love, for it is there that we learn how to give ourselves, to live in peace, to seek the common good, to care for others, to serve one another and to be open to God’s action in our lives as we journey together. Families are schools of unity: when a family loves, they grow in love, in communion, and thus they grow in their own existence, because they live their unity, which is a reflection of the eternal communion in the Blessed Trinity.\n\nThe Church community also grows in unity; it is called to be more than just a group that meets together for some activities, but rather a family that loves one another and shares life, growing together in faith and service to the world, as a sign of unity with God and with the world. In this way, we grow in unity, as a family, so that we can go out together to announce the Gospel, which is the good news of salvation.\n\nLet us ask ourselves: do I live my life like a house with open doors or one closed up and locked? Do I give myself to others in love, or am I closed off in my own comfort zone? Do I grow in unity with others, or am I focused only on my individual interests? Let us ask the Lord for the grace to become ever more united with him and with each other.\n\nLet us invoke the intercession of Mary, Our Lady of the Trinity: may she help us to be open to God’s action in our lives; may she help us to grow in love for one another, as a reflection of the eternal communion between the Father, Son and Holy Spirit. Amen!\n\n4. Pope Francis’ Prayer Intentions for July 2017: Evangelization\n\nThat all Christians, especially those living in countries where they are a minority, may be bold witnesses to their faith, with respect for others and with witness given by their actions.\n\n— — —\n\nThat the Church may joyfully propose Jesus Christ to the men and women of our time, taking care not to impose herself, but rather seeking to dialogue with every culture.", images=None, tool_calls=None)
2025-04-04 13:17:27,332 - root - INFO - CrewAIService initialized successfully
2025-04-04 13:17:27,337 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 13:17:27,337 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 13:17:27,337 - root - INFO - PaperSearchService initialized successfully
2025-04-04 13:17:27,488 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:17:30,318 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 13:17:31,221 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 13:17:31,222 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 13:17:31,222 - root - INFO - QnAService initialized successfully
2025-04-04 13:17:31,222 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 13:17:31,222 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 13:17:31,222 - root - INFO - AIService initialized successfully
2025-04-04 13:17:31,222 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 13:17:31,222 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 13:17:31,222 - root - INFO - PDFService initialized successfully
2025-04-04 13:17:31,222 - root - INFO - Services initialized and passed to routes
2025-04-04 13:17:31,225 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 138.622 seconds
2025-04-04 13:17:31,226 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=39, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 13:17:31,250 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 13:17:38,754 - src.services.pdf_service - INFO - Starting text extraction from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 13:17:38,755 - src.services.pdf_service - ERROR - Error extracting text from PDF: uploads/10.1371journal.pone.0231708.pdf
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 42, in extract_text_from_pdf
    text = await asyncio.to_thread(extract)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 37, in extract
    if end_page is None:
       ^^^^^^^^
UnboundLocalError: cannot access local variable 'end_page' where it is not associated with a value
2025-04-04 13:17:38,759 - src.api.routes - ERROR - Error processing uploaded file: Error extracting text from PDF: cannot access local variable 'end_page' where it is not associated with a value
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 42, in extract_text_from_pdf
    text = await asyncio.to_thread(extract)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 37, in extract
    if end_page is None:
       ^^^^^^^^
UnboundLocalError: cannot access local variable 'end_page' where it is not associated with a value

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 80, in upload_file
    text = await extract_text_from_pdf(filepath)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 58, in extract_text_from_pdf
    raise RuntimeError(f"Error extracting text from PDF: {str(e)}")
RuntimeError: Error extracting text from PDF: cannot access local variable 'end_page' where it is not associated with a value
2025-04-04 13:26:34,711 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.162 seconds
2025-04-04 13:26:34,713 - root - INFO - Starting up the application...
2025-04-04 13:26:34,714 - root - INFO - Configuration validated successfully
2025-04-04 13:26:34,714 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:26:34,726 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:26:34,852 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:26:34,852 - root - INFO - RAG service initialized successfully
2025-04-04 13:26:34,852 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:28:21,485 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.152 seconds
2025-04-04 13:28:21,487 - root - INFO - Starting up the application...
2025-04-04 13:28:21,487 - root - INFO - Configuration validated successfully
2025-04-04 13:28:21,487 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:28:21,499 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:28:21,624 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:28:21,624 - root - INFO - RAG service initialized successfully
2025-04-04 13:28:21,624 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:28:46,752 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 13:28:46,762 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T07:58:46.739998Z' done=True done_reason='stop' total_duration=25102583417 load_duration=16278500 prompt_eval_count=2 prompt_eval_duration=5167285083 eval_count=364 eval_duration=19915518583 message=Message(role='assistant', content=' <template>\n    <div class="container">\n      <h2>Todos:</h2>\n      <ul>\n        <li v-for="todo in todos" :key="todo.id">{{ todo.text }}</li>\n      </ul>\n      <input type="text" v-model="newTodo" @keyup.enter="addNewTodo" />\n    </div>\n  </template>\n\n  <script setup lang="ts">\n  import { ref } from \'vue\'\n\n  const newTodo = ref(\'\')\n  const todos = ref([\n    { id: 1, text: \'Learn JavaScript\' },\n    { id: 2, text: \'Learn Vue.js\' },\n  ])\n\n  function addNewTodo() {\n    if (newTodo.value.trim()) {\n      todos.value.push({ id: Date.now(), text: newTodo.value })\n      newTodo.value = \'\'\n    }\n  }\n  </script>\n\n<style scoped>\n  .container {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n  }\n\n  ul {\n    list-style-type: none;\n    padding: 0;\n    margin: 20px 0;\n  }\n\n  input[type="text"] {\n    width: 300px;\n    padding: 5px;\n    font-size: 16px;\n  }\n</style>', images=None, tool_calls=None)
2025-04-04 13:28:46,762 - root - INFO - CrewAIService initialized successfully
2025-04-04 13:28:46,762 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 13:28:46,762 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 13:28:46,762 - root - INFO - PaperSearchService initialized successfully
2025-04-04 13:28:46,796 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:28:56,693 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 13:28:57,644 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 13:28:57,645 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 13:28:57,645 - root - INFO - QnAService initialized successfully
2025-04-04 13:28:57,645 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 13:28:57,645 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 13:28:57,645 - root - INFO - AIService initialized successfully
2025-04-04 13:28:57,645 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 13:28:57,645 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 13:28:57,645 - root - INFO - PDFService initialized successfully
2025-04-04 13:28:57,645 - root - INFO - Services initialized and passed to routes
2025-04-04 13:28:57,648 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 36.164 seconds
2025-04-04 13:28:57,650 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=27, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 13:28:57,657 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 13:29:07,669 - src.services.pdf_service - INFO - Starting text extraction from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 13:29:07,670 - src.services.pdf_service - ERROR - Error extracting text from PDF: uploads/10.1371journal.pone.0231708.pdf
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 42, in extract_text_from_pdf
    text = await asyncio.to_thread(extract)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 37, in extract
    if end_page is None:
       ^^^^^^^^
UnboundLocalError: cannot access local variable 'end_page' where it is not associated with a value
2025-04-04 13:29:07,672 - src.api.routes - ERROR - Error processing uploaded file: Error extracting text from PDF: cannot access local variable 'end_page' where it is not associated with a value
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 42, in extract_text_from_pdf
    text = await asyncio.to_thread(extract)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 37, in extract
    if end_page is None:
       ^^^^^^^^
UnboundLocalError: cannot access local variable 'end_page' where it is not associated with a value

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 84, in upload_file
    text = await pdf_service.extract_text_from_pdf(filepath)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 58, in extract_text_from_pdf
    raise RuntimeError(f"Error extracting text from PDF: {str(e)}")
RuntimeError: Error extracting text from PDF: cannot access local variable 'end_page' where it is not associated with a value
2025-04-04 13:32:46,040 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.155 seconds
2025-04-04 13:32:46,042 - root - INFO - Starting up the application...
2025-04-04 13:32:46,042 - root - INFO - Configuration validated successfully
2025-04-04 13:32:46,042 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:32:46,056 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:32:46,182 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:32:46,182 - root - INFO - RAG service initialized successfully
2025-04-04 13:32:46,182 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:36:31,476 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.152 seconds
2025-04-04 13:36:31,478 - root - INFO - Starting up the application...
2025-04-04 13:36:31,478 - root - INFO - Configuration validated successfully
2025-04-04 13:36:31,478 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:36:31,489 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:36:31,606 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:36:31,606 - root - INFO - RAG service initialized successfully
2025-04-04 13:36:31,606 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:37:41,806 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 13:37:41,923 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:07:41.648784Z' done=True done_reason='stop' total_duration=70030316166 load_duration=20045416 prompt_eval_count=2 prompt_eval_duration=2041756834 eval_count=1242 eval_duration=67957922541 message=Message(role='assistant', content="1.  What is the most effective way to increase your overall productivity?\n\nTo increase overall productivity, consider implementing these strategies:\n\n- Time Management: Prioritize tasks based on their importance and urgency. Use tools like calendars, planners, or apps to organize your schedule effectively.\n\n- Breaks and Rest: Regular breaks can help prevent burnout and improve focus when you return to work. The Pomodoro Technique is a popular method that involves working for 25 minutes, followed by a 5-minute break.\n\n- Minimize Distractions: Create a workspace free of distractions, use noise-cancelling headphones, or turn off notifications on your devices during focused work periods.\n\n- Focus and Avoid Multitasking: Concentrate on one task at a time to maintain productivity levels. Multitasking can lead to errors and reduce the quality of work.\n\n- Delegate Tasks: If possible, delegate tasks to others who have the necessary skills to complete them efficiently. This allows you to focus on higher-priority tasks.\n\n- Continuous Learning: Keep yourself updated with new tools, techniques, and best practices in your field to stay productive and competitive.\n\n- Exercise and Eat Healthy: Regular exercise boosts energy levels and helps maintain mental clarity, while eating a balanced diet supports optimal physical and cognitive function.\n\n2.  How can I make the most of my commute time?\n\nYou can make your commuting time productive in several ways:\n\n- Listen to Educational Podcasts or Audiobooks: This is an excellent opportunity to learn new things, broaden your knowledge, and develop skills related to your profession.\n\n- Read Books or Articles: If you prefer a more stationary medium, bring along a book or magazine that interests you.\n\n- Brainstorm Ideas or Plan Your Day: Use this time to think about work-related problems, brainstorm solutions, or plan your day ahead.\n\n- Meditate or Practice Mindfulness: Commuting can be stressful, and taking a few moments for mindfulness practice can help you arrive at your destination calm and focused.\n\n- Take Online Courses: Use platforms like Coursera, edX, or LinkedIn Learning to learn new skills or advance in your career during your commute.\n\n3.  What are some effective strategies for managing stress?\n\nStress management techniques can vary based on individual preferences and circumstances. Here are a few strategies that have shown positive results:\n\n- Deep Breathing: Focus on breathing deeply, slowly, and consistently to reduce feelings of anxiety and calm your mind.\n\n- Progressive Muscle Relaxation: Systematically tense and relax each muscle group in your body, starting from your toes and working your way up to the top of your head.\n\n- Exercise Regularly: Physical activity is a powerful stress reliever that boosts your mood and energy levels while reducing feelings of anxiety.\n\n- Mindfulness and Meditation: Practice mindfulness techniques like meditation or yoga to stay centered, focused, and maintain emotional balance.\n\n- Social Support: Connect with friends, family, or support groups to discuss stressors and share coping strategies.\n\n- Limit Caffeine and Alcohol Intake: These substances can exacerbate feelings of anxiety and disrupt sleep patterns, leading to increased stress levels.\n\n- Prioritize Self-care: Make time for activities that bring you joy and relaxation, such as reading, listening to music, or taking a bath.\n\n4.  How can I improve my public speaking skills?\n\nTo enhance your public speaking abilities, consider the following tips:\n\n- Practice Speaking in Front of Others: Join a Toastmasters group or find other opportunities to present regularly. This will help build confidence and refine your delivery style.\n\n- Know Your Audience: Tailor your speech to your audience's interests and needs, using language that resonates with them.\n\n- Structure Your Speech Properly: Use an introduction, main points, and conclusion to guide your audience through the content.\n\n- Use Visual Aids Effectively: Use images, charts, or slides to support your key points and keep the audience engaged.\n\n- Practice Beforehand: Rehearse your speech multiple times to become familiar with the material and reduce nerves on the day of the presentation.\n\n- Embrace Imperfections: Understand that everyone makes mistakes when speaking in public, and remember that it's okay to stumble occasionally. Focus on delivering your message effectively rather than being flawless.\n\n5.  What are some tips for effective time management?\n\nEffective time management can help you accomplish more in less time:\n\n- Set Clear Goals: Determine what needs to be done and when, based on priorities and deadlines. Break larger tasks into smaller, manageable chunks.\n\n- Prioritize Tasks: Use the Eisenhower Matrix or other prioritization methods to organize your workload effectively.\n\n- Schedule Regular Breaks: Taking breaks can help prevent burnout and improve focus when you return to work. The Pomodoro Technique is a popular method that involves working for 25 minutes, followed by a 5-minute break.\n\n- Minimize Distractions: Create a workspace free of distractions, use noise-cancelling headphones, or turn off notifications on your devices during focused work periods.\n\n- Learn to Say No: Understand your limits and don't overcommit yourself. It's essential to protect your time for essential tasks and personal well-being.\n\n- Use Tools and Apps: Explore productivity tools like calendars, planners, or apps to help you stay organized and manage your time efficiently.", images=None, tool_calls=None)
2025-04-04 13:37:41,929 - root - INFO - CrewAIService initialized successfully
2025-04-04 13:37:41,941 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 13:37:41,941 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 13:37:41,942 - root - INFO - PaperSearchService initialized successfully
2025-04-04 13:37:42,126 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:37:44,982 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 13:37:45,712 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 13:37:45,713 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 13:37:45,713 - root - INFO - QnAService initialized successfully
2025-04-04 13:37:45,713 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 13:37:45,713 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 13:37:45,713 - root - INFO - AIService initialized successfully
2025-04-04 13:37:45,713 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 13:37:45,713 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 13:37:45,713 - root - INFO - PDFService initialized successfully
2025-04-04 13:37:45,713 - root - INFO - Services initialized and passed to routes
2025-04-04 13:37:45,717 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 74.238 seconds
2025-04-04 13:37:45,719 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=27, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 13:37:45,748 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 13:38:10,173 - src.services.pdf_service - INFO - Starting text extraction from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 13:38:10,298 - src.services.pdf_service - INFO - Successfully extracted and cleaned text from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 13:38:11,530 - src.services.rag_service - INFO - Document stored successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 13:38:11,642 - asyncio - WARNING - Executing <Task pending name='Task-11' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.111 seconds
2025-04-04 13:38:17,417 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.176 seconds
2025-04-04 13:38:19,570 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 13:45:07,229 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.353 seconds
2025-04-04 13:45:07,485 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.214 seconds
2025-04-04 13:45:07,515 - src.services.rag_service - INFO - Batch storage successful for 229 documents
2025-04-04 13:45:07,519 - src.services.qna_service - INFO - Added 229 document chunks to RAG for file: 10.1371journal.pone.0231708.pdf
2025-04-04 13:45:07,543 - src.api.routes - INFO - File uploaded and processed successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 13:45:07,674 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.167 seconds
2025-04-04 13:48:12,585 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 13:48:12,693 - asyncio - WARNING - Executing <Task pending name='Task-19' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.113 seconds
2025-04-04 13:48:13,496 - src.services.rag_service - INFO - Search completed for query: What is the main topic of this paper?
2025-04-04 13:48:13,497 - src.services.qna_service - INFO - Query results received: 10 documents
2025-04-04 13:48:13,497 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 13:48:13,687 - src.services.qna_service - ERROR - Error re-ranking with cross encoders: TextInputSequence must be str
2025-04-04 13:48:13,687 - src.services.qna_service - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 13:48:13,715 - src.api.routes - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 117, in ask_question
    answer = await qna_service.answer_question(question)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 13:48:13,735 - asyncio - WARNING - Executing <Task finished name='Task-19' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.238 seconds
2025-04-04 13:51:55,176 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.169 seconds
2025-04-04 13:51:55,178 - root - INFO - Starting up the application...
2025-04-04 13:51:55,178 - root - INFO - Configuration validated successfully
2025-04-04 13:51:55,178 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 13:51:55,190 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:51:55,275 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 13:51:55,275 - root - INFO - RAG service initialized successfully
2025-04-04 13:51:55,275 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 13:53:50,831 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 13:53:50,863 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:23:50.79267Z' done=True done_reason='stop' total_duration=115509401334 load_duration=3838079417 prompt_eval_count=2 prompt_eval_duration=8482265541 eval_count=1864 eval_duration=103186301292 message=Message(role='assistant', content='1. 05:39\n\n### MARAUDERS Trailer (2020) Bruce Willis, Chris Evans Movie HD\n\nWatch the new trailer for Marauders, starring Bruce Willis, Christopher Smith, and Chris Evans! In Theaters and On Demand April 17, 2020. #MaraudersMovie\n\nwww.youtube.com\n\n2. 00:30\n\n### Marauders (2020) - Official Trailer [HD] | Bruce Willis, Chris Evans | A24\n\nA group of unsuspecting employees find themselves caught in the cross hairs of a series of deadly robberies orchestrated by a mysterious and ruthless criminal known only as The Rook. As the loot from the robberies is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects th...\n\nwww.youtube.com\n\n3. 05:06\n\n### Marauders Trailer (2020) Bruce Willis, Christopher Smith, Chris Evans Movie HD - IGN\n\nFor more trailers and clips, go to https://www.ign.com/videos Subscribe to IGN on YouTube: http://bit.ly/IGN_Subscribe Watch all the latest trailers for movies, games and TV shows: http://youtu.be/VZ6pzKtYqcM Join IGN: https://www.ign.com IGN is your source for exciting videos, game trailers, and gameplay footage from the...\n\nwww.youtube.com\n\n4. 03:08\n\n### The Rook (Marauders) - Official Trailer [HD] | Bruce Willis, Christopher Smith, Chris Evans | A24\n\nA mysterious criminal known only as The Rook is orchestrating a series of brutal bank robberies, leaving a trail of destruction in his wake. As the loot from these raids is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects something is amiss and takes matters into his own hands...\n\nwww.youtube.com\n\n5. 02:43\n\n### Marauders Movie Clip - The First Heist [HD] | Bruce Willis, Christopher Smith, Chris Evans | A24\n\nSubscribe to A24 Films: http://bit.ly/A24Subscribe | http://smarturl.it/Marauders_A24 Website: http://www.a24films.com Twitter: https://twitter.com/A24 Facebook: https://www.facebook.com/A24 Follow Marauders on Instagram: https://www.instagram.com/Maraudersmovie/ In Theaters and On Demand April 17,...\n\nwww.youtube.com\n\n6. 00:30\n\n### The Rook (Official Trailer) | Marauders Movie - A24 Films\n\nIn Theaters & On Demand April 17, 2020 A mysterious criminal known only as The Rook is orchestrating a series of brutal bank robberies, leaving a trail of destruction in his wake. As the loot from these raids is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects something is...\n\nwww.youtube.com\n\n7. 02:15\n\n### Marauders - The Rook Is Watching (Official Teaser) | Bruce Willis Movie - A24 Films\n\nA mysterious criminal known only as The Rook is orchestrating a series of brutal bank robberies, leaving a trail of destruction in his wake. As the loot from these raids is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects something is amiss and takes matters into his own hands...\n\nwww.youtube.com\n\n8. 01:49\n\n### Marauders - Inside Look | Bruce Willis Movie | A24 Films\n\nIn Theaters and On Demand April 17, 2020. Check out this inside look at Marauders, starring Bruce Willis and Christopher Smith. Directed by Steven C. Miller.\n\nwww.youtube.com\n\n9. 03:14\n\n### Marauders - Trailer Tease | Chris Evans Movie - A24 Films\n\nMarauders - In Theaters April 17, 2020. Check out this trailer tease for Marauders, starring Chris Evans. Directed by Steven C. Miller.\n\nwww.youtube.com\n\n10. 03:09\n\n### Marauders Trailer (2020) Bruce Willis Movie HD - The Action Lab\n\nMarauders releases in theaters on April 17, 2020. Starring Bruce Willis, Christopher Smith, and Chris Evans, with Steven C. Miller as Director. Subscribe for more trailers & clips: http://smarturl.it/TALYouTube Follow us: https://www.instagram.com/TheActionLab/\n\nwww.youtube.com\n\n11. 05:43\n\n### Marauders | Official Trailer HD | Bruce Willis, Chris Evans | A24 Films\n\nIn Theaters April 17 and On Demand the same day! Subscribe to A24 Films: http://bit.ly/A24Subscribe | http://smarturl.it/Marauders_A24 Website: http://www.a24films.com Twitter: https://twitter.com/A24 Facebook: https://www.facebook.com/A24 Follow Marauders on Instagram: https://www.instagram.com/M...\n\nwww.youtube.com\n\n12. 05:36\n\n### Official Trailer for Marauders (2020) - A24\n\nMarauders in theaters April 17, 2020 and On Demand the same day! Subscribe to A24 Films: http://bit.ly/A24Subscribe | http://smarturl.it/Marauders_A24 Website: http://www.a24films.com Twitter: https://twitter.com/A24 Facebook: https://www.facebook.com/A24 Follow Marauders on Instagram: https://www.instagram...\n\nwww.youtube.com\n\n13. 02:28\n\n### A24 Films | Marauders - The Rook Is Watching (Official Trailer) HD | Bruce Willis Movie\n\nA mysterious criminal known only as The Rook is orchestrating a series of brutal bank robberies, leaving a trail of destruction in his wake. As the loot from these raids is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects something is amiss and takes matters into his own hands...\n\nwww.youtube.com\n\n14. 01:59\n\n### Marauders (2020) Official Trailer | A24 Films\n\nIn Theaters April 17, 2020 and On Demand the same day! Subscribe to A24 Films: http://bit.ly/A24Subscribe | http://smarturl.it/Marauders_A24 Website: http://www.a24films.com Twitter: https://twitter.com/A24 Facebook: https://www.facebook.com/A24 Follow Marauders on Instagram: https://www.instagram...\n\nwww.youtube.com\n\n15. 01:36\n\n### Marauders (2020) - Official Trailer [HD] | Bruce Willis, Christopher Smith, Chris Evans | A24\n\nA mysterious criminal known only as The Rook is orchestrating a series of brutal bank robberies, leaving a trail of destruction in his wake. As the loot from these raids is delivered to a staging ground, one employee, Scott (Bruce Willis), suspects something is amiss and takes matters into his own hands...\n\nwww.youtube.com', images=None, tool_calls=None)
2025-04-04 13:53:50,866 - root - INFO - CrewAIService initialized successfully
2025-04-04 13:53:50,875 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 13:53:50,875 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 13:53:50,875 - root - INFO - PaperSearchService initialized successfully
2025-04-04 13:53:50,964 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 13:54:00,309 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 13:54:08,312 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 13:54:08,313 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 13:54:08,313 - root - INFO - QnAService initialized successfully
2025-04-04 13:54:08,313 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 13:54:08,313 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 13:54:08,313 - root - INFO - AIService initialized successfully
2025-04-04 13:54:08,341 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 13:54:08,341 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 13:54:08,341 - root - INFO - PDFService initialized successfully
2025-04-04 13:54:08,341 - root - INFO - Services initialized and passed to routes
2025-04-04 13:54:08,346 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 133.167 seconds
2025-04-04 13:54:08,349 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=49, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 13:54:08,369 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 13:54:17,238 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 13:54:18,633 - src.services.rag_service - INFO - Search completed for query: What is the main topic of this paper?
2025-04-04 13:54:18,634 - src.services.qna_service - INFO - Query results received: 10 documents
2025-04-04 13:54:18,634 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 13:54:18,637 - src.services.qna_service - ERROR - Error re-ranking with cross encoders: TextInputSequence must be str
2025-04-04 13:54:18,637 - src.services.qna_service - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 13:54:18,644 - src.api.routes - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 117, in ask_question
    answer = await qna_service.answer_question(question)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 152, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 126, in re_rank_cross_encoders
    ranks = self.cross_encoder.rank(prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 13:54:24,618 - src.services.pdf_service - ERROR - Error checking PDF validity: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 13:54:24,618 - src.api.routes - WARNING - Invalid PDF file attempted: 10.1371journal.pone.0231708.pdf
2025-04-04 14:00:21,098 - src.services.pdf_service - ERROR - Error checking PDF validity: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:00:21,098 - src.api.routes - WARNING - Invalid PDF file attempted: 10.1371journal.pone.0231708.pdf
2025-04-04 14:00:46,695 - src.services.pdf_service - ERROR - Error checking PDF validity: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:00:46,695 - src.api.routes - WARNING - Invalid PDF file attempted: 10.1371journal.pone.0231708.pdf
2025-04-04 14:03:38,152 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.156 seconds
2025-04-04 14:03:38,154 - root - INFO - Starting up the application...
2025-04-04 14:03:38,154 - root - INFO - Configuration validated successfully
2025-04-04 14:03:38,154 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:03:38,166 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:03:38,297 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:03:38,297 - root - INFO - RAG service initialized successfully
2025-04-04 14:03:38,297 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:04:28,819 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:04:28,846 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:34:28.761116Z' done=True done_reason='stop' total_duration=50456638042 load_duration=4340625542 prompt_eval_count=2 prompt_eval_duration=12828888750 eval_count=617 eval_duration=33276864792 message=Message(role='assistant', content=" In 1957 a group of parents decided to form an organization to raise funds for a school that would teach their children in the classical tradition. They chose a name, The Classical School Association, and filed the articles of incorporation with the State of Ohio on March 6th of that year.\n\n   In June of 1957, the Board of Education granted them a charter to establish a school under the name of The Western Reserve Academy for Girls (later changed to The Western Reserve School for Girls). The first classes began in September of 1957 with twenty students in grades one through six. The initial faculty consisted of Mrs. Richard P. Hanna, Mrs. James McMichael, Miss Ann Miller, and a part-time teacher, Mrs. John Ritter.\n\n   In the spring of 1960, the Board of Education granted a charter to The Classical School Association for an academy level school for boys and girls under the name of Western Reserve Academy (WRA). This new program was designed to teach students in grades seven through twelve under the guidance of two full-time faculty members.\n\n   In 1967, the Academy level school moved into its own building at 3045 Fairmount Boulevard, which had been purchased from the University School and extensively remodeled. The Classical School continued at its original location until it was sold in 1972 to provide funds for a new building for WRA on the current site.\n\n   By this time, the school's name had changed from Western Reserve Academy to The Western Reserve School (WRS). In 1973, the Board of Education granted the school permission to include grades kindergarten and pre-kindergarten as part of its program. In 1984, WRS purchased property at 2500 Fairmount Boulevard, which is now the current location for both the Academy and PreK-6 divisions.\n\n   During the early years of the school, many parents were teachers in other schools during the day but would come to Western Reserve in the evenings to teach classes or serve on various committees. The Classical School Association was a volunteer organization staffed by parents who did everything from fundraising to teaching, and it continued to function that way until 1974 when WRS hired its first full-time teachers.\n\n   Throughout the years, the faculty has grown from seven teachers in 1958 to over sixty today, including several full-time support staff members.\n\n   The mission of Western Reserve School is to provide a challenging and nurturing environment for students so that they may develop their unique talents in an atmosphere of discipline, excellence, and personal responsibility. Our school has provided this kind of education for nearly fifty years, and we look forward to continuing our tradition of academic excellence in the years to come.", images=None, tool_calls=None)
2025-04-04 14:04:28,847 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:04:28,850 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:04:28,850 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:04:28,850 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:04:28,972 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:04:34,410 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:04:44,976 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:04:44,977 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:04:44,977 - root - INFO - QnAService initialized successfully
2025-04-04 14:04:44,977 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:04:44,977 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:04:44,977 - root - INFO - AIService initialized successfully
2025-04-04 14:04:45,000 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:04:45,001 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:04:45,001 - root - INFO - PDFService initialized successfully
2025-04-04 14:04:45,001 - root - INFO - Services initialized and passed to routes
2025-04-04 14:04:45,005 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 66.851 seconds
2025-04-04 14:04:45,008 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:04:45,027 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:05:16,702 - src.services.pdf_service - ERROR - Unexpected error checking PDF validity: uploads/10.1371journal.pone.0231708.pdf. Error: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 79, in is_valid_pdf
    is_valid = await asyncio.get_event_loop().run_in_executor(self.executor, check)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
2025-04-04 14:05:16,702 - src.api.routes - WARNING - Invalid PDF file attempted: 10.1371journal.pone.0231708.pdf
2025-04-04 14:06:23,946 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.169 seconds
2025-04-04 14:06:23,947 - root - INFO - Starting up the application...
2025-04-04 14:06:23,947 - root - INFO - Configuration validated successfully
2025-04-04 14:06:23,947 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:06:23,960 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:06:24,021 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:06:24,021 - root - INFO - RAG service initialized successfully
2025-04-04 14:06:24,021 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:06:59,302 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:06:59,387 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:36:59.114512Z' done=True done_reason='stop' total_duration=35087471917 load_duration=17251875 prompt_eval_count=2 prompt_eval_duration=8301926875 eval_count=424 eval_duration=26756884542 message=Message(role='assistant', content=' The first of a series of three events dedicated to the exploration of innovative practices in European higher education.\n\nEUNIS 2014 was the first edition of an annual event organised by EUNIS – The European University Information Systems Association, dedicated to exploring the new trends and challenges faced by the higher education community in the digital era. The conference gathered leaders from universities and research institutions, public authorities, IT industry representatives, educators and students from all over Europe.\n\nThe event was divided into three parts:\n\n- A two day conference – June 24^{th}-25^{th} – where the main challenge for participants was to identify and discuss new trends in higher education. The agenda covered a broad range of topics, such as: the digital transformation of universities; student mobility, data privacy and security; or the role of information systems in fostering innovation and cooperation.\n- A student competition – June 24^{th} – where students from all over Europe were invited to present innovative projects and ideas that could have a significant impact on the way universities operate. The three finalist teams had the opportunity to compete for a prize of €10,000 in order to develop their project further.\n- An information technology exhibition – June 25^{th} – where more than thirty exhibitors showcased their innovative solutions, focusing on software applications, mobile devices and network infrastructure that could help universities improve the quality of services they offer to students and staff. The main focus was on practical demonstrations, enabling participants to experience first-hand how these tools can be used in educational environments.\n\nThe three winning ideas in the student competition were:\n\n1st Prize – €5,000 -  “Synapta – An Interdisciplinary Learning Platform”\n\n2nd Prize – €3,000 - “i-Minds – an intelligent mobile app for mind mapping”\n\n3rd Prize – €2,000 - “University of the Future Mobile App”', images=None, tool_calls=None)
2025-04-04 14:06:59,391 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:06:59,402 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:06:59,402 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:06:59,402 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:06:59,641 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:07:09,274 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:07:29,713 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:07:29,714 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:07:29,714 - root - INFO - QnAService initialized successfully
2025-04-04 14:07:29,714 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:07:29,715 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:07:29,715 - root - INFO - AIService initialized successfully
2025-04-04 14:07:29,744 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:07:29,745 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:07:29,745 - root - INFO - PDFService initialized successfully
2025-04-04 14:07:29,745 - root - INFO - Services initialized and passed to routes
2025-04-04 14:07:29,749 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 65.801 seconds
2025-04-04 14:07:29,751 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=49, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:07:29,771 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:07:34,494 - src.services.pdf_service - ERROR - Unexpected error checking PDF validity: uploads/10.1371journal.pone.0231708.pdf. Error: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 79, in is_valid_pdf
    is_valid = await asyncio.get_event_loop().run_in_executor(self.executor, check)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.is_valid_pdf.<locals>.check'
2025-04-04 14:07:34,495 - src.api.routes - WARNING - Invalid PDF file attempted: 10.1371journal.pone.0231708.pdf
2025-04-04 14:17:15,398 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.156 seconds
2025-04-04 14:17:15,400 - root - INFO - Starting up the application...
2025-04-04 14:17:15,400 - root - INFO - Configuration validated successfully
2025-04-04 14:17:15,400 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:17:15,411 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:17:15,522 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:17:15,522 - root - INFO - RAG service initialized successfully
2025-04-04 14:17:15,522 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:17:39,833 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:17:39,857 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:47:39.795843Z' done=True done_reason='stop' total_duration=24266547500 load_duration=4085157541 prompt_eval_count=2 prompt_eval_duration=10305557792 eval_count=176 eval_duration=9869637791 message=Message(role='assistant', content='\t$(document).ready(function(){\n    //  $(\'#btn-save\').click(function(){\n    //      var text = \'The date is:\';\n    //      var today= new Date();\n    //      var dd = String(today.getDate()).padStart(2, \'0\');\n    //      var mm = String(today.getMonth() + 1).padStart(2, \'0\'); //January is 0!\n    //      var yyyy = today.getFullYear();\n\n    //      today = yyyy+\'-\'+mm+\'-\'+dd;\n\n    //      console.log(today);\n    //      document.getElementById("txtDate").value = text + " " + today;\n    //  });\n});', images=None, tool_calls=None)
2025-04-04 14:17:39,858 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:17:39,860 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:17:39,860 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:17:39,860 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:17:39,908 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:17:51,642 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:17:56,237 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:17:56,238 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:17:56,238 - root - INFO - QnAService initialized successfully
2025-04-04 14:17:56,238 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:17:56,238 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:17:56,238 - root - INFO - AIService initialized successfully
2025-04-04 14:17:56,266 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:17:56,266 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:17:56,266 - root - INFO - PDFService initialized successfully
2025-04-04 14:17:56,267 - root - INFO - Services initialized and passed to routes
2025-04-04 14:17:56,269 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 40.869 seconds
2025-04-04 14:17:56,271 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=57, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:17:56,285 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:19:54,998 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.159 seconds
2025-04-04 14:19:55,000 - root - INFO - Starting up the application...
2025-04-04 14:19:55,000 - root - INFO - Configuration validated successfully
2025-04-04 14:19:55,000 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:19:55,012 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:19:55,138 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:19:55,138 - root - INFO - RAG service initialized successfully
2025-04-04 14:19:55,138 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:21:04,149 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:21:04,165 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T08:51:04.11667Z' done=True done_reason='stop' total_duration=68970000291 load_duration=15545708 prompt_eval_count=2 prompt_eval_duration=4549066042 eval_count=1220 eval_duration=64398004000 message=Message(role='assistant', content="1. In the case where an individual is convicted for a serious offense such as sexual assault, armed robbery or homicide and receives a long prison sentence. How does the prison system determine their placement within the prison?\n\nIn the United States, the prison system typically uses a risk assessment tool to determine the initial placement of inmates upon entering prison. This tool takes into account factors such as the crime committed, prior criminal history, and any protective or safety concerns. Once an individual is placed in a facility, they may be reassigned based on various factors, including their behavior within the prison, security level of the offense, and available programs and resources. It's important to note that this process can vary significantly between different states and even individual prisons.\n\n2. Considering the same scenario as above, how does the prison system ensure the safety of inmates who are victims of sexual assault?\n\nPrison systems implement various strategies to protect inmates who have been victimized by sexual assault. These include:\n\n- Segregation or protective custody for victims\n- Implementing zero-tolerance policies regarding sexual misconduct\n- Providing training for staff on recognizing signs of abuse and reporting procedures\n- Offering counseling services for victims\n- Establishing confidential reporting mechanisms\n- Enforcing strict search and control procedures to prevent contraband (such as weapons or drugs) from entering the facility\n- Implementing sex offender management programs\n\n3. What is a 'good time' law in prison system? How does it work?\n\nGood Time Laws, also known as Earned Time Laws, are statutes that allow inmates to serve less than their full sentence by earning credits for good behavior and participation in rehabilitative programs while incarcerated. These credits can be applied towards reductions in the length of the prison term or early release.\n\nThe specific rules governing Good Time Laws vary from one jurisdiction to another, but common elements include:\n\n- Inmates earn a certain number of days (or percentage) off their sentence for each day served without disciplinary infractions\n- Inmates can also earn credits for completing rehabilitative programs, such as vocational training or substance abuse treatment\n- Some jurisdictions may deduct time from an inmate's good time if they are assigned to disciplinary segregation (isolation)\n- Good Time Laws do not apply to life sentences or certain other offenses, such as murder and violent crimes\n\n4. In the case of a long-term prisoner, how does the prison system handle their healthcare needs?\n\nPrison systems have a responsibility to provide adequate medical care for inmates. While the specifics can vary, common practices include:\n\n- Regular health screenings and checkups\n- Treatment for acute and chronic conditions (such as diabetes or heart disease)\n- Mental health services, including counseling and medication management\n- Dental care\n- Access to medications prescribed by medical staff\n- Emergency care in case of accidents or illnesses\n\n5. How does the prison system address mental health issues among inmates?\n\nPrison systems aim to identify and treat mental health issues among inmates, although resources can be limited. Common practices include:\n\n- Regular mental health screenings for all inmates upon admission and at regular intervals thereafter\n- Access to medication and counseling services for diagnosed mental health conditions\n- Group therapy sessions focusing on coping skills, stress management, and anger management\n- Specialized programs for inmates with severe mental illnesses or substance abuse issues\n- Training for staff on recognizing signs of mental health distress and providing appropriate responses\n- Collaboration between prison mental health professionals and community mental health providers to ensure continuity of care upon release\n\n6. Can a prisoner's sentence be shortened due to good behavior or participation in rehabilitative programs?\n\nYes, as mentioned earlier, Good Time Laws allow for the reduction of a prisoner's sentence through good behavior and participation in rehabilitative programs while incarcerated. The specific rules governing these laws vary from one jurisdiction to another. Some states may also offer parole or early release for certain offenders based on their conduct and completion of rehabilitative programs.\n\n7. How does the prison system handle the reentry of prisoners back into society?\n\nPrison systems work with various agencies, non-profits, and community organizations to provide support services for prisoners reentering society. These may include:\n\n- Preparation for release, including job training and life skills classes\n- Connection to housing and employment resources upon release\n- Case management services to help navigate the challenges of reentry, such as finding a job and obtaining identification documents\n- Mental health and substance abuse treatment programs\n- Reintegration programs that offer ongoing support and guidance for former prisoners during their first few months or years after release\n\n8. What is a 'three strikes' law, and how does it work?\n\nThree Strikes Laws are criminal sentencing laws that mandate harsher penalties for repeat offenders with multiple felony convictions. The specifics can vary between jurisdictions, but common elements include:\n\n- A third felony conviction results in a significantly longer prison sentence (often 25 years to life) compared to the sentences for the first two offenses\n- Some Three Strikes Laws require that all three convictions be for violent crimes or serious felonies, while others apply to any type of felony\n- In some cases, a third conviction can result in life imprisonment without parole\n- Some jurisdictions have modified Three Strikes Laws to focus on violent offenses only or to provide more flexibility in sentencing for non-violent offenses", images=None, tool_calls=None)
2025-04-04 14:21:04,166 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:21:04,168 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:21:04,168 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:21:04,168 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:21:04,208 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:21:16,544 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:21:18,101 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:21:18,101 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:21:18,101 - root - INFO - QnAService initialized successfully
2025-04-04 14:21:18,102 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:21:18,102 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:21:18,102 - root - INFO - AIService initialized successfully
2025-04-04 14:21:18,129 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:21:18,130 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:21:18,130 - root - INFO - PDFService initialized successfully
2025-04-04 14:21:18,131 - root - INFO - Services initialized and passed to routes
2025-04-04 14:21:18,135 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 83.134 seconds
2025-04-04 14:21:18,137 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=65, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:21:18,152 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:21:29,460 - src.services.pdf_service - INFO - Valid PDF file: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:21:29,461 - src.services.pdf_service - INFO - Starting text extraction from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:21:29,464 - src.services.pdf_service - ERROR - Error extracting text from PDF: uploads/10.1371journal.pone.0231708.pdf
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 56, in extract_text_from_pdf
    pages = await asyncio.get_running_loop().run_in_executor(self.executor, extract)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'
2025-04-04 14:21:29,464 - src.api.routes - ERROR - Error processing uploaded file: Error extracting text from PDF: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 56, in extract_text_from_pdf
    pages = await asyncio.get_running_loop().run_in_executor(self.executor, extract)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py", line 264, in _feed
    obj = _ForkingPickler.dumps(obj)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
AttributeError: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 84, in upload_file
    text = await pdf_service.extract_text_from_pdf(filepath)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/pdf_service.py", line 70, in extract_text_from_pdf
    raise RuntimeError(f"Error extracting text from PDF: {str(e)}")
RuntimeError: Error extracting text from PDF: Can't get local object 'PDFService.extract_text_from_pdf.<locals>.extract'
2025-04-04 14:24:02,604 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.153 seconds
2025-04-04 14:24:02,606 - root - INFO - Starting up the application...
2025-04-04 14:24:02,606 - root - INFO - Configuration validated successfully
2025-04-04 14:24:02,606 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:24:02,617 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:24:02,676 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:24:02,676 - root - INFO - RAG service initialized successfully
2025-04-04 14:24:02,676 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:33:13,928 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.157 seconds
2025-04-04 14:33:13,930 - root - INFO - Starting up the application...
2025-04-04 14:33:13,930 - root - INFO - Configuration validated successfully
2025-04-04 14:33:13,930 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:33:13,942 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:33:14,066 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:33:14,066 - root - INFO - RAG service initialized successfully
2025-04-04 14:33:14,066 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:33:25,655 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:33:25,665 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:03:25.638492Z' done=True done_reason='stop' total_duration=11560273042 load_duration=22731667 prompt_eval_count=2 prompt_eval_duration=3104401375 eval_count=171 eval_duration=8429350208 message=Message(role='assistant', content=' I’m not sure which one is the most important, but these three things are essential for my happiness:\n\n1. Love and connection with family and friends: Having strong bonds with people who care about me makes me feel loved, supported, and valued. Spending time together, sharing experiences, and expressing affection helps to reinforce these connections.\n2. Personal growth and development: Continually learning new things, setting goals, and working towards personal improvement keeps my mind engaged and energized. It also helps me feel a sense of purpose and accomplishment.\n3. A healthy body and mind: Taking care of myself physically, mentally, and emotionally is crucial for my overall happiness. This means eating well, getting regular exercise, practicing stress-reducing activities like meditation or yoga, and seeking help when needed to maintain mental health.', images=None, tool_calls=None)
2025-04-04 14:33:25,666 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:33:25,666 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:33:25,666 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:33:25,666 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:33:25,693 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:33:27,925 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:33:28,631 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:33:28,631 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:33:28,631 - root - INFO - QnAService initialized successfully
2025-04-04 14:33:28,631 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:33:28,631 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:33:28,631 - root - INFO - AIService initialized successfully
2025-04-04 14:33:28,657 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:33:28,658 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:33:28,658 - root - INFO - PDFService initialized successfully
2025-04-04 14:33:28,658 - root - INFO - Services initialized and passed to routes
2025-04-04 14:33:28,660 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 14.730 seconds
2025-04-04 14:33:28,663 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:33:28,671 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:33:41,956 - src.services.pdf_service - INFO - Valid PDF file: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:33:41,957 - src.services.pdf_service - INFO - Starting text extraction from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:33:42,080 - src.services.pdf_service - INFO - Successfully extracted and cleaned text from PDF: uploads/10.1371journal.pone.0231708.pdf
2025-04-04 14:33:43,228 - src.services.rag_service - INFO - Document stored successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 14:33:43,359 - asyncio - WARNING - Executing <Task pending name='Task-11' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.131 seconds
2025-04-04 14:42:59,159 - src.services.rag_service - INFO - Batch storage successful for 229 documents
2025-04-04 14:42:59,167 - src.services.qna_service - INFO - Added 229 document chunks to RAG for file: 10.1371journal.pone.0231708.pdf
2025-04-04 14:42:59,178 - src.api.routes - INFO - File uploaded and processed successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 14:42:59,264 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.111 seconds
2025-04-04 14:56:08,925 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:120> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.155 seconds
2025-04-04 14:56:08,927 - root - INFO - Starting up the application...
2025-04-04 14:56:08,927 - root - INFO - Configuration validated successfully
2025-04-04 14:56:08,927 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:56:08,940 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:56:09,072 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:56:09,072 - root - INFO - RAG service initialized successfully
2025-04-04 14:56:09,072 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:57:37,163 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:57:37,312 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:27:36.880922Z' done=True done_reason='stop' total_duration=87795260833 load_duration=4354636541 prompt_eval_count=2 prompt_eval_duration=17880559083 eval_count=1055 eval_duration=65541475208 message=Message(role='assistant', content=' This is a story about my first real trip to the woods. I had gone into the woods many times before, but this was different because this time I was alone and I was out to prove myself. I took a bag with some food and water and a knife just in case I needed it. I set out early on a Saturday morning, leaving my home village behind and taking the old road that led to the woods.\n\n   The road was shrouded in mist as I walked, but as I got further into the woods the sun began to burn off the fog, revealing the tall trees and green undergrowth. I felt a sense of excitement as I stepped deeper into the forest, knowing that no one else would be around for miles.\n\n   As I continued walking, I heard the sound of water rushing nearby. I followed the sound until I came to a small stream. I knelt down and drank from it, noticing how clear and cool the water was. I sat on a large rock near the stream, taking in the beauty of my surroundings.\n\n   As I sat there, I began to feel a strange sensation wash over me. It was as if something was watching me, but I couldn\'t see anything. I stood up and walked further down the stream, feeling uneasy but determined to press on.\n\n   The sun had now risen high in the sky, casting dappled shadows through the trees. I came across a clearing and saw a small deer grazing peacefully near the edge of the woods. I stopped for a moment to watch it before continuing on my way.\n\n   I soon arrived at a fork in the road, with one path leading deeper into the forest and the other heading back towards the village. I hesitated for a moment, wondering if I had made a mistake coming out here alone. But then I remembered why I had come - to prove myself, to show that I could survive on my own in the wilderness.\n\n   I took a deep breath and turned down the path leading deeper into the forest. The woods grew thicker as I walked, with the trees towering above me like giants. I heard the sound of twigs snapping behind me, but when I turned to look there was nothing there. I quickened my pace, my heart racing.\n\n   Suddenly, a large branch fell across the path in front of me. Startled, I jumped back and saw movement out of the corner of my eye. I spun around, knife at the ready, but there was nothing there. Just the forest, silent and still.\n\n   I took a deep breath and continued on, telling myself that it was just my imagination playing tricks on me. But as I walked, I couldn\'t shake the feeling that something was watching me, following me through the woods.\n\n   The sun began to set as I made my way back towards the village. I could feel the chill of night creeping in, and I quickened my pace, eager to get back home. As I neared the edge of the woods, I saw a figure standing at the edge of the clearing. It was a tall man with a long beard and a broad-brimmed hat.\n\n   "Hello there," he said in a deep voice. "You\'re out here alone, aren\'t you?"\n\n   I nodded, feeling uneasy but determined to keep going. The man gestured towards the village. "I live over yonder. Care for some company on the way?"\n\n   I hesitated for a moment before nodding again. The man smiled and fell into step beside me as we made our way back to the village. As we walked, he told me stories of his travels through the forest, and I listened in awe.\n\n   When we finally arrived at the edge of the village, the man turned to me and said, "I\'ve been watching you out here, young one. You have a spirit for adventure that not many possess. But remember this - the woods are full of wonder and beauty, but they can also be dangerous. Always trust your instincts and never go into the woods alone if you can help it."\n\n   I nodded, feeling grateful for his advice. As I turned to head back to my home, I looked back one last time at the figure standing in the clearing. He waved goodbye and disappeared into the forest, leaving me with a sense of wonder and a newfound respect for the wilderness.\n\n   That night, I lay in bed and thought about all that had happened. I realized that while I had gone out into the woods to prove myself, I had learned something far more valuable - that the world was full of beauty and mystery, and that sometimes we need to step outside our comfort zone to truly understand it.\n\n   From then on, I made many trips into the woods, always seeking new adventures and discovering new wonders. And every time I returned home, I would carry with me a sense of wonder and gratitude for the experiences I had had in the wilderness.', images=None, tool_calls=None)
2025-04-04 14:57:37,317 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:57:37,347 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:57:37,347 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:57:37,348 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:57:37,831 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:57:41,541 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:57:42,493 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:57:42,494 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:57:42,496 - root - INFO - QnAService initialized successfully
2025-04-04 14:57:42,496 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:57:42,496 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:57:42,496 - root - INFO - AIService initialized successfully
2025-04-04 14:57:42,519 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:57:42,519 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:57:42,519 - root - INFO - PDFService initialized successfully
2025-04-04 14:57:42,520 - root - INFO - Services initialized and passed to routes
2025-04-04 14:57:42,526 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 93.599 seconds
2025-04-04 14:57:42,528 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=53, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:57:42,553 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 14:57:59,718 - root - INFO - Starting up the application...
2025-04-04 14:57:59,719 - root - INFO - Configuration validated successfully
2025-04-04 14:57:59,719 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 14:57:59,731 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:57:59,856 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 14:57:59,856 - root - INFO - RAG service initialized successfully
2025-04-04 14:57:59,856 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 14:58:22,525 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 14:58:22,605 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:28:22.416315Z' done=True done_reason='stop' total_duration=22545359583 load_duration=18432292 prompt_eval_count=2 prompt_eval_duration=14611191000 eval_count=151 eval_duration=7907529750 message=Message(role='assistant', content="\tvar express = require('express');\n    var app = express();\n    const http = require('http').createServer(app);\n    const io = require('socket.io')(http);\n\n    app.use(express.static(__dirname + '/public'));\n\n    io.on('connection', function (socket) {\n      socket.on('chat message', function (msg) {\n        console.log('message: ' + msg);\n        io.emit('chat message', msg);\n      });\n    });\n\n    http.listen(3000, function () {\n      console.log('listening on *:3000');\n    });", images=None, tool_calls=None)
2025-04-04 14:58:22,607 - root - INFO - CrewAIService initialized successfully
2025-04-04 14:58:22,617 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 14:58:22,617 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 14:58:22,618 - root - INFO - PaperSearchService initialized successfully
2025-04-04 14:58:22,850 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 14:58:26,409 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 14:58:27,192 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 14:58:27,192 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 14:58:27,192 - root - INFO - QnAService initialized successfully
2025-04-04 14:58:27,192 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 14:58:27,192 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 14:58:27,192 - root - INFO - AIService initialized successfully
2025-04-04 14:58:27,211 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 14:58:27,212 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 14:58:27,212 - root - INFO - PDFService initialized successfully
2025-04-04 14:58:27,212 - root - INFO - Services initialized and passed to routes
2025-04-04 14:58:27,217 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 27.498 seconds
2025-04-04 14:58:27,219 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=61, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 14:58:27,240 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:00:51,531 - root - INFO - Starting up the application...
2025-04-04 15:00:51,531 - root - INFO - Configuration validated successfully
2025-04-04 15:00:51,531 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:00:51,543 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:00:51,647 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:00:51,648 - root - INFO - RAG service initialized successfully
2025-04-04 15:00:51,648 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:02:09,654 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:02:09,687 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:32:09.594884Z' done=True done_reason='stop' total_duration=77937692709 load_duration=20630292 prompt_eval_count=2 prompt_eval_duration=13905049875 eval_count=1200 eval_duration=64007423459 message=Message(role='assistant', content=' <script>\n    var token = "{{ csrf_token() }}";\n</script>\n<div class="row">\n\t<div class="col-lg-12">\n            <h4 class="page-header text-center">Add Category</h4>\n        </div>\n        <!-- /.col-lg-12 -->\n    </div>\n    <form action="{{url(\'admin/categories/store\')}}" method="POST" enctype="multipart/form-data">\n\t{{ csrf_field() }}\n    <div class="row">\n        <div class="col-lg-12">\n            <div class="panel panel-default">\n                <div class="panel-heading text-center">\n                    Add Category Form\n                </div>\n                <!-- /.panel-heading -->\n                <div class="panel-body">\n\t\t\t\t\t<div class="form-group {{ $errors->has(\'category_name\') ? \' has-error\' : \'\'}}">\n                        <label for="category_name">Category Name</label>\n                        <input type="text" name="category_name" id="category_name" class="form-control" placeholder="Enter Category Name">\n\t\t\t\t\t\t@if ($errors->has(\'category_name\'))\n\t\t\t\t\t\t<span class="help-block">{{ $errors->first(\'category_name\') }}</span>\n\t\t\t\t\t\t@endif\n                    </div>\n\n                    <div class="form-group {{ $errors->has(\'category_slug\') ? \' has-error\' : \'\'}}">\n                        <label for="category_slug">Category Slug</label>\n                        <input type="text" name="category_slug" id="category_slug" class="form-control" placeholder="Enter Category Slug">\n\t\t\t\t\t\t@if ($errors->has(\'category_slug\'))\n\t\t\t\t\t\t<span class="help-block">{{ $errors->first(\'category_slug\') }}</span>\n\t\t\t\t\t\t@endif\n                    </div>\n\n\t\t\t\t\t <div class="form-group {{ $errors->has(\'parent_id\') ? \' has-error\' : \'\'}}">\n                        <label for="parent_id">Parent Category</label>\n                        <select name="parent_id" id="parent_id" class="form-control">\n\t\t\t\t\t\t<option value="0">Select Parent Category</option>\n\t\t\t\t\t\t\t@foreach($categories as $category)\n\t\t\t\t\t\t\t\t<option value="{{$category->id}}">{{$category->name}}</option>\n\t\t\t\t\t\t\t@endforeach\n                        </select>\n\t\t\t\t\t\t@if ($errors->has(\'parent_id\'))\n\t\t\t\t\t\t<span class="help-block">{{ $errors->first(\'parent_id\') }}</span>\n\t\t\t\t\t\t@endif\n                    </div>\n\n                    <div class="form-group {{ $errors->has(\'icon\') ? \' has-error\' : \'\'}}">\n                        <label for="icon">Category Icon</label>\n                        <input type="file" name="icon" id="icon" class="form-control">\n\t\t\t\t\t\t@if ($errors->has(\'icon\'))\n\t\t\t\t\t\t<span class="help-block">{{ $errors->first(\'icon\') }}</span>\n\t\t\t\t\t\t@endif\n                    </div>\n\n\t\t\t\t\t<div class="form-group {{ $errors->has(\'status\') ? \' has-error\' : \'\'}}">\n                        <label for="status">Status</label>\n\t\t\t\t\t\t<select name="status" id="status" class="form-control">\n\t\t\t\t\t\t\t<option value="1">Publish</option>\n\t\t\t\t\t\t\t<option value="0">Unpublish</option>\n                        </select>\n\t\t\t\t\t\t@if ($errors->has(\'status\'))\n\t\t\t\t\t\t<span class="help-block">{{ $errors->first(\'status\') }}</span>\n\t\t\t\t\t\t@endif\n                    </div>\n\n                    <button type="submit" class="btn btn-primary">Add Category</button>\n                    <button type="reset" class="btn btn-default">Reset</button>\n                </div>\n                <!-- /.panel-body -->\n            </div>\n            <!-- /.panel -->\n        </div>\n        <!-- /.col-lg-12 -->\n    </div>\n</form>\n<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>\n<script src="//cdnjs.cloudflare.com/ajax/libs/autosize.js/3.0.15/autosize.min.js"></script>\n<script src="{{asset(\'assets/admin/scripts/custom/form-controls.js\')}}"></script>', images=None, tool_calls=None)
2025-04-04 15:02:09,689 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:02:09,692 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:02:09,692 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:02:09,692 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:02:09,762 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:02:18,853 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:02:21,690 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:02:21,690 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:02:21,690 - root - INFO - QnAService initialized successfully
2025-04-04 15:02:21,691 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:02:21,691 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:02:21,691 - root - INFO - AIService initialized successfully
2025-04-04 15:02:21,709 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:02:21,709 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:02:21,709 - root - INFO - PDFService initialized successfully
2025-04-04 15:02:21,709 - root - INFO - Services initialized and passed to routes
2025-04-04 15:02:21,713 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 90.182 seconds
2025-04-04 15:02:21,714 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=69, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:02:21,734 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:02:42,497 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:02:43,927 - src.services.rag_service - INFO - Search completed for query: What is the main topic of this paper?
2025-04-04 15:02:43,927 - src.services.qna_service - INFO - Query results received: 10 documents
2025-04-04 15:02:43,927 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:02:43,932 - src.services.qna_service - ERROR - Error re-ranking with cross encoders: TextInputSequence must be str
2025-04-04 15:02:43,932 - src.services.qna_service - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 165, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 143, in re_rank_cross_encoders
    ranks = await asyncio.to_thread(self.cross_encoder.rank, prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 15:02:43,940 - src.api.routes - ERROR - Error answering question: TextInputSequence must be str
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 129, in ask_question
    answer = await qna_service.answer_question(question)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 165, in answer_question
    relevant_text, relevant_text_ids = await self.re_rank_cross_encoders(context, prompt)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 143, in re_rank_cross_encoders
    ranks = await asyncio.to_thread(self.cross_encoder.rank, prompt, documents, top_k=3)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 503, in rank
    scores = self.predict(
             ^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/util.py", line 68, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 402, in predict
    features = self.tokenizer(
               ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2975, in _call_one
    return self.batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 3177, in batch_encode_plus
    return self._batch_encode_plus(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py", line 539, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextInputSequence must be str
2025-04-04 15:07:44,744 - root - INFO - Starting up the application...
2025-04-04 15:07:44,745 - root - INFO - Configuration validated successfully
2025-04-04 15:07:44,745 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:07:44,756 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:07:44,877 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:07:44,877 - root - INFO - RAG service initialized successfully
2025-04-04 15:07:44,877 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:09:25,208 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:09:25,464 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:39:24.726771Z' done=True done_reason='stop' total_duration=99839825042 load_duration=4084367875 prompt_eval_count=2 prompt_eval_duration=14263360500 eval_count=1249 eval_duration=81472531958 message=Message(role='assistant', content="1. Home\n2. Products\n3. Insects & Mites - Pests\n4. Bromley's® Acecap 5.0 Insecticide/Miticide\n\n# Bromley's® Acecap 5.0 Insecticide/Miticide\n\n## Overview\n\nBromley's® Acecap 5.0 is a versatile, contact and systemic insecticide for the control of spider mites, whiteflies, thrips, leafminers, scale and other pests on a wide variety of crops including vegetables, ornamentals and turf.\n\nActive Ingredient:  Acecapificheate (50%) + PBO (14.7%).\n\nPack Sizes:  2 x 8 kg; 4 x 8 kg; 6 x 8 kg; 30 lb (24.95 kg) drums\n\n### Features and Benefits\n\n- Acecapificheate provides fast knockdown and effective control of spider mites, thrips, leafminers, scale, whiteflies and other pests on a wide variety of crops. It also enhances the efficacy of PBO against broad mite and russet mite.\n- The addition of PBO improves plant health by promoting vigor and increasing photosynthesis. This results in improved fruit quality and yield.\n- Acecapificheate is highly systemic, providing effective control when applied at the lower rate of 14 ml/L.\n- Excellent for use in integrated pest management (IPM) programs to reduce the risk of resistance.\n- PBO is a broad spectrum adjuvant that enhances insecticide efficacy by inhibiting cuticle formation, thereby increasing absorption of systemic insecticides. PBO may also have beneficial effects on plant health by promoting photosynthesis and fruit size.\n- Acecapificheate (50%) + PBO (14.7%) is registered in Canada for use in a variety of crops.\n\n### Directions for Use\n\n#### Ornamentals\n\nUse as a preventative or curative treatment at the first sign of pest damage.  For optimum results, apply when temperatures are above 20°C (68°F).\n\nMix with water according to table below:\n\nApply thoroughly to underside and top of foliage using a sprayer calibrated to deliver 150-200 L/ha (7.3-9.5 gallons/acre) at recommended volumes. Repeat applications as needed, but do not apply more than three times per season.\n\n#### Turfgrass\n\nApply Acecap 5.0 when conditions are conducive to spider mite activity, such as high temperatures and low humidity. Treatments may be required on a monthly basis during the growing season to manage spider mites and other pests.\n\nFor optimum results, apply at the first sign of pest damage when temperatures are above 20°C (68°F).\n\nMix with water according to table below:\n\nApply thoroughly to foliage using a sprayer calibrated to deliver 150-200 L/ha (7.3-9.5 gallons/acre) at recommended volumes. Repeat applications as needed, but do not apply more than three times per season.\n\n#### Crop Recommendations\n\nNote: Always confirm the label before use.\n\n### Tips for Success\n\n- Spray early in the day to minimize leaf damage caused by high temperatures and to maximize coverage of the underside of leaves.\n- Apply during periods when spider mites are most active, such as hot, dry weather.\n- For better control of spider mites on susceptible crops like strawberries, apply Acecap 5.0 twice, with an interval of 7 to 10 days between applications.\n\n### Safety Information\n\nKeep out of reach of children and pets. Do not allow water runoff from application areas to enter waterways without proper treatment. Avoid contact with skin, eyes and clothing. Wash hands and exposed skin after handling product. Protective clothing, gloves and eyewear should be worn during application. If product contacts skin or eyes, rinse thoroughly with water for 15 minutes. In case of accidental ingestion, drink large amounts of water and contact a physician immediately. If inhaled, move to fresh air and seek medical attention. Keep container tightly closed when not in use. Dispose of empty containers in accordance with local regulations.\n\nThis product is toxic to aquatic organisms. Avoid spray drift and runoff into bodies of water. Do not apply within 15 m (50 ft) of water sources, including irrigation ditches, streams or ponds. Do not contaminate pristine or sensitive waters. Avoid application when rainfall is imminent.\n\n### Additional Information\n\nBromley's® Acecap 5.0 Insecticide/Miticide can be rotated with other insecticides to reduce the risk of pest resistance. When using multiple products, always consult the label before mixing.\n\nFor more information on the latest pesticide labels and safety requirements, visit www.agr.gc.ca/pesticides\n\nAlways read the product label before use. Products must be used in a manner consistent with their label. The user is responsible for knowing the regulatory status of products in their area and using them accordingly.\n\nPerformance may vary from region to region, grower to grower and year to year. Always consult a PBI-Gordon® representative for information specific to your operation.", images=None, tool_calls=None)
2025-04-04 15:09:25,476 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:09:25,492 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:09:25,495 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:09:25,495 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:09:26,173 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:09:29,889 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:09:31,608 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:09:31,609 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:09:31,609 - root - INFO - QnAService initialized successfully
2025-04-04 15:09:31,609 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:09:31,610 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:09:31,610 - root - INFO - AIService initialized successfully
2025-04-04 15:09:31,637 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:09:31,638 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:09:31,638 - root - INFO - PDFService initialized successfully
2025-04-04 15:09:31,638 - root - INFO - Services initialized and passed to routes
2025-04-04 15:09:31,643 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 106.898 seconds
2025-04-04 15:09:31,646 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=82, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:09:31,669 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:09:37,851 - root - INFO - Starting up the application...
2025-04-04 15:09:37,851 - root - INFO - Configuration validated successfully
2025-04-04 15:09:37,851 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:09:37,863 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:09:37,915 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:09:37,915 - root - INFO - RAG service initialized successfully
2025-04-04 15:09:37,915 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:09:49,006 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:09:49,028 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:39:48.983311Z' done=True done_reason='stop' total_duration=11055393000 load_duration=18944625 prompt_eval_count=2 prompt_eval_duration=4039148875 eval_count=135 eval_duration=6990323125 message=Message(role='assistant', content='\t#include<stdio.h>\n    #include<conio.h>\n\n    void main()\n\t{\n\t\tint a,b,c;\n\t\tclrscr();\n\n\t\tprintf("\\n Enter the values for A : ");\n\t\tscanf("%d",&a);\n\n\t\tprintf("\\n Enter the values for B : ");\n\t\tscanf("%d",&b);\n\n\t\tc=a+b;\n\n\t\tprintf("\\n The sum of A and B is %d ",c);\n\n\t\tgetch();\n\t}', images=None, tool_calls=None)
2025-04-04 15:09:49,029 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:09:49,029 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:09:49,029 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:09:49,029 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:09:49,071 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:09:54,194 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:09:55,636 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:09:55,636 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:09:55,636 - root - INFO - QnAService initialized successfully
2025-04-04 15:09:55,637 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:09:55,637 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:09:55,637 - root - INFO - AIService initialized successfully
2025-04-04 15:09:55,661 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:09:55,661 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:09:55,661 - root - INFO - PDFService initialized successfully
2025-04-04 15:09:55,662 - root - INFO - Services initialized and passed to routes
2025-04-04 15:09:55,666 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 17.815 seconds
2025-04-04 15:09:55,667 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=90, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:09:55,673 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:12:12,571 - root - INFO - Starting up the application...
2025-04-04 15:12:12,572 - root - INFO - Configuration validated successfully
2025-04-04 15:12:12,572 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:12:12,584 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:12:12,696 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:12:12,696 - root - INFO - RAG service initialized successfully
2025-04-04 15:12:12,696 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:12:47,056 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:12:47,085 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:42:47.006281Z' done=True done_reason='stop' total_duration=34299771167 load_duration=13062584 prompt_eval_count=2 prompt_eval_duration=7559335584 eval_count=515 eval_duration=26722658666 message=Message(role='assistant', content=' In the 17^{th} Century, the Dutch East India Company was a dominant trading force. They established colonies, built forts and factories in strategic locations, to ensure the flow of spices from Indonesia. One such colony was Nagasaki, Japan, which became one of the few ports open for trade with the West.\n\nIn 1623, the Dutch East India Company established a factory (trading post) in Hirado Island, where they traded with the local Daimyos, or Lords of the domains. The Portuguese had been trading at Nagasaki since 1549 and in 1609, Tokugawa Ieyasu established his capital in Edo, present day Tokyo, and banned foreigners from all ports except for Nagasaki. In 1637, he issued an edict prohibiting Christians and Christianity as it was seen as a threat to the feudal system.\n\nThe Dutch had been trading with Japan for nearly 90 years and in 1640, they established a factory at Dejima, an island created by building a causeway from Nagasaki. The Dutch were allowed to trade spices, weapons, and gold coins (known as Ducats) but only on Dejima under strict supervision of the Shogun’s government.\n\nThe Dutch built a small fort with a church next to it. The church was used for their private services only, as any Japanese converting to Christianity would be arrested or put to death.\n\nFor 200 years, the Dutch at Dejima were isolated from all other Europeans and the rest of the world. During this time, they maintained a strong trading partnership with Japan. In fact, during the Napoleonic Wars, when England was blockaded by France, the Dutch had their main port of communication with Europe through Nagasaki.\n\nIn 1853, Commodore Matthew Perry arrived in Tokyo with four gunships from the United States Navy and forced Japan to open its ports. The Treaty of Peace and Amity between America and Japan was signed in 1854, thus ending over 200 years of seclusion.\n\nIn 1867, Dejima was closed down and the Dutch had to move out. Today, all that remains is an empty field with a small museum dedicated to the history of the Dutch at Dejima.', images=None, tool_calls=None)
2025-04-04 15:12:47,086 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:12:47,089 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:12:47,089 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:12:47,089 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:12:47,134 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:12:55,775 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:12:56,508 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:12:56,509 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:12:56,509 - root - INFO - QnAService initialized successfully
2025-04-04 15:12:56,509 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:12:56,509 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:12:56,509 - root - INFO - AIService initialized successfully
2025-04-04 15:12:56,536 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:12:56,536 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:12:56,536 - root - INFO - PDFService initialized successfully
2025-04-04 15:12:56,537 - root - INFO - Services initialized and passed to routes
2025-04-04 15:12:56,539 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 43.968 seconds
2025-04-04 15:12:56,542 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:12:56,556 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:13:43,159 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:13:44,345 - src.services.rag_service - INFO - Search completed for query: What is the main topic of this paper?
2025-04-04 15:13:44,345 - src.services.qna_service - INFO - Query results received: 10 documents
2025-04-04 15:13:44,345 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:13:46,153 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 3569
2025-04-04 15:13:46,153 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 15:13:46,173 - src.services.crew_service - ERROR - Error in CrewAI analysis process: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 114, in analyze_with_crew
    analysis_task = Task(
                    ^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/pydantic/main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-04-04 15:13:46,179 - src.services.qna_service - ERROR - Error calling LLM: Error in CrewAI analysis process: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-04-04 15:13:46,179 - src.services.qna_service - ERROR - Error answering question: Error in CrewAI analysis process: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 114, in analyze_with_crew
    analysis_task = Task(
                    ^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/pydantic/main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 178, in answer_question
    response = await self.call_llm(context=relevant_text, prompt=prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 136, in call_llm
    return await self.crew_service.analyze_with_crew(system_prompt, full_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 131, in analyze_with_crew
    raise RuntimeError(f"Error in CrewAI analysis process: {str(e)}")
RuntimeError: Error in CrewAI analysis process: 1 validation error for Task
expected_output
  Field required [type=missing, input_value={'description': '\n      ...y trends and insights.)}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-04-04 15:20:01,439 - root - INFO - Starting up the application...
2025-04-04 15:20:01,440 - root - INFO - Configuration validated successfully
2025-04-04 15:20:01,440 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:20:01,451 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:20:01,568 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:20:01,568 - root - INFO - RAG service initialized successfully
2025-04-04 15:20:01,568 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:21:08,898 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:21:08,916 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:51:08.875472Z' done=True done_reason='stop' total_duration=67300441292 load_duration=4084017875 prompt_eval_count=2 prompt_eval_duration=9037990458 eval_count=965 eval_duration=54172967459 message=Message(role='assistant', content=' ![logo](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/GNU_GPL_Logo.svg/200px-GNU_GPL_Logo.svg.png)\n\n# Aula 3 - Introdução à Programação Orientada a Objetos em Python\n\n## Objetivos\n\n- Entender conceitos básicos da programação orientada a objetos (POO) em Python\n- Definir classes, atributos e métodos em Python\n- Criar instâncias de uma classe e usá-las para realizar operações específicas\n- Acessar e manipular atributos de uma instância\n- Chamar métodos de uma instância\n\n## Introdução à POO\n\nA programação orientada a objetos (POO) é um estilo de programação que permite definir, criar e manipular objetos, cada qual possuindo propriedades e comportamentos específicos. Cada objeto é uma instância de uma classe. A classe serve como um padrão para a criação dos objetos.\n\nUm objeto tem três partes principais:\n- Atributos: representam as características do objeto (propriedades)\n- Métodos: representam os comportamentos do objeto (operções que o objeto pode realizar)\n- Construtor: serve para criar objetos a partir de uma classe\n\n## Definindo Classes em Python\n\nUma classe é definida usando a palavra-chave `class`.\n```python\nclass Classe:\n    # Atributo de instância\n    atributo = "Atributo"\n\n    # Método de instância\n    def método(self):\n        print("Estou executando o método.")\n\n# Criar uma nova classe\nnova_classe = Classe()\n```\n## Instanciando e Acessando Atributos\n\nPara criar uma instância de uma classe, usamos a palavra-chave `new`. Todas as instâncias têm o mesmo conjunto de atributos de instância. Porém, todos eles podem ser sobreescritos individualmente em cada instância.\n```python\n# Criar uma nova classe\nnova_classe = Classe()\nprint(nova_classe.atributo) # Atributo\n\n# Alterando o atributo de uma instância\nnova_classe.atributo = "Novo atributo"\nprint(nova_classe.atributo) # Novo atributo\n```\n## Chamando Métodos\n\nOs métodos são chamados usando o sinal de pontos (.) após a instância e seguido pelo nome do método. Além disso, todos os métodos recebem como primeiro parâmetro uma referência para a instância chamante.\n```python\n# Chamando um método de uma instância\nnova_classe.método() # Estou executando o método.\n\n# Criar uma nova instância e alterando o nome do atributo\nnova_instancia = Classe()\nnova_instancia.atributo = "Outro atributo"\nprint(nova_instancia.atributo) # Outro atributo\n```\n## Definindo Métodos com Parâmetros\n\nPara definir um método que receba parâmetros, podemos adicioná-los após o nome do parâmetro `self`. Por exemplo:\n```python\nclass Calculadora:\n    def somar(self, valor1, valor2):\n        return valor1 + valor2\n\n# Criando uma nova instância e chamando um método com parâmetros\ncalculadora = Calculadora()\nresultado = calculadora.somar(3, 5)\nprint(resultado) # 8\n```', images=None, tool_calls=None)
2025-04-04 15:21:08,918 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:21:08,920 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:21:08,920 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:21:08,920 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:21:08,962 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:21:12,004 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:21:15,675 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:21:15,675 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:21:15,675 - root - INFO - QnAService initialized successfully
2025-04-04 15:21:15,675 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:21:15,675 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:21:15,675 - root - INFO - AIService initialized successfully
2025-04-04 15:21:15,692 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:21:15,692 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:21:15,692 - root - INFO - PDFService initialized successfully
2025-04-04 15:21:15,692 - root - INFO - Services initialized and passed to routes
2025-04-04 15:21:15,695 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 74.254 seconds
2025-04-04 15:21:15,696 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:21:15,708 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:26:01,959 - root - INFO - Starting up the application...
2025-04-04 15:26:01,959 - root - INFO - Configuration validated successfully
2025-04-04 15:26:01,959 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:26:01,971 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:26:02,104 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:26:02,104 - root - INFO - RAG service initialized successfully
2025-04-04 15:26:02,104 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:26:20,919 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:26:20,939 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T09:56:20.891166Z' done=True done_reason='stop' total_duration=18780499125 load_duration=14319000 prompt_eval_count=2 prompt_eval_duration=5744240917 eval_count=188 eval_duration=13015557875 message=Message(role='assistant', content=' <template>\n    <v-col cols="12">\n      <!-- Title -->\n      <h1 class="text-h4 font-weight-regular ma-0">{{ title }}</h1>\n      <p v-if="$slots.subtitle" class="font-weight-regular text-body-2 ma-0">{{ $slots.subtitle }}</p>\n\n      <!-- Content -->\n      <v-col cols="12">\n        <!-- Text -->\n        <slot></slot>\n      </v-col>\n    </v-col>\n  </template>\n\n  <script lang="ts">\n  export default {\n    props: {\n      title: {\n        type: String,\n        required: true,\n      },\n    },\n  };\n  </script>', images=None, tool_calls=None)
2025-04-04 15:26:20,940 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:26:20,941 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:26:20,941 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:26:20,941 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:26:20,990 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:26:24,284 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:26:25,115 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:26:25,115 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:26:25,115 - root - INFO - QnAService initialized successfully
2025-04-04 15:26:25,116 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:26:25,116 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:26:25,116 - root - INFO - AIService initialized successfully
2025-04-04 15:26:25,142 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:26:25,142 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:26:25,142 - root - INFO - PDFService initialized successfully
2025-04-04 15:26:25,142 - root - INFO - Services initialized and passed to routes
2025-04-04 15:26:25,149 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 23.189 seconds
2025-04-04 15:26:25,152 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:26:25,167 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:27:23,453 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:27:23,523 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 15:27:23,523 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 15:27:23,523 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:27:24,739 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 15:27:24,739 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 15:27:24,755 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 15:27:24,783 - root - ERROR - LiteLLM call failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:27:24,784 - src.services.crew_service - ERROR - Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 127, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 979, in completion
    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(
                                                            ^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 356, in get_llm_provider
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 333, in get_llm_provider
    raise litellm.exceptions.BadRequestError(  # type: ignore
litellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:27:24,792 - src.services.qna_service - ERROR - Error calling LLM: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:27:24,792 - src.services.qna_service - ERROR - Error answering question: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 127, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 979, in completion
    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(
                                                            ^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 356, in get_llm_provider
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 333, in get_llm_provider
    raise litellm.exceptions.BadRequestError(  # type: ignore
litellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 185, in answer_question
    response = await self.call_llm(context=relevant_text, prompt=prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 136, in call_llm
    return await self.crew_service.analyze_with_crew(system_prompt, full_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 132, in analyze_with_crew
    raise RuntimeError(f"Error in CrewAI analysis process: {str(e)}")
RuntimeError: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<module 'ollama' from '/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/ollama/__init__.py'>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:36:28,195 - root - INFO - Starting up the application...
2025-04-04 15:36:28,195 - root - INFO - Configuration validated successfully
2025-04-04 15:36:28,195 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:36:28,207 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:36:28,263 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:36:28,263 - root - INFO - RAG service initialized successfully
2025-04-04 15:36:28,263 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:38:04,980 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:38:05,085 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:08:04.808398Z' done=True done_reason='stop' total_duration=96537913416 load_duration=4083531583 prompt_eval_count=2 prompt_eval_duration=6617476791 eval_count=1494 eval_duration=85825342750 message=Message(role='assistant', content=' [The title is the Latin translation of “A New Hope”]\n\nAs the Republic begins to crumble, an old man clings desperately to his Jedi beliefs. The galaxy is in turmoil, and dark forces gather, awaiting a moment to strike back at the Jedi and everything they stand for. A new hope flickers in the heart of a desert planet; a young farm boy dreams of adventure. Will this be the spark that rekindles the flame of freedom?\n\nThe movie opens with a sweeping shot of an empty desert landscape, dunes stretching as far as the eye can see. Suddenly, an old man, Obi-Wan Kenobi, strides into view on a speeder bike. He is accompanied by two small droids, R2-D2 and C-3PO. The older droid, C-3PO, laments their situation – they are lost, without a map, with no clear direction. Obi-Wan dismisses the droids’ concerns and tells them to follow him.\n\nThe trio comes upon a small pit dwelling, where they meet a young woman named Leia Organa. She has a mysterious package she needs delivered to a Rebel leader. Obi-Wan, sensing the importance of this package, agrees to take it.\n\nMeanwhile, on another part of the planet, we see stormtroopers patrolling a massive construction site. The structure they are building is ominous and foreboding – a symbol of the Empire’s power. The stormtrooper commander reports that there have been no sign of life on this planet, but he suspects they may find what they are looking for in one of the nearby caves.\n\nInside the cave, we meet our hero: a young farm boy named Luke Skywalker. He is fixing his broken speeder bike when Obi-Wan and the droids appear. Luke is initially suspicious of these strangers, but after hearing their story, he agrees to help them. Together, they make their way across the desert to the Rebel base.\n\nAlong the way, we learn more about each character. Luke dreams of adventure, longing to escape the monotony of farm life and explore the galaxy. Obi-Wan, though old and weary, still carries a sense of hope and determination. C-3PO frets constantly about their imminent capture by the Empire, while R2-D2 communicates only through beeps and whistles.\n\nLeia, too, is revealed to have a secret: she is a princess, the daughter of a powerful senator who was murdered by the Empire. She is also the sister of Luke Skywalker, a fact that neither knows yet. This connection will prove vital in the fight against the Empire.\n\nUpon reaching the Rebel base, they are greeted by Mon Mothma, a respected leader of the rebellion. Mon Mothma implores Obi-Wan to use the Force and contact someone who can help them. Obi-Wan responds that he has already contacted someone – a friend named Han Solo.\n\nHan Solo, a smuggler with a heart of gold, arrives in his ship, the Millennium Falcon. He is immediately drawn to Leia and agrees to take her, Obi-Wan, and the droids on a dangerous mission: to deliver the package to the Rebel leader and destroy the Death Star, the Empire’s ultimate weapon.\n\nAs they fly through space, we are introduced to the rest of the crew: Chewbacca, Han’s loyal Wookiee co-pilot; Lando Calrissian, a slick and charming gambler who captains the Falcon when Han is not present; and, finally, the Millennium Falcon herself – a ship with a mind of its own and a knack for getting out of sticky situations.\n\nTheir journey takes them to the Death Star, where they must navigate through corridors filled with stormtroopers and Imperial officers. Leia uses her knowledge of the Empire’s inner workings to help the group avoid detection. In one tense moment, she even disguises herself as a stormtrooper to gain access to the control room.\n\nEventually, they reach the chamber where the Death Star plans are kept – only to find it empty. Obi-Wan sensed a disturbance in the Force and knew that something was amiss. They are pursued by Darth Vader, the Dark Lord of the Sith, who seeks to capture Leia and crush the Rebellion once and for all.\n\nIn a desperate bid to escape, Han leads the group onto the Death Star’s surface. There, they discover a small trench run that leads directly to the reactor core – if they can fly through it, they can destroy the Death Star from within.\n\nThe trench run is fraught with danger: TIE fighters swarm around them, laser bolts fly everywhere, and the walls of the trench are closing in on either side. But Han’s skill as a pilot – and Luke’s newfound connection to the Force – help them make it through unscathed.\n\nWith the Death Star destroyed, the Rebels celebrate their victory. Leia reunites with her brother Luke, and Obi-Wan passes on his knowledge of the Force to the young farm boy. The galaxy is not yet safe, but a new hope has been born – a hope that the Jedi will rise again and restore peace and justice to the galaxy.\n\nAs the movie comes to a close, we see Obi-Wan standing at the edge of a cliff, gazing out over the stars. He senses that his time is coming to an end, but he knows that Luke’s destiny lies far beyond these humble desert sands. With a wistful smile, Obi-Wan turns and walks into the sunset – leaving behind a legacy of hope and the promise of a brighter future for all who believe in the power of the Force.\n\nStar Wars: A New Hope is a timeless tale of adventure, heroism, and the struggle between good and evil. It introduced audiences to a rich and immersive universe filled with memorable characters, thrilling action sequences, and powerful themes that resonate even today. The film’s enduring appeal lies in its ability to tap into our collective imagination and remind us of the power we each possess – to dream, to hope, and to fight for what is right.\n\nAs Luke Skywalker learns from Obi-Wan, so too can we learn from this classic story: that even in the darkest times, there is always a new hope – a spark of light that can guide us through the darkness and lead us back to the path of righteousness. And as long as we hold onto that hope, nothing can stand in our way.\n\nMay the Force be with you, always.', images=None, tool_calls=None)
2025-04-04 15:38:05,105 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:38:05,120 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:38:05,121 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:38:05,121 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:38:05,506 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:38:08,309 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:38:09,089 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:38:09,089 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:38:09,089 - root - INFO - QnAService initialized successfully
2025-04-04 15:38:09,089 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:38:09,089 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:38:09,089 - root - INFO - AIService initialized successfully
2025-04-04 15:38:09,112 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:38:09,112 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:38:09,113 - root - INFO - PDFService initialized successfully
2025-04-04 15:38:09,113 - root - INFO - Services initialized and passed to routes
2025-04-04 15:38:09,116 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 100.920 seconds
2025-04-04 15:38:09,118 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=59, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:38:09,143 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:38:16,054 - root - INFO - Starting up the application...
2025-04-04 15:38:16,055 - root - INFO - Configuration validated successfully
2025-04-04 15:38:16,055 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:38:16,066 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:38:16,115 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:38:16,115 - root - INFO - RAG service initialized successfully
2025-04-04 15:38:16,115 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:38:49,255 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:38:49,341 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:08:49.056783Z' done=True done_reason='stop' total_duration=32926602791 load_duration=23112875 prompt_eval_count=2 prompt_eval_duration=4574779125 eval_count=435 eval_duration=28321289833 message=Message(role='assistant', content=' The U.S. Department of Agriculture (USDA) has designated 27 counties in Alabama as primary natural disaster areas due to damages and losses caused by excessive rain, flooding and straight-line winds that occurred from March 1 through April 30, 2020.\n\nThe counties are Barbour, Bullock, Coffee, Conecuh, Dale, Geneva, Henry, Houston, Lee, Lowndes, Monroe, Pike, Russell, and Tallapoosa in south Alabama; Bibb, Clarke, Greene, Hale, Lamar, Perry, Sumter, Wilcox, and Marengo in west-central Alabama; Autauga, Chilton, Dallas, Elmore, Montgomery, and Shelby in central Alabama.\n\nFarmers and ranchers in the contiguous counties of Butler, Covington, Clarke County, Alabama, Mobile, Monroe, Jackson, Lauderdale, Lawrence, Marion, Monroe, Greene, Hale, Choctaw, Washington, Marengo, Macon, Tallapoosa and Jefferson are also eligible to apply for assistance.\n\nAll counties listed above were designated natural disaster areas on June 19, making all qualified farm operators in the designated areas eligible for USDA Farm Service Agency emergency loans, provided eligibility requirements are met.\n\nThe deadline to apply for these loans is July 20, 2020. Farmers in eligible counties have eight months from the date of a disaster designation to apply for loans to help cover part of their actual losses. FSA will consider each loan application on its own merits, taking into account the totality of the circumstances and evidence provided by the applicant.\n\nFor more information on emergency loans or other FSA programs, contact your local FSA office or go to farmers.gov. For a list of FSA offices in Alabama, visit fsa.usda.gov/locate/office-lookup.', images=None, tool_calls=None)
2025-04-04 15:38:49,343 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:38:49,352 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:38:49,352 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:38:49,352 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:38:49,585 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:38:52,446 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:38:53,236 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:38:53,237 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:38:53,237 - root - INFO - QnAService initialized successfully
2025-04-04 15:38:53,237 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:38:53,237 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:38:53,237 - root - INFO - AIService initialized successfully
2025-04-04 15:38:53,260 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:38:53,260 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:38:53,261 - root - INFO - PDFService initialized successfully
2025-04-04 15:38:53,261 - root - INFO - Services initialized and passed to routes
2025-04-04 15:38:53,264 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 37.209 seconds
2025-04-04 15:38:53,266 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=67, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:38:53,287 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:39:18,318 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:39:18,382 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 15:39:18,382 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 15:39:18,382 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:39:20,312 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 15:39:20,312 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 15:39:20,331 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 15:39:20,365 - root - ERROR - LiteLLM call failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:39:20,366 - src.services.crew_service - ERROR - Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 61, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 979, in completion
    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(
                                                            ^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 356, in get_llm_provider
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 333, in get_llm_provider
    raise litellm.exceptions.BadRequestError(  # type: ignore
litellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:39:20,371 - src.services.qna_service - ERROR - Error calling LLM: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:39:20,371 - src.services.qna_service - ERROR - Error answering question: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 61, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 979, in completion
    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(
                                                            ^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 356, in get_llm_provider
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/get_llm_provider_logic.py", line 333, in get_llm_provider
    raise litellm.exceptions.BadRequestError(  # type: ignore
litellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 185, in answer_question
    response = await self.call_llm(context=relevant_text, prompt=prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 136, in call_llm
    return await self.crew_service.analyze_with_crew(system_prompt, full_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 66, in analyze_with_crew
    raise RuntimeError(f"Error in CrewAI analysis process: {str(e)}")
RuntimeError: Error in CrewAI analysis process: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=<function CrewAIService.create_ollama_llm.<locals>.<lambda> at 0x16ecabce0>
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2025-04-04 15:41:41,866 - root - INFO - Starting up the application...
2025-04-04 15:41:41,866 - root - INFO - Configuration validated successfully
2025-04-04 15:41:41,866 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:41:41,878 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:41:41,925 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:41:41,925 - root - INFO - RAG service initialized successfully
2025-04-04 15:41:41,925 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:42:32,185 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:42:32,246 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:12:32.095572Z' done=True done_reason='stop' total_duration=50163115375 load_duration=18912625 prompt_eval_count=2 prompt_eval_duration=4940715459 eval_count=776 eval_duration=45199052625 message=Message(role='assistant', content=' [Home](./README.md) | [Previous Step](./2_deploy-terraform.md) | Next Step:[4_deploy-docker](./4_deploy-docker.md)\n\n## 3_setup_helm_charts\nThis step assumes you have Kubernetes running in your cluster and Helm installed on your workstation.\n\nIn this project, we will be using two helm charts for deployment. You can get more information about the following helm charts here:\n\n1. [Bitnami Jenkins Chart](https://github.com/bitnami-labs/charts/tree/master/jenkins)\n2. [Bitnami MongoDB Atlas Helm chart](https://github.com/kubernetes-charts/mongodb-atlas)\n\nTo set these up in your project, follow the steps below:\n\n1. Clone both helm charts using the following commands:\n\n   ```\n   cd ~\n   git clone https://github.com/bitnami-labs/charts.git\n   git clone https://github.com/kubernetes-charts/mongodb-atlas\n   cd jenkins\n   cd mongodb-atlas\n   ```\n\n2. Create a directory in your project to keep the customized Helm charts:\n\n   ```\n   mkdir ~/my_helm_charts\n   cd ~/my_helm_charts\n   ```\n\n3. Copy the required files of both charts into `~/my_helm_charts` directory:\n\n   * Copy the `values.yaml` file from the following path to your custom helm chart directory:\n     ```\n     cd ~/jenkins\n     cp jenkins/values.yaml ~/my_helm_charts/mongodb-atlas\n     ```\n   * Create a new `values-mongodb-atlas.yaml` file and add the following details in it:\n\n     ```yaml\n     mongodb:\n       username: "your_username"\n       password: "your_password"\n       authSource: "admin"\n       replicasetName: "myrs0"\n       host: "mongodb-atlas.mongo.ondigitalocean.com"\n       port: 27017\n     ```\n   * Copy the `deploy/kubernetes` folder and the `templates` folder from both charts into your custom helm chart directory. To copy these files, run the following commands:\n\n     ```\n     cp -r ~/jenkins/deploy/kubernetes ~/my_helm_charts\n     cp -r ~/mongodb-atlas/templates ~/my_helm_charts\n     ```\n\n4. Now, you can customize the `values-mongodb-atlas.yaml` file to set any required changes for your MongoDB Atlas connection like username, password, and host.\n\nNow you have all the files ready in your customized Helm chart directory (`~/my_helm_charts`) to deploy Jenkins and MongoDB Atlas using Helm. In the next step, we will deploy these Helm charts to Kubernetes.\n\n[Home](./README.md) | [Previous Step](./2_deploy-terraform.md) | Next Step:[4_deploy-docker](./4_deploy-docker.md)', images=None, tool_calls=None)
2025-04-04 15:42:32,247 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:42:32,250 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:42:32,250 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:42:32,250 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:42:32,349 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:42:36,412 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:42:37,099 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:42:37,099 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:42:37,099 - root - INFO - QnAService initialized successfully
2025-04-04 15:42:37,099 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:42:37,100 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:42:37,100 - root - INFO - AIService initialized successfully
2025-04-04 15:42:37,123 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:42:37,123 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:42:37,123 - root - INFO - PDFService initialized successfully
2025-04-04 15:42:37,123 - root - INFO - Services initialized and passed to routes
2025-04-04 15:42:37,126 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 55.260 seconds
2025-04-04 15:42:37,128 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=85, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:42:37,146 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:43:31,286 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:43:31,349 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 15:43:31,349 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 15:43:31,349 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:43:33,179 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 15:43:33,179 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 15:43:33,179 - src.services.crew_service - ERROR - Error in CrewAI analysis process: name 'se' is not defined
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 45, in analyze_with_crew
    llm=self.create_ollama_llm(),
        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 36, in create_ollama_llm
    return self.model
           ^^
NameError: name 'se' is not defined
2025-04-04 15:43:33,184 - src.services.qna_service - ERROR - Error calling LLM: Error in CrewAI analysis process: name 'se' is not defined
2025-04-04 15:43:33,184 - src.services.qna_service - ERROR - Error answering question: Error in CrewAI analysis process: name 'se' is not defined
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 45, in analyze_with_crew
    llm=self.create_ollama_llm(),
        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 36, in create_ollama_llm
    return self.model
           ^^
NameError: name 'se' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 185, in answer_question
    response = await self.call_llm(context=relevant_text, prompt=prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 136, in call_llm
    return await self.crew_service.analyze_with_crew(system_prompt, full_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 66, in analyze_with_crew
    raise RuntimeError(f"Error in CrewAI analysis process: {str(e)}")
RuntimeError: Error in CrewAI analysis process: name 'se' is not defined
2025-04-04 15:48:53,034 - root - INFO - Starting up the application...
2025-04-04 15:48:53,034 - root - INFO - Configuration validated successfully
2025-04-04 15:48:53,034 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:48:53,046 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:48:53,116 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:48:53,116 - root - INFO - RAG service initialized successfully
2025-04-04 15:48:53,116 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:49:27,924 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:49:28,027 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:19:27.735685Z' done=True done_reason='stop' total_duration=34612329167 load_duration=3883798792 prompt_eval_count=2 prompt_eval_duration=8146356625 eval_count=382 eval_duration=22571077791 message=Message(role='assistant', content="\nDear Friends,\n\nI hope you had a wonderful Christmas with your loved ones. I am excited to share with you that we are going to start our new year by hosting an event to celebrate the life of our Lord Jesus Christ’s birth and to bring His love to others through a service project.\n\nOn January 6th, Feast of Epiphany, we will be hosting our annual Epiphany Party at the church. This is a tradition that dates back to when I was growing up in Spain, and it’s an opportunity for us to celebrate the manifestation of Jesus Christ as the Son of God to the Magi and all nations. We’ll have fun activities for the kids, food, and music. It will be an evening full of fellowship and joy!\n\nBut we won’t stop there. On this same day, we are going to make a difference in our community by hosting a coat drive in partnership with a local organization that helps the homeless and less fortunate in our area. Our goal is to collect as many coats as possible so that those who need them can stay warm during these cold winter months.\n\nI would be honored if you could join us for this special day, bring a coat to donate, and enjoy an evening of fellowship with your fellow brothers and sisters in Christ. Let’s come together and share the love of our Lord Jesus Christ with others.\n\nIf you can't make it but still want to participate, you can drop off a coat at the church between now and January 6th. We will also have a donation box for monetary contributions to help cover the costs of buying coats if we run out during the drive.\n\nLooking forward to seeing you all on January 6th!\n\nIn His love,\n[Your Name]", images=None, tool_calls=None)
2025-04-04 15:49:28,033 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:49:28,041 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:49:28,042 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:49:28,043 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:49:28,249 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:49:34,374 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:49:35,131 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:49:35,131 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:49:35,131 - root - INFO - QnAService initialized successfully
2025-04-04 15:49:35,131 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:49:35,132 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:49:35,132 - root - INFO - AIService initialized successfully
2025-04-04 15:49:35,154 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:49:35,154 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:49:35,154 - root - INFO - PDFService initialized successfully
2025-04-04 15:49:35,154 - root - INFO - Services initialized and passed to routes
2025-04-04 15:49:35,158 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 42.124 seconds
2025-04-04 15:49:35,160 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=103, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:49:35,178 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:49:35,183 - root - INFO - Shutting down the application...
2025-04-04 15:49:35,183 - src.services.rag_service - INFO - Cleaning up RAG service...
2025-04-04 15:49:35,184 - src.services.rag_service - INFO - RAG service cleaned up
2025-04-04 15:49:35,184 - root - INFO - RAG service cleaned up successfully
2025-04-04 15:49:35,184 - src.services.paper_search_service - INFO - Cleaning up PaperSearchService...
2025-04-04 15:49:35,184 - src.services.paper_search_service - INFO - PaperSearchService cleaned up
2025-04-04 15:49:35,184 - root - INFO - PaperSearchService cleaned up successfully
2025-04-04 15:49:35,184 - src.services.qna_service - INFO - Cleaning up QnAService...
2025-04-04 15:49:35,184 - src.services.qna_service - INFO - QnAService cleaned up
2025-04-04 15:49:35,184 - root - INFO - QnAService cleaned up successfully
2025-04-04 15:49:35,184 - src.services.crew_service - INFO - Cleaning up CrewAI service...
2025-04-04 15:49:35,184 - src.services.crew_service - INFO - CrewAI service cleaned up
2025-04-04 15:49:35,184 - root - INFO - CrewAIService cleaned up successfully
2025-04-04 15:49:35,184 - src.services.ai_service - INFO - Cleaning up AIService...
2025-04-04 15:49:35,184 - src.services.ai_service - INFO - AIService cleaned up
2025-04-04 15:49:35,184 - root - INFO - AIService cleaned up successfully
2025-04-04 15:49:35,185 - src.services.pdf_service - INFO - Cleaning up PDFService...
2025-04-04 15:49:35,185 - src.services.pdf_service - INFO - PDFService cleaned up
2025-04-04 15:49:35,185 - root - INFO - PDFService cleaned up successfully
2025-04-04 15:49:41,273 - root - INFO - Starting up the application...
2025-04-04 15:49:41,273 - root - INFO - Configuration validated successfully
2025-04-04 15:49:41,273 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:49:41,285 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:49:41,349 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:49:41,349 - root - INFO - RAG service initialized successfully
2025-04-04 15:49:41,349 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:53:21,617 - root - INFO - Starting up the application...
2025-04-04 15:53:21,617 - root - INFO - Configuration validated successfully
2025-04-04 15:53:21,617 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:53:21,629 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:53:21,751 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:53:21,751 - root - INFO - RAG service initialized successfully
2025-04-04 15:53:21,751 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:53:52,189 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:53:52,227 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:23:52.131449Z' done=True done_reason='stop' total_duration=30370822000 load_duration=15955625 prompt_eval_count=2 prompt_eval_duration=5492936417 eval_count=439 eval_duration=24856046250 message=Message(role='assistant', content=' :date: 2016-10-13\n   :modified: 2016-10-13\n\n=======================\nNaming conventions\n=======================\n\nThere are some naming conventions for functions, variables and data structures in python. For example, there is a convention that all function names should be written with lower case letters and separated by underscores if the name consists of several words: `function_name`.\n\nFor class names, capitalize the first letter and use camel case if the name consists of more than one word: `ClassName`. Here\'s an example of a class that models a car:\n\n.. code-block:: python\n\n    class Car:\n        def __init__(self, make, model, year):\n            self.make = make\n            self.model = model\n            self.year = year\n\n        def honk(self):\n            print("Beep")\n\nThere are no strict naming conventions in Python for variables and functions, except that the first character should be an underscore or a letter. Some people prefer to use lowercase letters only (snake case) while others prefer using capitalized letters with underscores (camelCase). The choice of a particular convention is up to you, but sticking to one convention consistently will make your code easier for other people to read.\n\nFor example, here\'s a simple program that uses snake case:\n\n.. code-block:: python\n\n    def function_name(x):\n        variable_name = x + 1\n        if variable_name > 5:\n            print(\'The number is greater than 5.\')\n        return variable_name\n\nHere\'s the equivalent program using camelCase:\n\n.. code-block:: python\n\n    def functionName(x):\n        varibleName = x + 1\n        if varibleName > 5:\n            print(\'The number is greater than 5.\')\n        return varibleName', images=None, tool_calls=None)
2025-04-04 15:53:52,228 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:53:52,232 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:53:52,232 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:53:52,232 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:53:52,299 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:53:58,127 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:54:01,288 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:54:01,288 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:54:01,289 - root - INFO - QnAService initialized successfully
2025-04-04 15:54:01,289 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:54:01,289 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:54:01,289 - root - INFO - AIService initialized successfully
2025-04-04 15:54:01,317 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:54:01,317 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:54:01,318 - root - INFO - PDFService initialized successfully
2025-04-04 15:54:01,318 - root - INFO - Services initialized and passed to routes
2025-04-04 15:54:01,321 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 39.704 seconds
2025-04-04 15:54:01,323 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:54:01,341 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:55:20,230 - root - INFO - Starting up the application...
2025-04-04 15:55:20,230 - root - INFO - Configuration validated successfully
2025-04-04 15:55:20,230 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:55:20,241 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:55:20,389 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:55:20,389 - root - INFO - RAG service initialized successfully
2025-04-04 15:55:20,389 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 15:56:25,523 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 15:56:25,553 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:26:25.477216Z' done=True done_reason='stop' total_duration=65076632250 load_duration=13931166 prompt_eval_count=2 prompt_eval_duration=4421610584 eval_count=1053 eval_duration=60633540750 message=Message(role='assistant', content="10-06-2021\n\n# 25 Fascinating Facts About the Great Barrier Reef\n\nThe Great Barrier Reef is not only Australia’s most famous natural wonder, but also one of the seven natural wonders of the world. It is a living organism that spans 1,430 miles (2,300 km) in northeastern Australia and protects the coastline with its vast coral formations.\n\nHere are 25 fascinating facts about the Great Barrier Reef:\n\n1. The Great Barrier Reef is so big it can be seen from outer space.\n2. The reef was formed around 20 million years ago by tiny marine organisms called corals. These corals live in colonies, building their homes out of calcium carbonate. Over millennia, these coral structures have grown and expanded to create the Great Barrier Reef as we know it today.\n3. The reef is home to an incredible amount of marine life. It hosts over 1,500 species of fish, more than 400 types of coral, and countless other creatures like sea turtles, sharks, and dolphins.\n4. There are thought to be around 30 different species of whale that visit the Great Barrier Reef.\n5. The reef is the world's largest single structure made by living organisms.\n6. It covers an area of approximately 133,000 square miles (344,000 km²). That’s almost twice the size of the United Kingdom!\n7. The Great Barrier Reef contains over 2,900 individual reef systems and 900 islands.\n8. The reef is a biodiversity hotspot, with about 1.5 million species of plants, animals, and marine life calling it home.\n9. The Great Barrier Reef is the largest coral reef system in the world. It’s so big that it can be seen from space!\n10. The Great Barrier Reef is made up of over 2,900 individual reefs and 900 islands.\n11. The Great Barrier Reef hosts an incredible variety of marine life, including more than 3,000 species of mollusk, over 600 types of starfish, 1,500 species of fish, and countless other creatures like sea turtles, sharks, and dolphins.\n12. The Great Barrier Reef is home to the world's largest coral reef system.\n13. It stretches for over 1,430 miles (2,300 km) along the northeastern coast of Australia.\n14. The Great Barrier Reef was formed around 20 million years ago by tiny marine organisms called corals. These corals live in colonies and build their homes out of calcium carbonate. Over time, these structures have grown and expanded to create the reef as we know it today.\n15. The Great Barrier Reef is a UNESCO World Heritage Site and one of the seven natural wonders of the world.\n16. It provides important habitat for many different species, including several that are threatened or endangered.\n17. Climate change is posing a major threat to the Great Barrier Reef. Rising sea temperatures and ocean acidification are causing coral bleaching events, which can kill large sections of the reef.\n18. The Great Barrier Reef is also under threat from pollution and overfishing.\n19. The Great Barrier Reef has suffered several major coral bleaching events in recent years, which have killed large sections of the reef.\n20. Coral bleaching occurs when the corals expel the algae that live inside their tissues, causing them to turn white. This can happen as a result of increased sea temperatures and ocean acidification.\n21. Coral bleaching events can have serious consequences for the Great Barrier Reef, as they can kill large sections of the reef and disrupt the food chain.\n22. The Great Barrier Reef is an important tourist destination, attracting millions of visitors each year.\n23. The Great Barrier Reef is also home to several Indigenous Australian cultures, who have lived in the area for thousands of years.\n24. The Great Barrier Reef is a vital part of Australia's economy, generating over $6 billion per year from tourism alone.\n25. Despite its many challenges, efforts are being made to protect and preserve the Great Barrier Reef. These include conservation initiatives, pollution reduction measures, and research projects aimed at understanding and addressing the threats facing the reef.", images=None, tool_calls=None)
2025-04-04 15:56:25,555 - root - INFO - CrewAIService initialized successfully
2025-04-04 15:56:25,558 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 15:56:25,558 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 15:56:25,558 - root - INFO - PaperSearchService initialized successfully
2025-04-04 15:56:25,645 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:56:31,362 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 15:56:32,312 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 15:56:32,312 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 15:56:32,312 - root - INFO - QnAService initialized successfully
2025-04-04 15:56:32,312 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 15:56:32,312 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 15:56:32,312 - root - INFO - AIService initialized successfully
2025-04-04 15:56:32,341 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 15:56:32,341 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 15:56:32,341 - root - INFO - PDFService initialized successfully
2025-04-04 15:56:32,341 - root - INFO - Services initialized and passed to routes
2025-04-04 15:56:32,345 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 72.114 seconds
2025-04-04 15:56:32,349 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 15:56:32,370 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 15:56:44,783 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 15:56:44,856 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 15:56:44,856 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 15:56:44,856 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 15:56:45,171 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 15:56:45,171 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 15:56:45,189 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 15:56:45,215 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 15:56:45,236 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/embeddings/api/generate "HTTP/1.1 404 Not Found"
2025-04-04 15:56:45,254 - root - ERROR - LiteLLM call failed: litellm.APIConnectionError: OllamaException - 404 page not found
2025-04-04 15:56:45,254 - src.services.crew_service - ERROR - Error in CrewAI analysis process: litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 107, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py", line 553, in post
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py", line 534, in post
    response.raise_for_status()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/httpx/_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/api/embeddings/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 2791, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 329, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 127, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 898, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 64, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2201, in exception_type
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2170, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-04-04 15:56:45,262 - src.services.qna_service - ERROR - Error calling LLM: Error in CrewAI analysis process: litellm.APIConnectionError: OllamaException - 404 page not found
2025-04-04 15:56:45,262 - src.services.qna_service - ERROR - Error answering question: Error in CrewAI analysis process: litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 107, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py", line 553, in post
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py", line 534, in post
    response.raise_for_status()
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/httpx/_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/api/embeddings/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 2791, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 329, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 127, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 898, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 64, in analyze_with_crew
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 640, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 752, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/crew.py", line 850, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 310, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 454, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/task.py", line 374, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 266, in execute_task
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agent.py", line 247, in execute_task
    result = self.agent_executor.invoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 119, in invoke
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 108, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 166, in _invoke_loop
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 146, in _invoke_loop
    answer = self._get_llm_response()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 216, in _get_llm_response
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py", line 207, in _get_llm_response
    answer = self.llm.call(
             ^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 739, in call
    return self._handle_non_streaming_response(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/crewai/llm.py", line 575, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1154, in wrapper
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/utils.py", line 1032, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/main.py", line 3068, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2201, in exception_type
    raise e
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2170, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 185, in answer_question
    response = await self.call_llm(context=relevant_text, prompt=prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/qna_service.py", line 136, in call_llm
    return await self.crew_service.analyze_with_crew(system_prompt, full_prompt)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 69, in analyze_with_crew
    raise RuntimeError(f"Error in CrewAI analysis process: {str(e)}")
RuntimeError: Error in CrewAI analysis process: litellm.APIConnectionError: OllamaException - 404 page not found
2025-04-04 15:59:20,797 - root - INFO - Starting up the application...
2025-04-04 15:59:20,797 - root - INFO - Configuration validated successfully
2025-04-04 15:59:20,797 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 15:59:20,808 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 15:59:20,851 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 15:59:20,852 - root - INFO - RAG service initialized successfully
2025-04-04 15:59:20,852 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:01:03,367 - root - INFO - Starting up the application...
2025-04-04 16:01:03,367 - root - INFO - Configuration validated successfully
2025-04-04 16:01:03,367 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:01:03,379 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:01:03,496 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:01:03,496 - root - INFO - RAG service initialized successfully
2025-04-04 16:01:03,496 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:01:22,206 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:01:22,223 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:31:22.186349Z' done=True done_reason='stop' total_duration=18682831958 load_duration=18480792 prompt_eval_count=2 prompt_eval_duration=4441186833 eval_count=246 eval_duration=14220729959 message=Message(role='assistant', content=' A.K.A. Coccyx\n\n1. Definition: It is the smallest and lowest part of the vertebral column, which is found at the end of the spinal cord.\n2. Structure: The coccyx consists of four fused pieces of bone called vertebrae.\n3. Function: The coccyx acts as a support for the muscles that control bowel movements and urination. It also serves as a point of attachment for various ligaments and tendons.\n4. Pathologies: The most common pathology related to the coccyx is coccydynia, which is pain in the tailbone area. Other conditions include fractures, cysts, tumors, and infections.\n5. Treatment: Treatment for coccydynia usually involves conservative measures such as rest, ice, heat, physical therapy, and medications. In severe cases, surgery may be required.\n6. Interesting Fact: The coccyx is also known as the "tailbone" because it was believed to be a vestigial tail in humans. However, this idea has been debunked by modern science.', images=None, tool_calls=None)
2025-04-04 16:01:22,223 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:01:22,224 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:01:22,224 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:01:22,224 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:01:22,254 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:01:32,163 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:01:33,349 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:01:33,349 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:01:33,349 - root - INFO - QnAService initialized successfully
2025-04-04 16:01:33,349 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:01:33,349 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:01:33,349 - root - INFO - AIService initialized successfully
2025-04-04 16:01:33,366 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:01:33,366 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:01:33,366 - root - INFO - PDFService initialized successfully
2025-04-04 16:01:33,367 - root - INFO - Services initialized and passed to routes
2025-04-04 16:01:33,368 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 30.001 seconds
2025-04-04 16:01:33,370 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:01:33,376 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:02:30,468 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 16:02:30,546 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:02:30,546 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 16:02:30,546 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 16:02:31,133 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 16:02:31,134 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 16:02:31,147 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 16:02:31,162 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:02:56,429 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:02:56,511 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:02:56,619 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:02:56,619 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:02:56,715 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:02:56,726 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:02:56,736 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:03:18,037 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:03:18,075 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:03:18,117 - src.services.crew_service - INFO - CrewAI analysis process completed
2025-04-04 16:03:18,117 - src.services.qna_service - INFO - LLM response received
2025-04-04 16:03:18,121 - src.api.routes - ERROR - Error answering question: Object of type CrewOutput is not JSON serializable
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 131, in ask_question
    return jsonify(answer), 200
           ^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/json/__init__.py", line 47, in jsonify
    return current_app.json.response(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 214, in response
    f"{self.dumps(obj, **dump_args)}\n", mimetype=self.mimetype
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 179, in dumps
    return json.dumps(obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 121, in _default
    raise TypeError(f"Object of type {type(o).__name__} is not JSON serializable")
TypeError: Object of type CrewOutput is not JSON serializable
2025-04-04 16:03:18,182 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:03:18,207 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 47.080 seconds
2025-04-04 16:03:18,211 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:06:14,484 - root - INFO - Starting up the application...
2025-04-04 16:06:14,484 - root - INFO - Configuration validated successfully
2025-04-04 16:06:14,484 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:06:14,496 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:06:14,608 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:06:14,608 - root - INFO - RAG service initialized successfully
2025-04-04 16:06:14,608 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:06:45,752 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:06:45,779 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:36:45.718586Z' done=True done_reason='stop' total_duration=31108519250 load_duration=16257958 prompt_eval_count=2 prompt_eval_duration=4739029166 eval_count=457 eval_duration=26350759250 message=Message(role='assistant', content=' <template>\n  <div id="app" class="container">\n    <h1 class="center">{{ msg }}</h1>\n    <ul class="collection">\n      <li v-for="item in items" :key="item.id" @click="deleteItem(item)" class="collection-item">\n        {{ item.text }}\n      </li>\n    </ul>\n    <form id="add-todo">\n      <label for="newTodo">Add new todo</label><br>\n      <input type="text" v-model="newTodo"><br>\n      <button @click.prevent="addNewItem">Add Item</button>\n    </form>\n  </div>\n</template>\n\n<script>\nexport default {\n  data () {\n    return {\n      msg: \'Welcome to Your Vue.js App\',\n      items: [\n        {id:1, text:\'item1\'},\n        {id:2, text:\'item2\'},\n        {id:3, text:\'item3\'}\n      ],\n      newTodo:\'\'\n    }\n  },\n  methods:{\n    addNewItem(){\n      this.items.push({\n          id:this.items.length +1,\n          text: this.newTodo\n        });\n      this.newTodo = \'\';\n    },\n    deleteItem(item){\n      const index = this.items.indexOf(item);\n      if(index > -1) {\n        this.items.splice(index, 1);\n      }\n    }\n  }\n}\n</script>\n\n<style>\n#app {\n  font-family: \'Avenir\', Helvetica, Arial, sans-serif;\n  text-align: center;\n  color: #2c3e50;\n  margin-top: 60px;\n}\n.center{\n  text-align: center !important;\n}\n</style>', images=None, tool_calls=None)
2025-04-04 16:06:45,779 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:06:45,781 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:06:45,781 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:06:45,781 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:06:45,847 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:06:56,050 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:06:58,135 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:06:58,135 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:06:58,135 - root - INFO - QnAService initialized successfully
2025-04-04 16:06:58,136 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:06:58,136 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:06:58,136 - root - INFO - AIService initialized successfully
2025-04-04 16:06:58,152 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:06:58,153 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:06:58,153 - root - INFO - PDFService initialized successfully
2025-04-04 16:06:58,153 - root - INFO - Services initialized and passed to routes
2025-04-04 16:06:58,155 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 43.671 seconds
2025-04-04 16:06:58,157 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:06:58,168 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:08:51,101 - root - INFO - Shutting down the application...
2025-04-04 16:08:51,103 - src.services.rag_service - INFO - Cleaning up RAG service...
2025-04-04 16:08:51,103 - src.services.rag_service - INFO - RAG service cleaned up
2025-04-04 16:08:51,104 - root - INFO - RAG service cleaned up successfully
2025-04-04 16:08:51,104 - src.services.paper_search_service - INFO - Cleaning up PaperSearchService...
2025-04-04 16:08:51,104 - src.services.paper_search_service - INFO - PaperSearchService cleaned up
2025-04-04 16:08:51,104 - root - INFO - PaperSearchService cleaned up successfully
2025-04-04 16:08:51,104 - src.services.qna_service - INFO - Cleaning up QnAService...
2025-04-04 16:08:51,104 - src.services.qna_service - INFO - QnAService cleaned up
2025-04-04 16:08:51,104 - root - INFO - QnAService cleaned up successfully
2025-04-04 16:08:51,104 - src.services.crew_service - INFO - Cleaning up CrewAI service...
2025-04-04 16:08:51,104 - src.services.crew_service - INFO - CrewAI service cleaned up
2025-04-04 16:08:51,105 - root - INFO - CrewAIService cleaned up successfully
2025-04-04 16:08:51,105 - src.services.ai_service - INFO - Cleaning up AIService...
2025-04-04 16:08:51,105 - src.services.ai_service - INFO - AIService cleaned up
2025-04-04 16:08:51,105 - root - INFO - AIService cleaned up successfully
2025-04-04 16:08:51,105 - src.services.pdf_service - INFO - Cleaning up PDFService...
2025-04-04 16:08:51,107 - src.services.pdf_service - INFO - PDFService cleaned up
2025-04-04 16:08:51,107 - root - INFO - PDFService cleaned up successfully
2025-04-04 16:11:44,213 - root - INFO - Starting up the application...
2025-04-04 16:11:44,213 - root - INFO - Configuration validated successfully
2025-04-04 16:11:44,214 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:11:44,225 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:11:44,333 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:11:44,333 - root - INFO - RAG service initialized successfully
2025-04-04 16:11:44,333 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:12:22,520 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:12:22,574 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:42:22.468694Z' done=True done_reason='stop' total_duration=38130118709 load_duration=15767334 prompt_eval_count=2 prompt_eval_duration=5985138833 eval_count=542 eval_duration=32123758708 message=Message(role='assistant', content=' <h3>Créer un compte</h3>\n    <form method="post" action="{{ url(\'/register\') }}">\n        @csrf\n\n        <div class="form-group{{ $errors->has(\'name\') ? \' has-error\' : \'\' }}">\n            <label for="name">Nom d\'utilisateur</label>\n            <input id="name" type="text" class="form-control" name="name" value="{{ old(\'name\') }}" required autofocus>\n\n            @if ($errors->has(\'name\'))\n                <span class="help-block">\n                    <strong>{{ $errors->first(\'name\') }}</strong>\n                </span>\n            @endif\n        </div>\n\n        <div class="form-group{{ $errors->has(\'email\') ? \' has-error\' : \'\' }}">\n            <label for="email">Adresse e-mail</label>\n            <input id="email" type="email" class="form-control" name="email" value="{{ old(\'email\') }}" required>\n\n            @if ($errors->has(\'email\'))\n                <span class="help-block">\n                    <strong>{{ $errors->first(\'email\') }}</strong>\n                </span>\n            @endif\n        </div>\n\n        <div class="form-group{{ $errors->has(\'password\') ? \' has-error\' : \'\' }}">\n            <label for="password">Mot de passe</label>\n            <input id="password" type="password" class="form-control" name="password" required>\n\n            @if ($errors->has(\'password\'))\n                <span class="help-block">\n                    <strong>{{ $errors->first(\'password\') }}</strong>\n                </span>\n            @endif\n        </div>\n\n        <div class="form-group">\n            <label for="password-confirm">Confirmation du mot de passe</label>\n            <input id="password-confirm" type="password" class="form-control" name="password_confirmation" required>\n        </div>\n\n        <div class="form-group">\n            <button type="submit" class="btn btn-primary">\n                Créer mon compte\n            </button>\n        </div>\n    </form>', images=None, tool_calls=None)
2025-04-04 16:12:22,576 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:12:22,578 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:12:22,578 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:12:22,578 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:12:22,698 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:12:33,877 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:12:39,398 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:12:39,398 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:12:39,398 - root - INFO - QnAService initialized successfully
2025-04-04 16:12:39,399 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:12:39,399 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:12:39,399 - root - INFO - AIService initialized successfully
2025-04-04 16:12:39,415 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:12:39,415 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:12:39,415 - root - INFO - PDFService initialized successfully
2025-04-04 16:12:39,416 - root - INFO - Services initialized and passed to routes
2025-04-04 16:12:39,419 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 55.206 seconds
2025-04-04 16:12:39,422 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:12:39,437 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:13:00,730 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 16:13:00,793 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:13:00,793 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 16:13:00,793 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 16:13:01,171 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 16:13:01,171 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 16:13:01,188 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 16:13:01,212 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:13:23,347 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:13:23,472 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:13:23,546 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:13:23,547 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:13:23,588 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:13:23,597 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:13:23,609 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:13:42,978 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:13:43,007 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:13:43,038 - src.services.crew_service - INFO - CrewAI analysis process completed
2025-04-04 16:13:43,039 - src.services.qna_service - INFO - LLM response received
2025-04-04 16:13:43,059 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 41.888 seconds
2025-04-04 16:13:43,060 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:13:43,067 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:14:47,025 - root - INFO - Starting up the application...
2025-04-04 16:14:47,025 - root - INFO - Configuration validated successfully
2025-04-04 16:14:47,025 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:14:47,037 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:14:47,168 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:14:47,168 - root - INFO - RAG service initialized successfully
2025-04-04 16:14:47,168 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:15:23,647 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:15:23,677 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:45:23.600277Z' done=True done_reason='stop' total_duration=36424362500 load_duration=13743500 prompt_eval_count=2 prompt_eval_duration=2578852500 eval_count=620 eval_duration=33822810958 message=Message(role='assistant', content=' I was born and raised in Brooklyn, New York. My mother moved us from the projects to a better neighborhood when I was two years old. She worked multiple jobs and went back to school so that we could have more opportunities. My father served in the military, he was proud of his service but never wanted to talk about it. When I was 10 years old my mom remarried to a loving man who she had known all her life and they had two more children together. He worked hard as a mailman so that we could have a better life, he did not grow up with much but always pushed us to do better and be better than him.\n\n   I went to a private school for middle and high school on scholarship. My teachers pushed me and made me want to learn. I graduated from Brooklyn Technical High School with 100% college scholarships, the first in my family to go to college. I received my Bachelors of Science degree in Biology from the University at Albany (SUNY). Then went on to receive my Masters in Physician Assistant Studies from the University of the Sciences in Philadelphia and my Doctorate of Health Science from East Carolina University Brody School of Medicine.\n\n   I have practiced as a physician assistant for 15 years. The last 6 years I worked at Johns Hopkins Hospital as an advanced clinical practitioner. When I started working there, they had one of the best residency programs in the country, but no program specifically designed to help doctors with addiction and mental illness. As I practiced medicine, I became more aware of the opioid epidemic in this country and how it affected physicians as well as patients. So, along with my colleagues at Hopkins, we created a residency program focused on addiction and mental health for physicians. We wanted to help doctors who needed help and not lose them to the system because of their addiction or mental illness.\n\n   I started practicing yoga 15 years ago to alleviate stress from work. The more I practiced, the better my life became in all areas. My practice helped me to stay focused during exams, calm when making important decisions, and centered when dealing with difficult patients. In fact, it changed my whole life for the better.\n\n   I decided to become a yoga teacher so that I can share this incredible gift with others who may be struggling in their lives. My goal is to create a safe space where people can come and practice, leaving their worries behind and finding peace within themselves. I want to help them to find balance and contentment through the practice of yoga, as it has done for me.\n\n   I also plan on using my medical knowledge to help those with addiction and mental illness who are struggling. Yoga is an amazing tool that can aid in recovery, but it must be paired with appropriate medical treatment. By combining my two passions: medicine and yoga, I hope to make a positive impact on the lives of others.', images=None, tool_calls=None)
2025-04-04 16:15:23,678 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:15:23,681 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:15:23,681 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:15:23,681 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:15:23,741 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:15:26,129 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:15:26,841 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:15:26,841 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:15:26,841 - root - INFO - QnAService initialized successfully
2025-04-04 16:15:26,842 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:15:26,842 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:15:26,842 - root - INFO - AIService initialized successfully
2025-04-04 16:15:26,866 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:15:26,867 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:15:26,867 - root - INFO - PDFService initialized successfully
2025-04-04 16:15:26,867 - root - INFO - Services initialized and passed to routes
2025-04-04 16:15:26,870 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 39.845 seconds
2025-04-04 16:15:26,872 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:15:26,890 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:16:28,176 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 16:16:28,271 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:16:28,272 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 16:16:28,272 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 16:16:28,586 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 16:16:28,586 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 16:16:28,603 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 16:16:28,622 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:16:52,064 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:16:52,127 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:16:52,178 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:16:52,178 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:16:52,209 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:16:52,215 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:16:52,220 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:17:12,647 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:17:12,674 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:17:12,703 - src.services.crew_service - INFO - CrewAI analysis process completed
2025-04-04 16:17:12,704 - src.services.qna_service - INFO - LLM response received
2025-04-04 16:17:12,733 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 44.147 seconds
2025-04-04 16:17:12,758 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:17:12,772 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:22:46,433 - root - INFO - Starting up the application...
2025-04-04 16:22:46,433 - root - INFO - Configuration validated successfully
2025-04-04 16:22:46,433 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:22:46,444 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:22:46,561 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:22:46,561 - root - INFO - RAG service initialized successfully
2025-04-04 16:22:46,561 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:23:20,991 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:23:21,063 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:53:20.813611Z' done=True done_reason='stop' total_duration=34248042209 load_duration=4075424250 prompt_eval_count=2 prompt_eval_duration=5202472083 eval_count=431 eval_duration=24958588250 message=Message(role='assistant', content='29 June 2018, India:\n\nA US-based e-commerce giant Amazon is planning to set up a research and development (R&D) centre in Hyderabad. The company intends to invest $50 million on the new facility.\n\nAmazon already operates two R&D centres in India at Bengaluru and Hyderabad. Its R&D unit in Hyderabad focuses on areas such as artificial intelligence, machine learning, data analytics, and big data. The new centre will be the third one by Amazon in India to carry out R&D activities.\n\n“We are committed to increasing our investments in India. We have been here for 13 years and we will continue to invest more and grow. The government has created a very good environment for us to thrive, and that is why we’re investing more,” said Akash Puri, director of engineering at Amazon, during a media briefing on Wednesday.\n\nThe company also announced the hiring of 10,000 people in India over the next 18 months as part of its global expansion plans. This includes software development engineers, cloud services experts and artificial intelligence professionals. It currently employs over 35,000 people across the country.\n\nIn April this year, Amazon said it will invest $5 billion to build a network of data centres in India over the next several years. The company has also been working on its food delivery business in partnership with local startup Foodpanda and has announced plans to open more grocery stores under the brand Amazon Go.\n\nThe e-commerce giant competes with homegrown Flipkart, which is backed by Walmart Inc., Alibaba Group Holding Ltd and SoftBank Group Corp. The U.S.-China trade dispute could hurt Alibaba, according to analysts, as the e-commerce company is heavily dependent on China for its growth, making it vulnerable to any slowdown in the country’s economy.\n\n(Image – Amazon)', images=None, tool_calls=None)
2025-04-04 16:23:21,065 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:23:21,068 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:23:21,068 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:23:21,068 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:23:21,151 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:23:23,704 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:23:25,733 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:23:25,733 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:23:25,733 - root - INFO - QnAService initialized successfully
2025-04-04 16:23:25,733 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:23:25,733 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:23:25,733 - root - INFO - AIService initialized successfully
2025-04-04 16:23:25,759 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:23:25,759 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:23:25,759 - root - INFO - PDFService initialized successfully
2025-04-04 16:23:25,759 - root - INFO - Services initialized and passed to routes
2025-04-04 16:23:25,762 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 39.328 seconds
2025-04-04 16:23:25,764 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=59, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:23:25,781 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:23:32,112 - root - INFO - Starting up the application...
2025-04-04 16:23:32,112 - root - INFO - Configuration validated successfully
2025-04-04 16:23:32,112 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:23:32,123 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:23:32,195 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:23:32,195 - root - INFO - RAG service initialized successfully
2025-04-04 16:23:32,195 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:24:16,343 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:24:16,386 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:54:16.275953Z' done=True done_reason='stop' total_duration=44067738750 load_duration=16625167 prompt_eval_count=2 prompt_eval_duration=2151891875 eval_count=772 eval_duration=41893086375 message=Message(role='assistant', content=' <template>\n    <div class="page-wapper">\n      <Header title="登录"></Header>\n      <div style="margin: 0 auto;width:90%;margin-top:10px;">\n        <el-form :model="loginForm" :rules="rules" ref="loginForm" label-width="100px">\n          <el-form-item label="用户名" prop="username">\n            <el-input v-model.trim="loginForm.username"></el-input>\n          </el-form-item>\n          <el-form-item label="密码" prop="password">\n            <el-input type="password" v-model="loginForm.password"></el-input>\n          </el-form-item>\n          <el-form-item>\n            <el-button type="primary" @click="submitLoginForm(\'loginForm\')">登录</el-button>\n            <el-link :underline="false" style="float: right;margin-right:20px;" @click="$router.push({name:\'register\'})">还没有账号，去注册</el-link>\n          </el-form-item>\n        </el-form>\n      </div>\n    </div>\n  </template>\n\n<script>\nimport Header from "../components/Header.vue";\nexport default {\n  name: "Login",\n  components: {\n    Header,\n  },\n  data() {\n    return {\n      loginForm: {\n        username: "",\n        password: "",\n      },\n      rules: {\n        username: [\n          { required: true, message: "请输入用户名", trigger: "blur" },\n          { min: 3, max: 10, message: "长度在 3 到 10 个字符", trigger: "blur" },\n        ],\n        password: [\n          { required: true, message: "请输入密码", trigger: "blur" },\n          { min: 6, max: 12, message: "长度在 6 到 12 个字符", trigger: "blur" },\n        ],\n      },\n    };\n  },\n  methods: {\n    submitLoginForm(formName) {\n      this.$refs[formName].validate((valid) => {\n        if (valid) {\n          const user = this.loginForm;\n          const loginFn = this.$api.user.login;\n          this.$http.post(loginFn, user).then((res) => {\n            if (res.code === 200) {\n              localStorage.setItem("token", res.data);\n              this.$message({\n                message: "登录成功",\n                type: "success",\n              });\n              this.$router.push({ name: "home" });\n            } else {\n              this.$message.error(res.msg);\n            }\n          });\n        } else {\n          console.log("error submit!!");\n          return false;\n        }\n      });\n    },\n  },\n};\n</script>\n\n<style lang="less" scoped>\n.page-wapper {\n  background: #f2f3f4;\n}\n</style>', images=None, tool_calls=None)
2025-04-04 16:24:16,389 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:24:16,395 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:24:16,395 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:24:16,395 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:24:16,510 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:24:25,689 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:24:30,510 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:24:30,510 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:24:30,510 - root - INFO - QnAService initialized successfully
2025-04-04 16:24:30,510 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:24:30,510 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:24:30,511 - root - INFO - AIService initialized successfully
2025-04-04 16:24:30,530 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:24:30,531 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:24:30,531 - root - INFO - PDFService initialized successfully
2025-04-04 16:24:30,531 - root - INFO - Services initialized and passed to routes
2025-04-04 16:24:30,535 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 58.423 seconds
2025-04-04 16:24:30,537 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=67, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:24:30,562 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:24:36,595 - root - INFO - Starting up the application...
2025-04-04 16:24:36,595 - root - INFO - Configuration validated successfully
2025-04-04 16:24:36,595 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:24:36,607 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:24:36,677 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:24:36,677 - root - INFO - RAG service initialized successfully
2025-04-04 16:24:36,677 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:25:33,384 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:25:33,424 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T10:55:33.344597Z' done=True done_reason='stop' total_duration=56651509250 load_duration=17589208 prompt_eval_count=2 prompt_eval_duration=1811389666 eval_count=970 eval_duration=54811480584 message=Message(role='assistant', content=' This page describes how to use the `npm` command-line interface (CLI) for a basic project, and provides some guidelines on best practices.\n\n---\n\n## Setting up your environment\n\nTo set up your environment for using `npm`, make sure you have [Node.js](https://nodejs.org/) installed on your computer. After installing Node.js, check the version by running the following command:\n\n```bash\nnode -v\n```\n\nThis should return the version of Node.js that is currently installed. You can also use nvm (Node Version Manager) for managing different versions of node easily. Follow the instructions at https://github.com/nvm-sh/nvm to install and configure it.\n\nNext, make sure you have `npm` installed as well:\n\n```bash\nnpm -v\n```\n\nIf `npm` is not installed or if it\'s an outdated version, you can install it using Node.js package manager by running the following command:\n\n```bash\nnpm install npm@latest -g\n```\n\nReplace `-g` with `--global` if you\'re on Windows.\n\n## Creating a new project\n\nCreate a new directory for your project, then navigate to that directory in the terminal:\n\n```bash\nmkdir my-project && cd my-project\n```\n\nInitialize the project as an npm package by running `npm init`:\n\n```bash\nnpm init\n```\n\nFollow the prompts, filling out the name, description, entry point, and other information for your new project. This will create a new `package.json` file in your project\'s root directory, which contains metadata about your package and lists its dependencies.\n\n## Installing dependencies\n\nIn most projects, you\'ll need to install one or more packages as dependencies. To do so, first find the desired package on npmjs.com ([https://www.npmjs.com/](https://www.npmjs.com/)) and note its name. Next, use `npm` to install the package locally in your project:\n\n```bash\nnpm install <package-name>\n```\n\nReplace `<package-name>` with the actual name of the package you want to install. This command will add a new entry to the "dependencies" section of your `package.json` file, ensuring that the correct version of the package is installed when others install your project from npm.\n\n## Running scripts\n\nYou can define custom scripts in the `scripts` section of your `package.json` file. These scripts can be run using `npm run <script-name>`. For example, if you have a script called "start" that runs your application, you can use it to start your app by running:\n\n```bash\nnpm run start\n```\n\n## Updating dependencies\n\nTo update the dependencies in your project, run `npm update`. This will update all listed dependencies to their latest versions and add any new dependencies that were added since you last updated.\n\nIf you want to update a specific dependency, you can do so by running:\n\n```bash\nnpm update <package-name>\n```\n\nThis will only update the specified package to its latest version without changing the versions of other packages.\n\n## Best practices\n\n1. Keep your `package.json` file up-to-date and minimize the number of dependencies you list, as each dependency increases the size of your bundle and can introduce potential security risks.\n2. Use npm\'s `devDependencies` field for any packages that are only needed during development, such as linters or build tools. This keeps your production bundle smaller by excluding these packages when it\'s built.\n3. Use semantic versioning ([http://semver.org/](http://semver.org/)) to ensure consistent and predictable behavior across versions of your package.\n4. Use the `preinstall` and `postinstall` scripts in your `package.json` file to perform any necessary setup or cleanup when installing your package, such as creating directories, building assets, or running tests.\n5. Always run `npm audit` before publishing a new version of your package to identify and fix any potential security vulnerabilities in your dependencies.', images=None, tool_calls=None)
2025-04-04 16:25:33,426 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:25:33,431 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:25:33,431 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:25:33,431 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:25:33,489 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:25:38,838 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:25:39,691 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:25:39,691 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:25:39,692 - root - INFO - QnAService initialized successfully
2025-04-04 16:25:39,692 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:25:39,692 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:25:39,692 - root - INFO - AIService initialized successfully
2025-04-04 16:25:39,710 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:25:39,711 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:25:39,711 - root - INFO - PDFService initialized successfully
2025-04-04 16:25:39,711 - root - INFO - Services initialized and passed to routes
2025-04-04 16:25:39,715 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 63.119 seconds
2025-04-04 16:25:39,717 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=75, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:25:39,731 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:25:48,755 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 16:25:48,866 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:25:48,867 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 16:25:48,867 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 16:25:49,155 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 16:25:49,155 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 16:25:49,175 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 16:25:49,198 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:26:15,281 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:26:15,345 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:26:15,407 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:26:15,409 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:26:15,455 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:26:15,461 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:26:15,467 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:26:35,414 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:26:35,463 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:26:35,562 - src.services.crew_service - INFO - CrewAI analysis process completed
2025-04-04 16:26:35,570 - src.services.qna_service - INFO - LLM response received
2025-04-04 16:26:35,603 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 46.447 seconds
2025-04-04 16:26:35,618 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:26:35,628 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:29:18,822 - root - INFO - Starting up the application...
2025-04-04 16:29:18,822 - root - INFO - Configuration validated successfully
2025-04-04 16:29:18,822 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:29:18,835 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:29:18,959 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:29:18,959 - root - INFO - RAG service initialized successfully
2025-04-04 16:29:18,959 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:30:22,943 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:30:23,020 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:00:22.844687Z' done=True done_reason='stop' total_duration=63880316917 load_duration=15923333 prompt_eval_count=2 prompt_eval_duration=3304099583 eval_count=1060 eval_duration=60551157583 message=Message(role='assistant', content="2018:  The year I am going to learn how to swim.\n\nI was never a water baby, in fact I'm pretty sure I was the land dwelling type. I don’t remember ever really enjoying being in the water. My childhood summer memories are of sandy beaches and paddling pools. Not the pool or sea. So it is a bit of a surprise to me that when I was a kid, my parents sent me on a two week long camping holiday with my uncle to Cornwall where we spent every day at the beach.\n\nWhen I look back on photos from our trips, I see a young child wrapped in a towel and sitting on the sandy beach staring out at the waves. It’s not until I see my Mum in the background that I remember she was there too. I think my mum must have been the one to push us into the water each day. She was an excellent swimmer; a keen diver who used to compete and could hold her breath for longer than anyone else I knew.\n\nI don’t really know what went wrong with me, but I never learnt to swim properly as a child.  I remember being in swimming lessons at school and sitting on the side and refusing to get into the water. It wasn't fear that stopped me. I just didn't want to do it.\n\nMy mum tried again when I was in my twenties but I was not convinced. She took me to a pool for an hour-long lesson, where she stood at the side with a towel and I practiced my backstroke with the instructor. I don’t even remember how many lessons we had but after that I never went swimming again until 2016 when I finally plucked up the courage to book myself on to the adult swimming course at my local pool.\n\nI had an incredible teacher, who encouraged me and helped me build my confidence with each new skill. By the end of the course I could swim a length of front crawl with the aid of flippers. It wasn't fast or pretty but it was a start!  I was even able to jump in at the deep end without feeling scared and I practiced my backstroke in open water for the first time on holiday.\n\nThen the following year (2017) I took another leap of faith and booked myself onto a triathlon training course. It was a 12 week programme, with weekly sessions at the pool to improve our swimming skills and technique, followed by an open water swim in the lake on Sundays.\n\nI was nervous about this as I have never been a confident swimmer but I had been working hard on my technique and wanted to see how it translated to open water. Open water was so different from swimming in the pool. There were waves, there were fish swimming around me and I couldn’t see my feet on the bottom anymore. I felt like I was swimming in circles for a while until I finally found the end of the lake and could touch down.\n\nBy the end of the course, I had swum 1500m in open water. This was a massive achievement for me, but not quite enough to complete the triathlon. I decided that this year (2018) would be my year. I was determined to finish the triathlon and I set out to train.\n\nI started with a regular 40 minute swim at the pool every Monday night and then as the weather improved, I moved my weekly training session outside on a Sunday morning. It was so much harder than swimming in the pool, as the lake is always choppy and windy but there were so many more benefits to swimming in open water that it was worth persevering.\n\nThe first benefit of open water swimming is you get to swim with nature. As I swam from one side of the lake to the other, I saw fish, ducks and even a heron floating on his back. The second benefit is that it feels like you have more space to move. In the pool there are always lanes criss-crossing your path but in open water you can swim wherever you want without bumping into anyone else.\n\nThe final benefit of swimming in open water is the confidence you gain from completing each length. When you swim in a lake, it takes more effort to keep yourself moving forward as there are waves and currents to contend with. So every length I completed gave me a huge boost of self-belief that I could do it!\n\nI didn't quite get round to doing the triathlon last year (2018) but I did complete my first ever open water swim on Sunday 26th August in the lake. It was hard work, but I managed to stay focused and kept swimming despite the cold water and wobbly legs. I even completed a length using my front crawl.\n\nIt wasn't easy but it was worth it! And I'm already looking forward to doing it again next year.", images=None, tool_calls=None)
2025-04-04 16:30:23,022 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:30:23,024 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:30:23,024 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:30:23,024 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:30:23,104 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:30:28,507 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:30:30,846 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:30:30,846 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:30:30,846 - root - INFO - QnAService initialized successfully
2025-04-04 16:30:30,846 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:30:30,846 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:30:30,846 - root - INFO - AIService initialized successfully
2025-04-04 16:30:30,871 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:30:30,872 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:30:30,872 - root - INFO - PDFService initialized successfully
2025-04-04 16:30:30,872 - root - INFO - Services initialized and passed to routes
2025-04-04 16:30:30,877 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 72.054 seconds
2025-04-04 16:30:30,879 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=93, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:30:30,901 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:30:38,146 - root - INFO - Starting up the application...
2025-04-04 16:30:38,146 - root - INFO - Configuration validated successfully
2025-04-04 16:30:38,146 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:30:38,158 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:30:38,234 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:30:38,234 - root - INFO - RAG service initialized successfully
2025-04-04 16:30:38,234 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:31:27,679 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:31:27,689 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:01:27.656008Z' done=True done_reason='stop' total_duration=49411746916 load_duration=14874083 prompt_eval_count=2 prompt_eval_duration=1910468750 eval_count=848 eval_duration=47481409166 message=Message(role='assistant', content=' [Back](../)\n# C++11: Templates\n\n## Template Types\n### Template Instantiation\n```cpp\ntemplate <typename Type>\nType square (Type x);\n\nint main() {\n  int i = 3;\n  float f = 4.5f;\n  cout << "square(3) = " << square(i) << endl; // 9\n  cout << "square(4.5) = " << square(f) << endl; // 20.25\n}\n```\n- The function `square()` is a *template*. It can take any data type as its argument and return the squared value of it.\n- In the above example, I\'ve used both an integer and a floating point to show that the template function will work for multiple types.\n- The template function is instantiated by the compiler when called with concrete types in the `main()` function.\n\n### Constraints on Template Types\n- Templates cannot be constrained to certain data types using inheritance as they can take any type (including user defined types) as parameters.\n- However, we can use a set of compile time conditions to check whether or not a given template instantiation is possible. For example:\n```cpp\ntemplate <typename Type>\nType max(const Type& x, const Type& y) {\n  if constexpr (std::is_integral<Type>::value) { // This is a new feature of C++11!\n    return std::max(x, y);\n  } else {\n    return x > y ? x : y;\n  }\n}\n```\n- The above function will compare integers and floats differently. For integral types (e.g. int) it uses the `std::max()` function, while for floating point types it performs a comparison itself using the greater than operator (`>`).\n- The condition inside the `if constexpr` block is a compile time check that checks whether or not the type being passed to the template is an integral type. If so, then the rest of the code within the block will be executed. If not, the second branch of the if statement will be executed.\n\n### Default Template Parameters\n- We can also provide default values for our template parameters. The syntax for this looks like:\n```cpp\ntemplate <typename Type = int>\nType max(const Type& x, const Type& y) {\n  // ...\n}\n```\n- In the above example, the template takes an optional type parameter which defaults to `int`. This means that if you don\'t specify a type when calling the function, it will use int as the type.\n\n### Explicit Template Instantiation\n- If your template contains recursive functions or large loops and you want the compiler to only instantiate specific instances of the template, you can explicitly request instantiation by using the `template` keyword followed by the namespace scope:\n```cpp\n#include <iostream>\nusing namespace std;\n\ntemplate<typename Type>\nType max(const Type& x, const Type& y) {\n  return x > y ? x : y;\n}\n\ntemplate<>\nint max<float>(const float& x, const float& y); // Explicit instantiation for the float type\n\nint main() {\n  cout << "max(3, 4) = " << max<int>(3, 4) << endl; // 4\n  cout << "max(3.0f, 2.5f) = " << max(3.0f, 2.5f) << endl; // 3 (explicit instantiation!)\n}\n```\n- In the above example I\'ve explicitly told the compiler to use a specific instantiation of my template function for a float when calling it in `main()`.', images=None, tool_calls=None)
2025-04-04 16:31:27,690 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:31:27,692 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:31:27,692 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:31:27,692 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:31:27,724 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:31:30,602 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:31:31,413 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:31:31,413 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:31:31,413 - root - INFO - QnAService initialized successfully
2025-04-04 16:31:31,413 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:31:31,413 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:31:31,414 - root - INFO - AIService initialized successfully
2025-04-04 16:31:31,434 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:31:31,434 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:31:31,435 - root - INFO - PDFService initialized successfully
2025-04-04 16:31:31,435 - root - INFO - Services initialized and passed to routes
2025-04-04 16:31:31,436 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 53.290 seconds
2025-04-04 16:31:31,437 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=101, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:31:31,444 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:31:57,585 - src.services.qna_service - INFO - Querying collection for prompt: What is the main topic of this paper?
2025-04-04 16:31:57,701 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:31:57,701 - src.services.qna_service - INFO - Query results received: 1 documents
2025-04-04 16:31:57,701 - src.services.qna_service - INFO - Re-ranking documents with cross-encoder
2025-04-04 16:31:58,468 - src.services.qna_service - INFO - Re-ranking complete. Relevant text length: 63502
2025-04-04 16:31:58,469 - src.services.qna_service - INFO - Calling LLM for response
2025-04-04 16:31:58,487 - src.services.crew_service - INFO - Starting CrewAI analysis process
2025-04-04 16:31:58,506 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:32:25,121 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:32:25,213 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:32:25,324 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:25,325 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:25,385 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 16:32:25,393 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:25,400 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:47,996 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 16:32:48,042 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 16:32:48,112 - src.services.crew_service - INFO - CrewAI analysis process completed
2025-04-04 16:32:48,114 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:48,117 - src.services.qna_service - INFO - LLM response received
2025-04-04 16:32:48,184 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 16:32:48,213 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 49.745 seconds
2025-04-04 16:34:29,640 - src.services.rag_service - INFO - Document retrieved from cache: 10.1371journal.pone.0231708.pdf
2025-04-04 16:34:29,641 - src.api.routes - ERROR - Error during summarization: 'NoneType' object is not callable
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 167, in summarize
    summary = await summarize_text(text, level)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable
2025-04-04 16:36:26,500 - root - INFO - Starting up the application...
2025-04-04 16:36:26,500 - root - INFO - Configuration validated successfully
2025-04-04 16:36:26,500 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:36:26,512 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:36:26,628 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:36:26,628 - root - INFO - RAG service initialized successfully
2025-04-04 16:36:26,628 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:38:49,642 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:38:49,679 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:08:49.546669Z' done=True done_reason='stop' total_duration=142913359584 load_duration=16422834 prompt_eval_count=2 prompt_eval_duration=3736088458 eval_count=2248 eval_duration=139156629333 message=Message(role='assistant', content=' The Duck Commander Family is a household name across America thanks to the popularity of their hit TV show Duck Dynasty. The family-run business was started by Phil Robertson, his wife Kay, and their son Willie. Together they built a successful duck call company that eventually led to the creation of Duck Commander Productions, which produces the popular A&E television series.\n\nDespite the family\'s success, their story didn\'t begin with millions of dollars or fame. It started with hard work and determination in the swamps of Louisiana. In this article, we\'ll explore the history of the Duck Commander Family, their journey to success, and some interesting facts about each member of the family.\n\n## Early Life and Origins of the Duck Commander Family\n\nThe Robertson family can trace their roots back to Williamson County, Tennessee, where Phil Robertson\'s great-great-grandfather, Elias Camp, was a founding member of the Methodist Church in 1825. Phil was born on July 22, 1946, in West Monroe, Louisiana, the second child of Jeanette and Pete Robertson. He grew up in a loving family with three siblings: Phyllis, John, and Bobby.\n\nPhil\'s father, Pete, worked as a sharecropper, and the family lived a simple life in a small farmhouse. The children helped their parents with the daily chores, and Phil developed a strong work ethic at an early age. He attended West Monroe High School but left before graduating to join the U.S. Navy.\n\nWhile serving in the military, Phil married his high school sweetheart, Kay, on June 6, 1965. They settled down in the Louisiana bayou and raised their four sons: Willie, Jase, Alan, and Si. Like their father, the boys grew up working hard on the family\'s farm and developing a passion for the outdoors.\n\n## The Birth of Duck Commander\n\nIn 1972, Phil had a vision to create duck calls that mimicked the sounds ducks make in the wild. He spent countless hours experimenting with different materials and designs until he finally perfected his duck call. With a $400 loan from Kay, Phil founded Duck Commander and began selling his duck calls at sporting goods stores.\n\nThe business was slow to take off, but Phil\'s persistence paid off when he landed a significant order from a local store in 1978. This helped him pay off the family\'s debts and provided enough money for him to quit his job as an assistant coach at Louisiana Tech University. From that point on, Duck Commander became the Robertson family\'s primary source of income.\n\nAs Phil continued to refine his product, he also developed a unique sales strategy: he would go directly to the hunters who frequented the swamps and sell them his duck calls in person. This hands-on approach helped build relationships with customers and solidify Duck Commander\'s reputation for quality products.\n\n## The Rise of Duck Dynasty\n\nIn 2008, Willie Robertson approached his brother Jase about the idea of creating a reality TV show based on their family and their business. They pitched the idea to the producers at A&E, who were immediately intrigued by the quirky, down-to-earth nature of the Robertsons. The network gave them a chance, and Duck Dynasty was born.\n\nThe show premiered on March 3, 2010, and quickly became a ratings juggernaut. Viewers were drawn to the family\'s humor, Southern charm, and genuine love for one another. Each episode followed the Robertsons as they navigated their busy lives, which included running Duck Commander, hunting, fishing, and spending time together as a family.\n\nDuck Dynasty became an instant hit, averaging 11.8 million viewers per episode during its peak in 2013. The show helped launch the careers of Willie, Jase, Si, and their cousin, Uncle Si, who quickly became fan favorites. The Robertsons also gained a massive social media following, with millions of followers on platforms like Facebook and Twitter.\n\n## Controversies and Setbacks\n\nDespite the success of Duck Dynasty, the Robertson family has faced its fair share of controversies. In 2013, Phil made headlines for a GQ interview in which he expressed his conservative views on homosexuality and same-sex marriage. A&E suspended him from the show, but the outcry from fans was so great that they quickly reinstated him.\n\nIn 2015, Willie faced criticism when he refused to renew a contract with a company that made shirts with the Confederate flag on them. The decision was met with backlash from some fans, but Willie stood firm in his belief that the symbol was offensive and divisive.\n\nAnother controversy erupted in 2017 when Phil\'s book "Happy, Happy, Happy" was banned by Walmart due to explicit content. The decision sparked a debate about freedom of speech and censorship, with some fans defending Phil\'s right to express his opinions while others criticized the book\'s content as offensive and inappropriate.\n\n## Phil Robertson: The Patriarch\n\nPhil is the patriarch of the Duck Commander Family and the founder of the business that made them famous. Known for his outspoken nature, Phil has never shied away from expressing his conservative views on politics, religion, and culture. He is a devout Christian and often speaks openly about his faith in interviews and on social media.\n\nDespite his controversial statements, Phil remains a beloved figure to many fans of Duck Dynasty. He is known for his humor, Southern drawl, and quick wit, as well as his love for hunting and the outdoors. In 2016, he published his autobiography "Happy, Happy, Happy: My Life and Legacy in the Bayou," which details his upbringing, his journey to founding Duck Commander, and his family\'s rise to fame.\n\n## Kay Robertson: The Matriarch\n\nKay is the wife of Phil and the mother of Willie, Jase, Alan, and Si. She grew up in a Baptist church in West Monroe and met Phil while they were both attending high school. After marrying in 1965, Kay became a homemaker and raised her four boys with Phil\'s help.\n\nAlthough she is often portrayed as the quiet one on Duck Dynasty, Kay is a strong, compassionate woman who plays an essential role in keeping the family together. She is known for her cooking skills, particularly her famous gumbo recipe, and her love for her family. In 2016, she published a cookbook titled "Miss Kay\'s Duck Commander Kitchen: Family Recipes and Secret Eats."\n\n## Willie Robertson: The CEO\n\nWillie is the eldest son of Phil and Kay and the current CEO of Duck Commander. After graduating from Louisiana Tech University with a degree in finance, Willie joined the family business full-time in 2001. He took over as CEO in 2007 and has since grown the company into a multimillion-dollar enterprise.\n\nIn addition to his role at Duck Commander, Willie is also the star of Duck Dynasty and has become a household name across America. He is married to Korie, with whom he has five children: John Luke, Sadie, Bella, Rebecca, and Willie Alexander. Together they run their own production company, Buck Commander Productions, which produces hunting-related content for television and social media.\n\n## Jase Robertson: The Outdoorsman\n\nJase is the second eldest son of Phil and Kay and the brother of Willie. He is known for his love of the outdoors, particularly hunting and fishing. On Duck Dynasty, Jase often serves as the comic relief with his witty remarks and prankster antics.\n\nIn 2013, Jase married Missy, with whom he has four children: Reed, Mia, Priscilla, and Coleman. The couple runs their own production company, Buck Commander Productions, alongside Willie and Korie. In addition to their TV work, they also run a hunting lodge in West Monroe called Buck Hollow Lodge.\n\n## Alan Robertson: The Minister\n\nAlan is the third son of Phil and Kay and a brother to Willie and Jase. He attended Baylor University on a football scholarship but left after his freshman year to join Duck Commander full-time. In 2015, he was ordained as a minister at White\'s Ferry Road Church in West Monroe.\n\nAlan is married to Lisa, with whom he has three children: Alexander, Lulu, and Merritt. The family moved to Florida in 2014, where Alan continues to serve as a pastor while also working for Duck Commander part-time.\n\n## Si Robertson: The Entertainer\n\nSi is the fourth son of Phil and Kay and the brother of Willie, Jase, and Alan. He is known for his eccentric personality, love of camouflage, and catchphrase "si-ver." On Duck Dynasty, Si often serves as the comic relief with his offbeat humor and antics.\n\nIn 2013, Si married Christine, with whom he has four children: Scott, Scottie, Brittany, and Daniella. The couple runs a camouflage clothing line called Si Camo. They also have their own reality show, "The Duck Commander Family," which focuses on their day-to-day life in West Monroe.\n\n## The Duck Commander Family: A Legacy of Success\n\nThe Duck Commander Family has become a household name thanks to the success of their business and reality TV show. Despite facing controversies along the way, they remain a beloved figure to many fans across America. Through hard work, determination, and a strong family bond, the Robertsons have built a legacy that will endure for generations to come.', images=None, tool_calls=None)
2025-04-04 16:38:49,681 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:38:49,684 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:38:49,684 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:38:49,684 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:38:49,749 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:38:57,402 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:38:59,742 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:38:59,742 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:38:59,743 - root - INFO - QnAService initialized successfully
2025-04-04 16:38:59,743 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:38:59,743 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:38:59,743 - root - INFO - AIService initialized successfully
2025-04-04 16:38:59,765 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:38:59,766 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:38:59,766 - root - INFO - PDFService initialized successfully
2025-04-04 16:38:59,766 - root - INFO - Services initialized and passed to routes
2025-04-04 16:38:59,769 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 153.269 seconds
2025-04-04 16:38:59,771 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=119, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:38:59,790 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:40:05,540 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:40:05,541 - src.api.routes - ERROR - Error during summarization: 'NoneType' object is not callable
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 167, in summarize
    summary = await summarize_text(text, level)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable
2025-04-04 16:45:38,627 - root - INFO - Starting up the application...
2025-04-04 16:45:38,627 - root - INFO - Configuration validated successfully
2025-04-04 16:45:38,627 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:45:38,639 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:45:38,687 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:45:38,687 - root - INFO - RAG service initialized successfully
2025-04-04 16:45:38,687 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:46:03,423 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:46:03,437 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:16:03.405556Z' done=True done_reason='stop' total_duration=24713158417 load_duration=4079337125 prompt_eval_count=2 prompt_eval_duration=5007095750 eval_count=271 eval_duration=15623594583 message=Message(role='assistant', content='07/23/16\n\nWelcome to the website of the SUNY Potsdam Department of Music! Thank you for stopping by. Our department offers a wealth of musical opportunities in both performance and academic pursuits. As you navigate our site, we hope that you will find information about our programs, faculty, and facilities as well as our community outreach initiatives. We invite you to contact us with any questions or requests for additional information.\n\nOur performance program offers study in Music Education, Performance, and Music Therapy. The academic program allows students to earn a Bachelor of Arts (B.A.) degree or a Bachelor of Science (B.S.) degree in Music, while minors in Music are also available to non-majors.\n\nFor our current students: be sure to check out the SUNY Potsdam Music Facebook page for the latest announcements about events and news on campus! We invite you to join us this year at one of the many concerts, recitals, opera productions, and other exciting musical performances that take place in the Department of Music each semester.\n\nWe look forward to seeing our returning students, faculty, staff and friends, and hope that you will enjoy exploring what we have to offer here at SUNY Potsdam!', images=None, tool_calls=None)
2025-04-04 16:46:03,437 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:46:03,438 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:46:03,438 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:46:03,438 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:46:03,474 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:46:08,166 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:46:09,101 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:46:09,102 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:46:09,102 - root - INFO - QnAService initialized successfully
2025-04-04 16:46:09,102 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:46:09,102 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:46:09,102 - root - INFO - AIService initialized successfully
2025-04-04 16:46:09,119 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:46:09,119 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:46:09,119 - root - INFO - PDFService initialized successfully
2025-04-04 16:46:09,119 - root - INFO - Services initialized and passed to routes
2025-04-04 16:46:09,124 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 30.497 seconds
2025-04-04 16:46:09,127 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=131, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:46:09,144 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:46:18,357 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:46:18,357 - src.services.ai_service - INFO - Starting summarization with level: intermediate
2025-04-04 16:46:18,357 - src.services.crew_service - ERROR - Error creating agents
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 84, in create_agents
    llm=self.llm,
        ^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'llm'
2025-04-04 16:46:18,360 - src.services.crew_service - ERROR - Error in CrewAI summarization process: Error creating agents: 'CrewAIService' object has no attribute 'llm'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 84, in create_agents
    llm=self.llm,
        ^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'llm'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 147, in summarize_with_crew
    researcher, writer, editor = await self.create_agents()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 109, in create_agents
    raise RuntimeError(f"Error creating agents: {str(e)}")
RuntimeError: Error creating agents: 'CrewAIService' object has no attribute 'llm'
2025-04-04 16:46:18,360 - src.services.ai_service - ERROR - Error generating summary with CrewAI: Error in CrewAI summarization process: Error creating agents: 'CrewAIService' object has no attribute 'llm'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 84, in create_agents
    llm=self.llm,
        ^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'llm'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 147, in summarize_with_crew
    researcher, writer, editor = await self.create_agents()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 109, in create_agents
    raise RuntimeError(f"Error creating agents: {str(e)}")
RuntimeError: Error creating agents: 'CrewAIService' object has no attribute 'llm'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/ai_service.py", line 36, in summarize_text
    summary = await asyncio.wait_for(
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 179, in summarize_with_crew
    raise RuntimeError(f"Error in CrewAI summarization process: {str(e)}")
RuntimeError: Error in CrewAI summarization process: Error creating agents: 'CrewAIService' object has no attribute 'llm'
2025-04-04 16:46:18,361 - src.api.routes - ERROR - Error during summarization: Error in CrewAI summarization process: Error creating agents: 'CrewAIService' object has no attribute 'llm'
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 84, in create_agents
    llm=self.llm,
        ^^^^^^^^
AttributeError: 'CrewAIService' object has no attribute 'llm'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 147, in summarize_with_crew
    researcher, writer, editor = await self.create_agents()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 109, in create_agents
    raise RuntimeError(f"Error creating agents: {str(e)}")
RuntimeError: Error creating agents: 'CrewAIService' object has no attribute 'llm'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 171, in summarize
    summary = await ai_service.summarize_text(text, level)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/ai_service.py", line 36, in summarize_text
    summary = await asyncio.wait_for(
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 179, in summarize_with_crew
    raise RuntimeError(f"Error in CrewAI summarization process: {str(e)}")
RuntimeError: Error in CrewAI summarization process: Error creating agents: 'CrewAIService' object has no attribute 'llm'
2025-04-04 16:50:33,389 - root - INFO - Starting up the application...
2025-04-04 16:50:33,389 - root - INFO - Configuration validated successfully
2025-04-04 16:50:33,390 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:50:33,401 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:50:33,478 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:50:33,478 - root - INFO - RAG service initialized successfully
2025-04-04 16:50:33,478 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:53:09,221 - root - INFO - Starting up the application...
2025-04-04 16:53:09,222 - root - INFO - Configuration validated successfully
2025-04-04 16:53:09,222 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:53:09,233 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:53:09,343 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:53:09,343 - root - INFO - RAG service initialized successfully
2025-04-04 16:53:09,343 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 16:54:17,433 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 16:54:17,469 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:24:17.39402Z' done=True done_reason='stop' total_duration=68038582833 load_duration=18183458 prompt_eval_count=2 prompt_eval_duration=5258790208 eval_count=1064 eval_duration=62759318292 message=Message(role='assistant', content='1.  If you could have a conversation with any person from history, who would it be and what would you say?\n    I would choose to speak with Albert Einstein, as his insights into the universe have always fascinated me. I would ask him about his thoughts on how science has evolved since his time, particularly in areas like quantum mechanics and cosmology, and whether he believes there are still undiscovered principles of nature waiting to be discovered.\n\n2.  What\'s your all-time favorite movie, and why do you love it so much?\n    My all-time favorite movie is "The Shawshank Redemption." I love this film because it tells a compelling story about hope, resilience, and the power of friendship in the face of adversity. The characters are well-developed, and the narrative keeps you engaged from start to finish. Plus, the cinematography and musical score add an extra layer of emotion that make it a truly memorable experience.\n\n3.  If you could live anywhere in the world for a year, where would you go and why?\n    I would love to spend a year living in Japan, specifically in Tokyo. The bustling city life, rich culture, history, food, and technology appeal to me immensely. As someone who enjoys learning new things and experiencing different perspectives, I believe that living in Japan would provide countless opportunities for personal growth and enrichment.\n\n4.  What\'s the most exciting adventure you\'ve ever been on?\n    The most exciting adventure I\'ve ever been on was a road trip across Western Europe with my family when I was 17 years old. We started in London, England, and traveled through France, Switzerland, Germany, Austria, Italy, and Spain before ending our journey in Lisbon, Portugal. Along the way, we visited iconic landmarks like the Eiffel Tower, the Swiss Alps, the Roman Colosseum, and the Sagrada Familia. This experience opened my eyes to different cultures, landscapes, and histories, making me appreciate the diverse world we live in.\n\n5.  What\'s one thing you wish everyone knew about you?\n    One thing I wish everyone knew about me is that I am passionate about learning new skills and pursuing personal growth opportunities. Whether it\'s a new language, coding, photography, or cooking, I enjoy challenging myself and expanding my horizons. I believe that lifelong learning is essential for staying curious, adaptable, and open-minded in an ever-changing world.\n\n6.  If you could have any superpower, what would it be and why?\n    If I could have any superpower, I would choose the ability to control time. Being able to pause, rewind, or fast-forward life would give me the opportunity to make more meaningful connections with people, learn from my mistakes without consequences, and explore various paths without worrying about running out of time. Plus, who wouldn\'t want to be able to catch every important moment in sports games?\n\n7.  What\'s one thing you would like to accomplish before you turn 30?\n    One thing I would like to accomplish before turning 30 is to publish a book based on my experiences and insights about life, personal growth, and the pursuit of happiness. Sharing my thoughts with others and potentially inspiring them to chase their dreams would be incredibly rewarding and fulfilling.\n\n8.  If you could meet any fictional character, who would it be and why?\n    I would love to meet Atticus Finch from "To Kill a Mockingbird" by Harper Lee. He is an exemplary figure who upholds justice, empathy, and integrity in the face of adversity, which are qualities that I deeply admire. Meeting him would give me an opportunity to learn more about his perspective on life, morality, and how to navigate complex social issues effectively.\n\n9.  If you could trade places with any person for a day, who would it be and why?\n    I would choose to trade places with Elon Musk for a day. As the CEO of SpaceX, Tesla, and Neuralink, he is at the forefront of some of the most exciting technological advancements happening today. Trading places with him would allow me to experience firsthand the challenges and triumphs that come with leading innovative companies and pushing the boundaries of what\'s possible.\n\n10. What\'s one piece of advice you\'d give to your 18-year-old self?\n    The one piece of advice I\'d give to my 18-year-old self is to take more risks and embrace uncertainty. Don\'t be afraid to make mistakes or fail, as they are essential for growth and learning. Be curious about the world around you, seek out new experiences, and never stop asking questions. Life is short, and it\'s important to seize opportunities when they arise, even if they seem daunting or uncertain at first.', images=None, tool_calls=None)
2025-04-04 16:54:17,471 - root - INFO - CrewAIService initialized successfully
2025-04-04 16:54:17,474 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 16:54:17,474 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 16:54:17,474 - root - INFO - PaperSearchService initialized successfully
2025-04-04 16:54:17,528 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:54:19,904 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 16:54:20,601 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 16:54:20,601 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 16:54:20,601 - root - INFO - QnAService initialized successfully
2025-04-04 16:54:20,601 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 16:54:20,602 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 16:54:20,602 - root - INFO - AIService initialized successfully
2025-04-04 16:54:20,629 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 16:54:20,629 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 16:54:20,629 - root - INFO - PDFService initialized successfully
2025-04-04 16:54:20,630 - root - INFO - Services initialized and passed to routes
2025-04-04 16:54:20,634 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 71.412 seconds
2025-04-04 16:54:20,637 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 16:54:20,656 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 16:55:16,008 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 16:55:16,009 - src.services.ai_service - INFO - Starting summarization with level: intermediate
2025-04-04 16:55:16,019 - src.services.crew_service - ERROR - Error in CrewAI summarization process: slice(None, 1000, None)
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 119, in summarize_with_crew
    description=f"Analyze the following research paper and identify the key points, methodology, and findings:\n\n{text[:1000]}...",  # Truncate text to avoid token limit issues
                                                                                                                   ~~~~^^^^^^^
KeyError: slice(None, 1000, None)
2025-04-04 16:55:16,023 - src.services.ai_service - ERROR - Error generating summary with CrewAI: Error in CrewAI summarization process: slice(None, 1000, None)
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 119, in summarize_with_crew
    description=f"Analyze the following research paper and identify the key points, methodology, and findings:\n\n{text[:1000]}...",  # Truncate text to avoid token limit issues
                                                                                                                   ~~~~^^^^^^^
KeyError: slice(None, 1000, None)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/ai_service.py", line 36, in summarize_text
    summary = await asyncio.wait_for(
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 148, in summarize_with_crew
    raise RuntimeError(f"Error in CrewAI summarization process: {str(e)}")
RuntimeError: Error in CrewAI summarization process: slice(None, 1000, None)
2025-04-04 16:55:16,024 - src.api.routes - ERROR - Error during summarization: Error in CrewAI summarization process: slice(None, 1000, None)
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 119, in summarize_with_crew
    description=f"Analyze the following research paper and identify the key points, methodology, and findings:\n\n{text[:1000]}...",  # Truncate text to avoid token limit issues
                                                                                                                   ~~~~^^^^^^^
KeyError: slice(None, 1000, None)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 171, in summarize
    summary = await ai_service.summarize_text(text, level)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/ai_service.py", line 36, in summarize_text
    summary = await asyncio.wait_for(
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/crew_service.py", line 148, in summarize_with_crew
    raise RuntimeError(f"Error in CrewAI summarization process: {str(e)}")
RuntimeError: Error in CrewAI summarization process: slice(None, 1000, None)
2025-04-04 16:58:49,665 - root - INFO - Starting up the application...
2025-04-04 16:58:49,665 - root - INFO - Configuration validated successfully
2025-04-04 16:58:49,666 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 16:58:49,677 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 16:58:49,793 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 16:58:49,793 - root - INFO - RAG service initialized successfully
2025-04-04 16:58:49,794 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 17:01:07,085 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 17:01:07,123 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:31:07.023545Z' done=True done_reason='stop' total_duration=137225101542 load_duration=15507208 prompt_eval_count=2 prompt_eval_duration=5304061708 eval_count=2112 eval_duration=131900058417 message=Message(role='assistant', content=' The following is an excerpt from the book “The Bible: How to Understand It” by Dr. David Jeremiah\n\nJesus Christ spoke of the Holy Spirit in seven different ways in the four Gospels. We will examine six of them here and consider what the Holy Spirit is and what He does in our lives today.\n\n1. The Comforter (John 14:16)\nIn the Upper Room discourse, just prior to His crucifixion, Jesus said to the disciples, “And I will pray the Father, and He will give you another Helper, that He may abide with you forever — the Spirit of truth” (John 14:16–17). The word “Helper” comes from a Greek term meaning “one who is sent alongside to help.”\n\nJesus told them, “I am going away…but I will send you another Helper that He may abide with you forever — the Spirit of truth” (John 14:16). Jesus promised that He would never leave them or forsake them. The Holy Spirit would come and make His abiding presence known to them as a Comforter, one who would strengthen their faith when they faced trials, tribulations, and persecution.\n\n2. The Counselor (John 14:26)\n“But the Helper, the Holy Spirit, whom the Father will send in My name, He will teach you all things, and bring to your remembrance all things that I said to you” (John 14:26). Jesus promised that when the Holy Spirit came upon them after His ascension into heaven, He would help them remember what He had taught them.\n\nWhen He was with them, they had asked questions of Him; and He gave answers that were helpful for their specific situations. But now they needed a more reliable way to recall Jesus’ teachings in the future. The Holy Spirit would serve as a kind of memory aid, helping them recollect the truths Jesus taught them.\n\n3. The Guide (John 16:13)\n“However, when He, the Spirit of truth, has come, He will guide you into all truth; for He will not speak on His own authority, but whatever He hears He will speak; and He will tell you things to come” (John 16:13). This Greek term means “leader” or “director.” Jesus promised that the Holy Spirit would lead them in all truth.\n\nThe Holy Spirit will guide us into all truth, not away from it. If we are following the leading of the Holy Spirit and making decisions according to His guidance, we can be sure that we are following God’s plan for our lives. The Holy Spirit will never contradict or conflict with the Word of God. The Bible is authoritative and the Holy Spirit will help us apply the Scriptures in every situation.\n\n4. The Giver of Life (John 6:63)\n“The Spirit gives life; the flesh counts for nothing. The words I have spoken to you are spirit and they are life” (John 6:63). This is a fascinating statement because it suggests that we can be spiritually alive or dead, depending on our relationship with Jesus Christ and whether we have accepted the Holy Spirit into our lives.\n\nThe Holy Spirit gives spiritual life when He comes into us at the moment of salvation (1 Corinthians 12:13). The Holy Spirit is not a force or a power that can be summoned up by the willpower of man. No one, no matter how strong their desire to please God, can coerce the Holy Spirit to come into his life. It is only through faith in Jesus Christ that a person can receive the gift of the Holy Spirit.\n\n5. The Intercessor (Romans 8:26–27)\n“In the same way, the Spirit helps us in our weakness. We do not know what we ought to pray for, but the Spirit himself intercedes for us with groans that words cannot express. And He who searches our hearts knows the mind of the Spirit, because the Spirit intercedes for the saints according to God’s will” (Romans 8:26–27). The Holy Spirit prays for us.\n\nWhen we don’t know what to pray for, the Holy Spirit intercedes on our behalf with groanings too deep for words. We can be sure that He knows exactly what we need and when we need it, and He will bring our requests before God at the perfect moment. The Holy Spirit also makes certain that everything we ask for is in line with God’s will for our lives and not contrary to it.\n\n6. The Power of God (1 Corinthians 2:4)\n“My message and my preaching were not with wise and persuasive words, but with a demonstration of the Spirit’s power” (1 Corinthians 2:4). This refers to the Holy Spirit’s miraculous abilities that were used to confirm the truth of Jesus Christ. The Holy Spirit was responsible for the miracles in the life of Christ and later in the lives of the apostles, as evidenced by Peter’s healing of the lame man at the temple (Acts 3:6) or Paul’s healing of the crippled beggar in Acts 9:34.\n\nThe miracles that were performed by Jesus and His disciples did not happen because they had a special ability, but rather because they had submitted themselves to the Holy Spirit’s power. The same miraculous power is available to us today as we seek God through prayer and follow His leading in our lives.\n\n7. The Promise of the Father (Acts 1:4)\nOn the night before Jesus was crucified, He said to His disciples, “Do not leave Jerusalem, but wait for the gift my Father promised, which you have heard Me speak about. For John baptized with water, but in a few days you will be baptized with the Holy Spirit” (Acts 1:4–5). Jesus was referring to the coming of the Holy Spirit that would take place on the Day of Pentecost fifty days after His resurrection.\n\nThe Holy Spirit is the “promise of the Father,” a reference to God’s covenant relationship with Israel. The Old Testament prophets had promised a future outpouring of the Holy Spirit upon God’s people (Joel 2:28–32). That promise was fulfilled on the Day of Pentecost, and it is also for us today as we live in the New Covenant. We can receive the Holy Spirit through faith in Jesus Christ. The Holy Spirit is a gift to all who believe.\n\nApplication of the Bible’s Teaching About the Holy Spirit\nWe must be aware that the Holy Spirit is present and active in our lives today, ready to help us, guide us, intercede for us, and give us life. We must also understand that He is not a force or a power that we can summon up by our own willpower. The Holy Spirit comes into our lives as a result of faith in Jesus Christ.\n\nWe cannot earn the gift of the Holy Spirit through good works, but only receive it by grace through faith in Jesus Christ (Ephesians 2:8–9). The Holy Spirit is not for just a select few, but for all who will believe (Acts 2:38–39). As we yield ourselves to Him, He will guide us into all truth and help us discern God’s will for our lives. We can be certain that the Holy Spirit will never lead us away from what is true or contrary to God’s Word.\n\nAs we walk in the power of the Holy Spirit, we will find that He helps us when we are weak, intercedes for us with groanings too deep for words, and performs miracles through us as evidence of His presence. The Holy Spirit is the promise of the Father to all who believe. We can be certain that if we have received Him, we have been given eternal life (Romans 8:11).\n\nPrayer\nFather in heaven, I thank You for the gift of the Holy Spirit, the Comforter, Counselor, Guide, Giver of Life, Intercessor, Power of God, and the Promise of the Father. Help me to walk in Your Spirit and not according to my flesh (Galatians 5:16). Give me wisdom and understanding as I seek You and Your will for my life (James 1:5). Fill me with the power of Your Holy Spirit that I might live a life pleasing to You, bearing fruit for Your kingdom. In Jesus’ name I pray. Amen.\n\nThe Bible provides us with a clear understanding of who the Holy Spirit is and what He does in our lives. It teaches that He is sent by God to be with us forever as a Comforter and Counselor. The Holy Spirit will guide us into all truth, intercede for us when we don’t know what to pray, and perform miracles through us as evidence of His presence. He gives us spiritual life and helps us discern God’s will for our lives. We can be certain that if we have received the Holy Spirit, we have been given eternal life. The Holy Spirit is not just for a select few but for all who believe in Jesus Christ. As we yield ourselves to Him, we will find that He helps us when we are weak, intercedes for us with groanings too deep for words, and performs miracles through us as evidence of His presence. We can live a life pleasing to God and bear fruit for His kingdom as we walk in the power of the Holy Spirit.', images=None, tool_calls=None)
2025-04-04 17:01:07,125 - root - INFO - CrewAIService initialized successfully
2025-04-04 17:01:07,128 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 17:01:07,128 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 17:01:07,128 - root - INFO - PaperSearchService initialized successfully
2025-04-04 17:01:07,204 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:01:09,602 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 17:01:10,349 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 17:01:10,349 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 17:01:10,349 - root - INFO - QnAService initialized successfully
2025-04-04 17:01:10,349 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 17:01:10,349 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 17:01:10,349 - root - INFO - AIService initialized successfully
2025-04-04 17:01:10,377 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 17:01:10,378 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 17:01:10,378 - root - INFO - PDFService initialized successfully
2025-04-04 17:01:10,378 - root - INFO - Services initialized and passed to routes
2025-04-04 17:01:10,382 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 140.716 seconds
2025-04-04 17:01:10,385 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 17:01:10,407 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 17:01:46,871 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 17:01:46,871 - src.services.ai_service - INFO - Starting summarization with level: intermediate
2025-04-04 17:01:46,889 - src.services.crew_service - INFO - Starting CrewAI summarization process for level: intermediate
2025-04-04 17:01:46,914 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:02:39,516 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:02:39,581 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:02:39,653 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:02:39,655 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:02:39,685 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:02:39,696 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:02:39,702 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:03:06,199 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:03:06,229 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:03:06,260 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:03:06,282 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:03:06,288 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:03:27,696 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:03:27,722 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:03:27,749 - src.services.crew_service - INFO - CrewAI summarization process completed
2025-04-04 17:03:27,755 - src.services.ai_service - INFO - Summarization completed successfully in 100.88 seconds
2025-04-04 17:03:27,756 - src.api.routes - INFO - Successfully summarized document: 10.1371journal.pone.0231708.pdf
2025-04-04 17:03:27,764 - src.api.routes - ERROR - Error during summarization: Object of type CrewOutput is not JSON serializable
Traceback (most recent call last):
  File "/Volumes/T7 Shield/Codes/Python/Major Project/backend/src/api/routes.py", line 173, in summarize
    return jsonify({"summary": summary}), 200
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/json/__init__.py", line 47, in jsonify
    return current_app.json.response(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 214, in response
    f"{self.dumps(obj, **dump_args)}\n", mimetype=self.mimetype
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 179, in dumps
    return json.dumps(obj, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/flask/json/provider.py", line 121, in _default
    raise TypeError(f"Object of type {type(o).__name__} is not JSON serializable")
TypeError: Object of type CrewOutput is not JSON serializable
2025-04-04 17:03:27,808 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:03:27,847 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:03:27,850 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 100.978 seconds
2025-04-04 17:07:23,356 - root - INFO - Starting up the application...
2025-04-04 17:07:23,357 - root - INFO - Configuration validated successfully
2025-04-04 17:07:23,357 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 17:07:23,368 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:07:23,486 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 17:07:23,486 - root - INFO - RAG service initialized successfully
2025-04-04 17:07:23,486 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 17:08:33,629 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 17:08:33,652 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T11:38:33.587105Z' done=True done_reason='stop' total_duration=70091943000 load_duration=16496917 prompt_eval_count=2 prompt_eval_duration=5637625125 eval_count=1094 eval_duration=64435143667 message=Message(role='assistant', content=' In my last post, I provided an overview of the first and second chapters of the book of Acts.  As I have been working through this amazing book, it has occurred to me that there are some clear lessons that can be learned from it.\n\nLesson 1: Prayer works!\n\nOne thing you may notice about the very early church is the importance of prayer and its place in their daily lives.  Acts 1:14 tells us that they “all joined together constantly in prayer.” (NASB). In verse 24, they prayed for a suitable replacement for Judas Iscariot, and they were given Saul (Paul) who ended up being the greatest missionary of all time.  The power of this kind of prayer cannot be overstated.  If we are going to see revival in our church and our country, we need to be committed to a life of prayer.\n\nLesson 2: God calls us to reach the lost and broken.\n\nIn Acts chapter one, Jesus makes it clear that His disciples should stay in Jerusalem until they receive the Holy Spirit.  They obeyed Him and waited for this event, which occurred on the Day of Pentecost.  As a result of their obedience and the filling of the Holy Spirit, they had the courage to go out and reach their fellow Jews with the good news of the gospel (Acts 2:38-41).\n\nLesson 3: Be bold in your witness.\n\nPeter and John were put in prison because of their preaching.  The religious leaders had them brought before the council and threatened to silence them, but they responded with boldness (Acts 4:9-20).  They told the council that it was impossible for them not to speak about what they saw and heard, and as a result they were released.\n\nLesson 4: God has a plan for your life.\n\nIn Acts 5, Ananias was directed by God to go to Saul (who had been persecuting the church) and lay hands on him so that he could receive his sight and be filled with the Holy Spirit.  Ananias was reluctant because of Saul’s reputation as a murderer, but he obeyed God nonetheless.  Saul became Paul and became the most effective missionary in history.\n\nLesson 5: We are all called to share the gospel.\n\nIn Acts chapter 8, Philip is directed by an angel of the Lord to go south to a city along the road he was traveling (Acts 8:26). There, he met the Ethiopian eunuch who had been to Jerusalem to worship and was returning home.  The eunuch asked him if he understood what he was reading from the prophet Isaiah, and Philip explained it to him.\n\nLesson 6: God can use people in incredible ways.\n\nIn Acts 9, Saul (Paul) had a powerful encounter with Jesus Christ on the road to Damascus.  In chapter ten, Peter was called to go to Cornelius’ house and minister to his family.  Both men were initially resistant but God used each of them in incredible ways.\n\nLesson 7: We must trust God even when it doesn’t make sense.\n\nIn Acts 10, Peter is reluctant to go to the home of Cornelius because it was a gentile and he felt it was not appropriate for him to do so.  But he obeyed God nonetheless and discovered that the Holy Spirit had been poured out on the gentiles as well.  This opened up the door for the gospel to be preached to all people.\n\nLesson 8: God’s grace is sufficient.\n\nIn Acts chapter eleven, Peter gives an account of his visit with Cornelius and how he received the Holy Spirit while there.  The Jewish Christians were initially skeptical that the gentiles had received the Holy Spirit, but Peter explains to them that it was a demonstration of God’s grace.\n\nLesson 9: Be obedient to God, no matter what the cost.\n\nIn Acts chapter twelve, we find out that Herod Agrippa killed James and imprisoned Peter with the intention of also killing him. But an angel delivered Peter from prison and he continued preaching the gospel.\n\nLesson 10: Evil may have temporary victories but God always wins in the end.\n\nHerod Agrippa was eventually struck down by an angel of the Lord for his arrogance, and God’s will was done.\n\nThese lessons are very applicable to our lives today as we seek to live obediently to Christ and make a difference in this world for Him.  As we study the book of Acts together on Wednesday nights, I pray that we can see how these principles played out in the early church and be encouraged to apply them to our own lives.\n\nBlessings,\n\nPastor Matt\n\nPosted in Uncategorized.', images=None, tool_calls=None)
2025-04-04 17:08:33,653 - root - INFO - CrewAIService initialized successfully
2025-04-04 17:08:33,655 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 17:08:33,655 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 17:08:33,655 - root - INFO - PaperSearchService initialized successfully
2025-04-04 17:08:33,727 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:08:36,387 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 17:08:37,092 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 17:08:37,093 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 17:08:37,093 - root - INFO - QnAService initialized successfully
2025-04-04 17:08:37,094 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 17:08:37,094 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 17:08:37,094 - root - INFO - AIService initialized successfully
2025-04-04 17:08:37,121 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 17:08:37,121 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 17:08:37,121 - root - INFO - PDFService initialized successfully
2025-04-04 17:08:37,121 - root - INFO - Services initialized and passed to routes
2025-04-04 17:08:37,127 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 73.770 seconds
2025-04-04 17:08:37,129 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 17:08:37,151 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 17:08:50,421 - src.services.rag_service - INFO - Document retrieved successfully: 10.1371journal.pone.0231708.pdf
2025-04-04 17:08:50,422 - src.services.ai_service - INFO - Starting summarization with level: intermediate
2025-04-04 17:08:50,439 - src.services.crew_service - INFO - Starting CrewAI summarization process for level: intermediate
2025-04-04 17:08:50,458 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:09:30,004 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:09:30,131 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:09:30,245 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:09:30,246 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:09:30,333 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:09:30,355 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:09:30,366 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:09:52,332 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:09:52,358 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:09:52,401 - LiteLLM - INFO - 
LiteLLM completion() model= mistral; provider = ollama
2025-04-04 17:09:52,416 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:09:52,428 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:10:16,059 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-04 17:10:16,093 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
2025-04-04 17:10:16,118 - src.services.crew_service - INFO - CrewAI summarization process completed
2025-04-04 17:10:16,119 - src.services.ai_service - INFO - Summarization completed successfully in 85.70 seconds
2025-04-04 17:10:16,120 - src.api.routes - INFO - Successfully summarized document: 10.1371journal.pone.0231708.pdf
2025-04-04 17:10:16,141 - asyncio - WARNING - Executing <Task finished name='Task-11' coro=<ASGIHTTPConnection.handle_request() done, defined at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 85.720 seconds
2025-04-04 17:10:16,158 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:10:16,169 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/show "HTTP/1.1 200 OK"
2025-04-04 17:33:40,505 - root - INFO - Starting up the application...
2025-04-04 17:33:40,506 - root - INFO - Configuration validated successfully
2025-04-04 17:33:40,506 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 17:33:40,517 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:33:40,633 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 17:33:40,633 - root - INFO - RAG service initialized successfully
2025-04-04 17:33:40,633 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 17:36:50,678 - root - INFO - Starting up the application...
2025-04-04 17:36:50,678 - root - INFO - Configuration validated successfully
2025-04-04 17:36:50,678 - src.services.rag_service - INFO - Initializing RAG service...
2025-04-04 17:36:50,690 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:36:50,793 - src.services.rag_service - INFO - RAG service initialized with storage path: rag_db
2025-04-04 17:36:50,793 - root - INFO - RAG service initialized successfully
2025-04-04 17:36:50,793 - src.services.crew_service - INFO - Initializing CrewAI service...
2025-04-04 17:37:58,036 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-04-04 17:37:58,113 - src.services.crew_service - INFO - CrewAI service initialized successfully. Response: model='mistral' created_at='2025-04-04T12:07:57.983895Z' done=True done_reason='stop' total_duration=67181484667 load_duration=16539709 prompt_eval_count=2 prompt_eval_duration=3341929542 eval_count=1123 eval_duration=63820374792 message=Message(role='assistant', content=' [Vue.js 入门](https://vue3js.cn/docs/vue3/introduction.html)\n\n```html\n<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <title>Document</title>\n    <script src="https://cdn.jsdelivr.net/npm/vue@3"></script>\n</head>\n<body>\n<!-- 模板 -->\n<!-- 在标签内容中插入Vue实例对象的data -->\n<div id="app">{{ message }}</div>\n<!-- 定义Vue实例对象 -->\n<script>\n    const vm = new Vue({\n        // data: function () { 也可以这样写，但是这种方式不推荐使用，推荐使用es6简化语法\n        el: \'#app\',  // 挂载元素\n        data: {    // 数据对象\n            message: \'Hello Vue 3!\'\n        }\n    })\n</script>\n</body>\n</html>\n```\n\n```html\n<!-- v-bind -->\n<div id="app">\n    <h1 :title="title">{{ message }}</h1>\n</div>\nconst vm = new Vue({\n    el: \'#app\',\n    data: {\n        title: \'Vue 3 的标题\',\n        message: \'Hello Vue 3!\'\n    }\n})\n```\n\n```html\n<!-- v-model -->\n<div id="app">\n    <input type="text" v-model="message">\n</div>\nconst vm = new Vue({\n    el: \'#app\',\n    data: {\n        message: \'Hello Vue 3!\'\n    }\n})\n```\n\n```html\n<!-- v-for -->\n<div id="app">\n    <ul>\n        <li v-for="(item,index) in items" :key="index">{{ index + \' - \' + item}}</li>\n    </ul>\n</div>\nconst vm = new Vue({\n    el: \'#app\',\n    data: {\n        items: [\'Apple\',\'Banana\',\'Cherry\']\n    }\n})\n```\n\n```html\n<!-- v-on -->\n<button @click="sayHi">点击我</button>\nconst vm = new Vue({\n    el: \'#app\',\n    data: {\n        msg: \'\'\n    },\n    methods: {\n        sayHi() {\n            this.msg = \'你好，Vue3\';\n        }\n    }\n})\n```\n\n```html\n<!-- v-if、v-show -->\n<h1 v-if="isShow">我是显示的</h1>\n<h1 v-else>我是隐藏的</h1>\nconst vm = new Vue({\n    el: \'#app\',\n    data: {\n        isShow: true\n    }\n})\n```\n\n```html\n<!-- 组件 -->\n<!-- 创建组件模板 -->\n<template id="child">\n    这是一个子组件！\n</template>\n<!-- 父组件，挂载子组件 -->\n<div id="app">\n    <h1>我是父组件</h1>\n    <!-- 用v-once指令让元素渲染一次 -->\n    <child v-once></child>\n    <child></child>\n</div>\n<!-- 定义子组件实例对象 -->\n<script type="text/javascript">\nconst ChildComponent = {\n    template: \'#child\'\n}\nconst vm = new Vue({\n    el: \'#app\',\n    components: {\n        child: ChildComponent\n    }\n})\n</script>\n```\n\n```html\n<!-- 父组件，挂载子组件 -->\n<div id="parent">\n    这是一个父组件，我有一个child组件！\n    <!-- 父组件使用v-bind的方式将数据传递给子组件 -->\n    <child :title="message"></child>\n</div>\n<!-- 定义子组件模板和子组件实例对象 -->\n<template id="child">\n    这是一个子组件！\n    <h1>{{ title }}</h1>\n</template>\n<script type="text/javascript">\nconst ChildComponent = {\n    template: \'#child\',\n    props: [\'title\']  // 定义props属性，用于接收父组件的数据\n}\n// 子组件实例对象\nconst vm = new Vue({\n    el: \'#parent\'\n})\n</script>\n```', images=None, tool_calls=None)
2025-04-04 17:37:58,117 - root - INFO - CrewAIService initialized successfully
2025-04-04 17:37:58,121 - src.services.paper_search_service - INFO - Initializing PaperSearchService...
2025-04-04 17:37:58,121 - src.services.paper_search_service - INFO - PaperSearchService initialized successfully
2025-04-04 17:37:58,121 - root - INFO - PaperSearchService initialized successfully
2025-04-04 17:37:58,240 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-04-04 17:38:00,561 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: mps
2025-04-04 17:38:01,268 - src.services.qna_service - INFO - Initializing QnAService...
2025-04-04 17:38:01,268 - src.services.qna_service - INFO - QnAService initialized successfully
2025-04-04 17:38:01,268 - root - INFO - QnAService initialized successfully
2025-04-04 17:38:01,269 - src.services.ai_service - INFO - Initializing AIService...
2025-04-04 17:38:01,269 - src.services.ai_service - INFO - AIService initialized successfully
2025-04-04 17:38:01,269 - root - INFO - AIService initialized successfully
2025-04-04 17:38:01,294 - src.services.pdf_service - INFO - Initializing PDFService...
2025-04-04 17:38:01,295 - src.services.pdf_service - INFO - PDFService initialized successfully
2025-04-04 17:38:01,295 - root - INFO - PDFService initialized successfully
2025-04-04 17:38:01,295 - root - INFO - Services initialized and passed to routes
2025-04-04 17:38:01,299 - asyncio - WARNING - Executing <Task pending name='Task-3' coro=<Lifespan.handle_lifespan() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/lifespan.py:55> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/hypercorn/asyncio/run.py:83> took 70.621 seconds
2025-04-04 17:38:01,302 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=41, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-04-04 17:38:01,326 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-04-04 17:39:11,925 - scholarly - INFO - Getting https://scholar.google.com/scholar?hl=en&q=artificial%20intelligence&as_vis=0&as_sdt=0,33
2025-04-04 17:39:14,315 - httpx - INFO - HTTP Request: GET https://scholar.google.com/scholar?hl=en&q=artificial%20intelligence&as_vis=0&as_sdt=0,33 "HTTP/1.1 200 OK"
2025-04-04 17:39:14,684 - scholarly - INFO - Getting https://scholar.google.com/scholar?start=10&q=artificial+intelligence&hl=en&as_sdt=0,33
2025-04-04 17:39:16,682 - httpx - INFO - HTTP Request: GET https://scholar.google.com/scholar?start=10&q=artificial+intelligence&hl=en&as_sdt=0,33 "HTTP/1.1 200 OK"
2025-04-04 17:39:17,050 - src.services.paper_search_service - INFO - Fetched 20 results from Google Scholar
2025-04-04 17:39:17,061 - asyncio - WARNING - Executing <Task pending name='Task-11' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[shield.<locals>._outer_done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:922, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 5.139 seconds
2025-04-04 17:39:17,755 - asyncio - INFO - Getting address info export.arxiv.org:80, type=<SocketKind.SOCK_STREAM: 1>, flags=<AddressInfo.AI_ADDRCONFIG: 1024> took 695.437ms: [(<AddressFamily.AF_INET: 2>, <SocketKind.SOCK_STREAM: 1>, 6, '', ('128.84.21.203', 80))]
2025-04-04 17:39:18,765 - src.services.paper_search_service - INFO - Fetched 20 results from ArXiv
2025-04-04 17:39:18,907 - asyncio - WARNING - Executing <Task pending name='Task-37' coro=<RAGService.store_document() running at /Volumes/T7 Shield/Codes/Python/Major Project/backend/src/services/rag_service.py:45> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 0.127 seconds
2025-04-04 17:39:25,799 - asyncio - WARNING - Executing <TimerHandle when=24244.430487166 _set_result_unless_cancelled(<Future finis...events.py:448>, None) at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:313 created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:661> took 6.079 seconds
2025-04-04 17:39:28,793 - asyncio - WARNING - Executing <Handle _chain_future.<locals>._set_state(<Future finis...events.py:448>, <Future at 0x...rned NoneType>) at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:383 created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:405> took 2.153 seconds
2025-04-04 17:39:30,700 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 1.352 seconds
2025-04-04 17:39:36,349 - asyncio - WARNING - Executing <Handle _chain_future.<locals>._set_state(<Future finis...events.py:448>, <Future at 0x...rned NoneType>) at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:383 created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:405> took 4.314 seconds
2025-04-04 17:39:42,014 - asyncio - WARNING - Executing <Handle _chain_future.<locals>._set_state(<Future finis...events.py:448>, <Future at 0x...rned NoneType>) at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:383 created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:405> took 5.438 seconds
2025-04-04 17:39:43,235 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_11
2025-04-04 17:39:43,236 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_3
2025-04-04 17:39:43,237 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_1
2025-04-04 17:39:43,237 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_9
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_6
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_8
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_0
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_7
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_2
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_5
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_10
2025-04-04 17:39:43,238 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_4
2025-04-04 17:39:43,240 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_13
2025-04-04 17:39:43,240 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_12
2025-04-04 17:39:43,240 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_14
2025-04-04 17:39:43,240 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_15
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_17
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_20
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_18
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_16
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_19
2025-04-04 17:39:43,241 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_21
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_23
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_25
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_24
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_22
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_28
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_27
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_26
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_33
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_30
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_29
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_31
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_32
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_34
2025-04-04 17:39:43,242 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_39
2025-04-04 17:39:43,243 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_36
2025-04-04 17:39:43,243 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_37
2025-04-04 17:39:43,569 - asyncio - WARNING - Executing <Task pending name='Task-2' coro=<observe_changes() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/utils.py:125> cb=[gather.<locals>._done_callback() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:767] created at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/app.py:873> took 0.251 seconds
2025-04-04 17:39:43,569 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_38
2025-04-04 17:39:43,569 - src.services.rag_service - INFO - Document stored successfully: search_result_artificial intelligence_35
2025-04-04 17:39:43,570 - src.services.paper_search_service - INFO - Completed paper search for query: artificial intelligence
2025-04-04 17:56:09,980 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Swathy%20R
2025-04-04 17:56:14,309 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Swathy%20R "HTTP/1.1 200 OK"
2025-04-04 17:56:14,344 - scholarly - INFO - Found 10 authors
2025-04-04 17:56:14,346 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&user=9ipAiU0AAAAJ&pagesize=100
2025-04-04 17:56:16,201 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&user=9ipAiU0AAAAJ&pagesize=100 "HTTP/1.1 200 OK"
2025-04-04 17:56:18,799 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&tzom=300&user=9ipAiU0AAAAJ&view_op=list_mandates&pagesize=100
2025-04-04 17:56:25,076 - scholarly - INFO - Timeout Exception ReadTimeout while fetching page: ('The read operation timed out',)
2025-04-04 17:56:25,077 - scholarly - INFO - Increasing timeout and retrying within same session.
2025-04-04 17:56:32,767 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&tzom=300&user=9ipAiU0AAAAJ&view_op=list_mandates&pagesize=100 "HTTP/1.1 200 OK"
2025-04-04 17:56:32,823 - src.services.paper_search_service - INFO - Fetched details for author: Swathy R
2025-04-04 17:56:32,905 - asyncio - WARNING - Executing <Task pending name='Task-60' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 22.926 seconds
2025-04-04 17:56:33,574 - src.services.rag_service - INFO - Document stored successfully: author_Swathy R
2025-04-04 17:56:33,574 - src.services.paper_search_service - INFO - Stored author details in RAG for: Swathy R
2025-04-04 17:57:14,674 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Swathy%20R%20SRM%20
2025-04-04 17:57:18,279 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Swathy%20R%20SRM%20 "HTTP/1.1 200 OK"
2025-04-04 17:57:18,549 - scholarly - INFO - Found 1 authors
2025-04-04 17:57:18,549 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&user=SEfqCcUAAAAJ&pagesize=100
2025-04-04 17:57:20,989 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&user=SEfqCcUAAAAJ&pagesize=100 "HTTP/1.1 200 OK"
2025-04-04 17:57:21,016 - scholarly - INFO - Getting https://scholar.google.com/citations?hl=en&tzom=300&user=SEfqCcUAAAAJ&view_op=list_mandates&pagesize=100
2025-04-04 17:57:25,523 - httpx - INFO - HTTP Request: GET https://scholar.google.com/citations?hl=en&tzom=300&user=SEfqCcUAAAAJ&view_op=list_mandates&pagesize=100 "HTTP/1.1 200 OK"
2025-04-04 17:57:25,541 - src.services.paper_search_service - INFO - Fetched details for author: Swathy R SRM 
2025-04-04 17:57:25,996 - asyncio - WARNING - Executing <Task pending name='Task-68' coro=<ASGIHTTPConnection.handle_request() running at /Volumes/T7 Shield/Codes/Python/Major Project/myproject_env_py3.12/lib/python3.12/site-packages/quart/asgi.py:108> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:389, Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:448> cb=[_wait.<locals>._on_completion() at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:534] created at /opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 11.322 seconds
2025-04-04 17:57:26,269 - src.services.rag_service - INFO - Document stored successfully: author_Swathy R SRM 
2025-04-04 17:57:26,269 - src.services.paper_search_service - INFO - Stored author details in RAG for: Swathy R SRM 
